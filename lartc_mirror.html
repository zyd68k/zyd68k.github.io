<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html class=" kzmsuhgui idc0_350 fqpakdqg kghtzriu"><head>
<meta http-equiv="content-type" content="text/html; charset=windows-1252"><title>Linux Advanced Routing &amp; Traffic Control HOWTO</title><meta name="GENERATOR" content="Modular DocBook HTML Stylesheet Version 1.79"><link href="style.css" rel="stylesheet" /></head><body class="BOOK" bgcolor="#FFFFFF" text="#000000" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="BOOK"><a name="LARTC"></a><div class="TITLEPAGE"><h1 class="TITLE"><a name="AEN2">Linux Advanced Routing &amp; Traffic Control HOWTO</a></h1><h3 class="AUTHOR"><a name="AEN5"></a>Bert Hubert</h3><div class="AFFILIATION"><span class="ORGNAME">Netherlabs BV<br></span><div class="ADDRESS"><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:bert.hubert@netherlabs.nl">bert.hubert@netherlabs.nl</a>&gt;</code></p></div></div><span class="COLLAB"><span class="COLLABNAME">Thomas Graf (Section Author)</span><div class="AFFILIATION"><div class="ADDRESS"><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:tgraf%suug.ch">tgraf%suug.ch</a>&gt;</code></p></div></div><br></span><span class="COLLAB"><span class="COLLABNAME">Gregory Maxwell (Section Author)</span><br></span><span class="COLLAB"><span class="COLLABNAME">Remco van Mook (Section Author)</span><div class="AFFILIATION"><div class="ADDRESS"><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:remco@virtu.nl">remco@virtu.nl</a>&gt;</code></p></div></div><br></span><span class="COLLAB"><span class="COLLABNAME">Martijn van Oosterhout (Section Author)</span><div class="AFFILIATION"><div class="ADDRESS"><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:kleptog@cupid.suninternet.com">kleptog@cupid.suninternet.com</a>&gt;</code></p></div></div><br></span><span class="COLLAB"><span class="COLLABNAME">Paul B Schroeder (Section Author)</span><div class="AFFILIATION"><div class="ADDRESS"><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:paulsch@us.ibm.com">paulsch@us.ibm.com</a>&gt;</code></p></div></div><br></span><span class="COLLAB"><span class="COLLABNAME">Jasper Spaans (Section Author)</span><div class="AFFILIATION"><div class="ADDRESS"><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:jasper@spaans.ds9a.nl">jasper@spaans.ds9a.nl</a>&gt;</code></p></div></div><br></span><span class="COLLAB"><span class="COLLABNAME">Pedro Larroy (Section Author)</span><div class="AFFILIATION"><div class="ADDRESS"><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:piotr%member.fsf.org">piotr%member.fsf.org</a>&gt;</code></p></div></div><br></span><div><div class="ABSTRACT"><p></p><a name="AEN49"></a><p>A very hands-on approach to <span class="APPLICATION">iproute2</span>,
     traffic shaping and a bit of <span class="APPLICATION">netfilter</span>.
     </p><p></p></div></div><hr></div><div class="TOC"><dl><dt><b>Table of Contents</b></dt><dt>1. <a href="#LARTC.DEDICATION">Dedication</a></dt><dt>2. <a href="#LARTC.INTRO">Introduction</a></dt><dd><dl><dt>2.1. <a href="#LARTC.INTRO.DISCLAIMER">Disclaimer &amp; License</a></dt><dt>2.2. <a href="#LARTC.INTRO.PRIOR">Prior knowledge</a></dt><dt>2.3. <a href="#LARTC.INTRO.LINUX">What Linux can do for you</a></dt><dt>2.4. <a href="#LARTC.INTRO.HOUSKEEPING">Housekeeping notes</a></dt><dt>2.5. <a href="#LARTC.INTRO.GIT">Access, GIT &amp; submitting updates</a></dt><dt>2.6. <a href="#LARTC.INTRO.MLIST">Mailing list</a></dt><dt>2.7. <a href="#LARTC.INTRO.LAYOUT">Layout of this document</a></dt></dl></dd><dt>3. <a href="#LARTC.IPROUTE2">Introduction to iproute2</a></dt><dd><dl><dt>3.1. <a href="#LARTC.IPROUTE2.WHY">Why iproute2?</a></dt><dt>3.2. <a href="#LARTC.IPROUTE2.TOUR">iproute2 tour</a></dt><dt>3.3. <a href="#LARTC.IPROUTE2.PACKAGE">Prerequisites</a></dt><dt>3.4. <a href="#LARTC.IPROUTE2.EXPLORE">Exploring your current configuration</a></dt><dd><dl><dt>3.4.1. <a href="#AEN195"><b class="COMMAND">ip</b> shows us our links</a></dt><dt>3.4.2. <a href="#AEN204"><b class="COMMAND">ip</b> shows us our IP addresses</a></dt><dt>3.4.3. <a href="#AEN214"><b class="COMMAND">ip</b> shows us our routes</a></dt></dl></dd><dt>3.5. <a href="#LARTC.IPROUTE2.ARP">ARP</a></dt></dl></dd><dt>4. <a href="#LARTC.RPDB">Rules - routing policy database</a></dt><dd><dl><dt>4.1. <a href="#LARTC.RPDB.SIMPLE">Simple source policy routing</a></dt><dt>4.2. <a href="#LARTC.RPDB.MULTIPLE-LINKS">Routing for multiple uplinks/providers</a></dt><dd><dl><dt>4.2.1. <a href="#AEN267">Split access</a></dt><dt>4.2.2. <a href="#AEN297">Load balancing</a></dt></dl></dd></dl></dd><dt>5. <a href="#LARTC.TUNNEL">GRE and other tunnels</a></dt><dd><dl><dt>5.1. <a href="#LARTC.TUNNEL.REMARKS">A few general remarks about tunnels:</a></dt><dt>5.2. <a href="#LARTC.TUNNEL.IP-IP">IP in IP tunneling</a></dt><dt>5.3. <a href="#LARTC.TUNNEL.GRE">GRE tunneling</a></dt><dd><dl><dt>5.3.1. <a href="#AEN337">IPv4 Tunneling</a></dt><dt>5.3.2. <a href="#AEN355">IPv6 Tunneling</a></dt></dl></dd><dt>5.4. <a href="#LARTC.TUNNEL.USERLAND">Userland tunnels</a></dt></dl></dd><dt>6. <a href="#LARTC.IPV6-TUNNEL">IPv6 tunneling with Cisco and/or 6bone</a></dt><dd><dl><dt>6.1. <a href="#LARTC.TUNNEL-IPV6.ADDRESSING">IPv6 Tunneling</a></dt></dl></dd><dt>7. <a href="#LARTC.IPSEC">IPSEC: secure IP over the Internet</a></dt><dd><dl><dt>7.1. <a href="#LARTC.IPSEC.INTRO">Intro with Manual Keying</a></dt><dt>7.2. <a href="#LARTC.IPSEC.AUTOMATIC.KEYING">Automatic keying</a></dt><dd><dl><dt>7.2.1. <a href="#LARTC.IPSEC.KEYING.THEORY">Theory</a></dt><dt>7.2.2. <a href="#LARTC.IPSEC.AUTOMATIC.KEYING.EXAMPLE">Example</a></dt><dt>7.2.3. <a href="#LARTC.IPSEC.X509">Automatic keying using X.509 certificates</a></dt></dl></dd><dt>7.3. <a href="#LARTC.IPSEC.TUNNEL">IPSEC tunnels</a></dt><dt>7.4. <a href="#LARTC.IPSEC.OTHER">Other IPSEC software</a></dt><dt>7.5. <a href="#LARTC.IPSEC.INTEROP">IPSEC interoperation with other systems</a></dt><dd><dl><dt>7.5.1. <a href="#LARTC.IPSEC.INTEROP.WIN32">Windows</a></dt><dt>7.5.2. <a href="#LARTC.IPSEC.INTEROP.CHECKPOINT">Check Point VPN-1
NG</a></dt></dl></dd></dl></dd><dt>8. <a href="#LARTC.MULTICAST">Multicast routing</a></dt><dt>9. <a href="#LARTC.QDISC">Queueing Disciplines for Bandwidth Management</a></dt><dd><dl><dt>9.1. <a href="#LARTC.QDISC.EXPLAIN">Queues and Queueing Disciplines explained</a></dt><dt>9.2. <a href="#LARTC.QDISC.CLASSLESS">Simple, classless Queueing Disciplines</a></dt><dd><dl><dt>9.2.1. <a href="#AEN658">pfifo_fast</a></dt><dt>9.2.2. <a href="#AEN690">Token Bucket Filter</a></dt><dt>9.2.3. <a href="#LARTC.SFQ">Stochastic Fairness Queueing</a></dt></dl></dd><dt>9.3. <a href="#LARTC.QDISC.ADVICE">Advice for when to use which queue</a></dt><dt>9.4. <a href="#LARTC.QDISC.TERMINOLOGY">Terminology</a></dt><dt>9.5. <a href="#LARTC.QDISC.CLASSFUL">Classful Queueing Disciplines</a></dt><dd><dl><dt>9.5.1. <a href="#AEN876">Flow within classful qdiscs &amp; classes</a></dt><dt>9.5.2. <a href="#AEN882">The qdisc family: roots, handles, siblings and parents</a></dt><dt>9.5.3. <a href="#AEN902">The PRIO qdisc</a></dt><dt>9.5.4. <a href="#AEN938">The famous CBQ qdisc</a></dt><dt>9.5.5. <a href="#AEN1071">Hierarchical Token Bucket</a></dt></dl></dd><dt>9.6. <a href="#LARTC.QDISC.FILTERS">Classifying packets with filters</a></dt><dd><dl><dt>9.6.1. <a href="#AEN1099">Some simple filtering examples</a></dt><dt>9.6.2. <a href="#LARTC.FILTERING.SIMPLE">All the filtering commands you will normally need</a></dt></dl></dd><dt>9.7. <a href="#LARTC.IMQ">The Intermediate queueing device (IMQ)</a></dt><dd><dl><dt>9.7.1. <a href="#AEN1154">Sample configuration</a></dt></dl></dd></dl></dd><dt>10. <a href="#LARTC.LOADSHARE">Load sharing over multiple interfaces</a></dt><dd><dl><dt>10.1. <a href="#LARTC.LOADSHARE.CAVEATS">Caveats</a></dt><dt>10.2. <a href="#LARTC.LOADSHARE.OTHER">Other possibilities</a></dt></dl></dd><dt>11. <a href="#LARTC.NETFILTER">Netfilter &amp; iproute - marking packets</a></dt><dt>12. <a href="#LARTC.ADV-FILTER">Advanced filters for (re-)classifying packets</a></dt><dd><dl><dt>12.1. <a href="#LARTC.ADV-FILTER.U32">The <code class="OPTION">u32</code> classifier</a></dt><dd><dl><dt>12.1.1. <a href="#AEN1289">U32 selector</a></dt><dt>12.1.2. <a href="#AEN1303">General selectors</a></dt><dt>12.1.3. <a href="#AEN1327">Specific selectors</a></dt></dl></dd><dt>12.2. <a href="#LARTC.ADV-FILTER.ROUTE">The <code class="OPTION">route</code> classifier</a></dt><dt>12.3. <a href="#LARTC.ADV-FILTER.POLICING">Policing filters</a></dt><dd><dl><dt>12.3.1. <a href="#AEN1371">Ways to police</a></dt><dt>12.3.2. <a href="#AEN1393">Overlimit actions</a></dt><dt>12.3.3. <a href="#AEN1413">Examples</a></dt></dl></dd><dt>12.4. <a href="#LARTC.ADV-FILTER.HASHING">Hashing filters for very fast massive filtering</a></dt><dt>12.5. <a href="#LARTC.ADV-FILTER.IPV6">Filtering IPv6 Traffic</a></dt><dd><dl><dt>12.5.1. <a href="#AEN1446">How come that IPv6 tc filters do not work?</a></dt><dt>12.5.2. <a href="#AEN1451">Marking IPv6 packets using ip6tables</a></dt><dt>12.5.3. <a href="#AEN1456">Using the u32 selector to match IPv6 packet</a></dt></dl></dd></dl></dd><dt>13. <a href="#LARTC.KERNEL">Kernel network parameters</a></dt><dd><dl><dt>13.1. <a href="#LARTC.KERNEL.RPF">Reverse Path Filtering</a></dt><dt>13.2. <a href="#LARTC.KERNEL.OBSCURE">Obscure settings</a></dt><dd><dl><dt>13.2.1. <a href="#AEN1492">Generic ipv4</a></dt><dt>13.2.2. <a href="#AEN1673">Per device settings</a></dt><dt>13.2.3. <a href="#AEN1730">Neighbor policy</a></dt><dt>13.2.4. <a href="#AEN1782">Routing settings</a></dt></dl></dd></dl></dd><dt>14. <a href="#LARTC.ADV-QDISC">Advanced &amp; less common queueing disciplines</a></dt><dd><dl><dt>14.1. <a href="#LARTC.ADV-QDISC.BFIFO-PFIFO"><tt class="LITERAL">bfifo</tt>/<tt class="LITERAL">pfifo</tt></a></dt><dd><dl><dt>14.1.1. <a href="#AEN1861">Parameters &amp; usage</a></dt></dl></dd><dt>14.2. <a href="#LARTC.ADV-QDISC.CSZ">Clark-Shenker-Zhang algorithm (CSZ)</a></dt><dt>14.3. <a href="#LARTC.ADV-QDISC.DSMARK">DSMARK</a></dt><dd><dl><dt>14.3.1. <a href="#AEN1902">Introduction</a></dt><dt>14.3.2. <a href="#AEN1907">What is Dsmark related to?</a></dt><dt>14.3.3. <a href="#AEN1911">Differentiated Services guidelines</a></dt><dt>14.3.4. <a href="#AEN1919">Working with Dsmark</a></dt><dt>14.3.5. <a href="#AEN1935">How SCH_DSMARK works.</a></dt><dt>14.3.6. <a href="#AEN1952">TC_INDEX Filter</a></dt></dl></dd><dt>14.4. <a href="#LARTC.ADV-QDISC.INGRESS">Ingress qdisc</a></dt><dd><dl><dt>14.4.1. <a href="#AEN1980">Parameters &amp; usage</a></dt></dl></dd><dt>14.5. <a href="#LARTC.ADV-QDISC.RED">Random Early Detection (RED)</a></dt><dt>14.6. <a href="#LARTC.ADV-QDISC.GRED">Generic Random Early Detection</a></dt><dt>14.7. <a href="#LARTC.ADV-QDISC.VC-ATM">VC/ATM emulation</a></dt><dt>14.8. <a href="#LARTC.ADV-QDISC.WRR">Weighted Round Robin (WRR)</a></dt></dl></dd><dt>15. <a href="#LARTC.COOKBOOK">Cookbook</a></dt><dd><dl><dt>15.1. <a href="#LARTC.COOKBOOK.SLA">Running multiple sites with different SLAs</a></dt><dt>15.2. <a href="#LARTC.COOKBOOK.SYNFLOOD-PROTECT">Protecting your host from SYN floods</a></dt><dt>15.3. <a href="#LARTC.COOKBOOK.ICMP-RATELIMIT">Rate limit ICMP to prevent dDoS</a></dt><dt>15.4. <a href="#LARTC.COOKBOOK.INTERACTIVE-PRIO">Prioritizing interactive traffic</a></dt><dt>15.5. <a href="#LARTC.COOKBOOK.SQUID">Transparent web-caching using <span class="APPLICATION">netfilter</span>,
	<span class="APPLICATION">iproute2</span>, <span class="APPLICATION">ipchains</span> and 
	<span class="APPLICATION">squid</span></a></dt><dd><dl><dt>15.5.1. <a href="#AEN2139">Traffic flow diagram after implementation</a></dt></dl></dd><dt>15.6. <a href="#LARTC.COOKBOOK.MTU-DISCOVERY">Circumventing Path MTU Discovery issues with per route MTU settings</a></dt><dd><dl><dt>15.6.1. <a href="#AEN2164">Solution</a></dt></dl></dd><dt>15.7. <a href="#LARTC.COOKBOOK.MTU-MSS">Circumventing Path MTU Discovery issues with MSS Clamping
  (for ADSL, cable, PPPoE &amp; PPtP users)</a></dt><dt>15.8. <a href="#LARTC.COOKBOOK.ULTIMATE-TC">The Ultimate Traffic Conditioner: Low Latency, Fast Up &amp; Downloads</a></dt><dd><dl><dt>15.8.1. <a href="#AEN2210">Why it doesn't work well by default</a></dt><dt>15.8.2. <a href="#AEN2233">The actual script (CBQ)</a></dt><dt>15.8.3. <a href="#AEN2241">The actual script (HTB)</a></dt></dl></dd><dt>15.9. <a href="#LARTC.RATELIMIT.SINGLE">Rate limiting a single host or netmask</a></dt><dt>15.10. <a href="#LARTC.COOKBOOK.FULLNAT.INTRO">Example of a full nat solution with QoS</a></dt><dd><dl><dt>15.10.1. <a href="#AEN2279">Let's begin optimizing that scarce bandwidth</a></dt><dt>15.10.2. <a href="#AEN2313">Classifying packets</a></dt><dt>15.10.3. <a href="#AEN2333">Improving our setup</a></dt><dt>15.10.4. <a href="#AEN2338">Making all of the above start at boot</a></dt></dl></dd></dl></dd><dt>16. <a href="#LARTC.BRIDGING">Building bridges, and pseudo-bridges with Proxy ARP</a></dt><dd><dl><dt>16.1. <a href="#LARTC.BRIDGING.IPTABLES">State of bridging and iptables</a></dt><dt>16.2. <a href="#LARTC.BRIDGING.SHAPING">Bridging and shaping</a></dt><dt>16.3. <a href="#LARTC.BRIDGING.PROXY-ARP">Pseudo-bridges with Proxy-ARP</a></dt><dd><dl><dt>16.3.1. <a href="#AEN2364">ARP &amp; Proxy-ARP</a></dt><dt>16.3.2. <a href="#AEN2371">Implementing it</a></dt></dl></dd></dl></dd><dt>17. <a href="#LARTC.DYNAMIC-ROUTING">Dynamic routing - OSPF and BGP</a></dt><dd><dl><dt>17.1. <a href="#LARTC.DYNAMIC-ROUTING.OSPF">Setting up OSPF with Zebra</a></dt><dd><dl><dt>17.1.1. <a href="#LARTC.DYNAMIC-ROUTING.OSPF.PREREQ">Prerequisites</a></dt><dt>17.1.2. <a href="#LARTC.DYNAMIC-ROUTING.OSPF.ZEBRACFG">Configuring Zebra</a></dt><dt>17.1.3. <a href="#LARTC.DYNAMIC-ROUTING.OSPF.RUNNING">Running Zebra</a></dt></dl></dd><dt>17.2. <a href="#LARTC.DYNAMIC-ROUTING.BGP">Setting up BGP4 with Zebra</a></dt><dd><dl><dt>17.2.1. <a href="#LARTC.DYNAMIC-ROUTING.BGP.NETMAP">Network Map (Example)</a></dt><dt>17.2.2. <a href="#LARTC.DYNAMIC-ROUTING.BGP.CONFIG">Configuration (Example)</a></dt><dt>17.2.3. <a href="#AEN2512">Checking Configuration</a></dt></dl></dd></dl></dd><dt>18. <a href="#LARTC.OTHER">Other possibilities</a></dt><dt>19. <a href="#LARTC.FURTHER">Further reading</a></dt><dt>20. <a href="#LARTC.ACK">Acknowledgements</a></dt></dl></div><div class="CHAPTER"><hr><h1><a name="LARTC.DEDICATION"></a>Chapter 1. Dedication</h1><p>      This document is dedicated to lots of people, and is my attempt to do
      something back. To list but a few:
    </p><p>      </p><p></p><ul><li><p>	    Rusty Russell
	  </p></li><li><p>	    Alexey N. Kuznetsov
	  </p></li><li><p>	    The good folks from Google
	  </p></li><li><p>	    The staff of Casema Internet
	  </p></li></ul>
	
    <p></p></div><div class="CHAPTER"><hr><h1><a name="LARTC.INTRO"></a>Chapter 2. Introduction</h1><p>Welcome, gentle reader.</p><p>      This document hopes to enlighten you on how to do more with Linux 2.2/2.4
      routing. Unbeknownst to most users, you already run tools which allow you to
      do spectacular things. Commands like <b class="COMMAND">route</b> and 
      <b class="COMMAND">ifconfig</b> are actually
      very thin wrappers for the very powerful iproute2 infrastructure.</p><p>      I hope that this HOWTO will become as readable as the ones by Rusty Russell
      of (amongst other things) netfilter fame.
    </p><p>      You can always reach us by posting to the mailing list (see the relevant
      section) if you have comments or questions about or somewhat related to
      this HOWTO. We are no free helpdesk, but we often will answer questions
      asked on the list.</p><p>Before losing your way in this HOWTO, if all you want to do is simple
traffic shaping, skip everything and head to the <i class="CITETITLE"><a href="#LARTC.OTHER">Other possibilities</a></i> chapter, and read about CBQ.init.</p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.INTRO.DISCLAIMER">2.1. Disclaimer &amp; License</a></h2><p>This document is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p><p>In short, if your STM-64 backbone breaks down and distributes pornography to
your most esteemed customers - it's never our fault. Sorry.</p><p>Copyright (c) 2002 by bert hubert, Gregory Maxwell, Martijn van
Oosterhout, Remco van Mook, Paul B. Schroeder and others. This material may
be distributed only subject to the terms and conditions set forth in the
Open Publication License, v1.0 or later (the latest version is presently
available at http://www.opencontent.org/openpub/).</p><p>Please freely copy and distribute (sell or give away) this document in any
format. It's requested that corrections and/or comments be forwarded to the
document maintainer. </p><p>It is also requested that if you publish this HOWTO in hardcopy that you
send the authors some samples for <span class="QUOTE">"review purposes"</span> :-) </p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.INTRO.PRIOR">2.2. Prior knowledge</a></h2><p>As the title implies, this is the <span class="QUOTE">"Advanced"</span> HOWTO.
While by no means rocket science, some prior knowledge is assumed. </p><p>Here are some other references which might help teach you more:
</p><p></p><div class="VARIABLELIST"><dl><dt><a href="http://netfilter.samba.org/unreliable-guides/networking-concepts-HOWTO/index.html" target="_top">      Rusty Russell's networking-concepts-HOWTO</a></dt><dd><p>Very nice introduction, explaining what a network is, and how it is
    connected to other networks.
    </p></dd><dt>Linux Networking-HOWTO (Previously the Net-3 HOWTO)</dt><dd><p>Great stuff, although very verbose. It teaches you a lot of stuff 
    that's already configured if you are able to connect to the Internet. 
    Should be located in <tt class="FILENAME">/usr/doc/HOWTO/NET3-4-HOWTO.txt</tt>
 but can be also be found 
    <a href="http://www.linuxports.com/howto/networking" target="_top">online</a>.
    </p></dd></dl></div><p></p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.INTRO.LINUX">2.3. What Linux can do for you</a></h2><p>A small list of things that are possible:</p><p></p><ul><li><p>Throttle bandwidth for certain computers
  </p></li><li><p>Throttle bandwidth TO certain computers
  </p></li><li><p>Help you to fairly share your bandwidth
  </p></li><li><p>Protect your network from DoS attacks
  </p></li><li><p>Protect the Internet from your customers
  </p></li><li><p>Multiplex several servers as one, for load balancing or
  enhanced availability
  </p></li><li><p>Restrict access to your computers
  </p></li><li><p>Limit access of your users to other hosts
  </p></li><li><p>Do routing based on user id (yes!), MAC address, source IP
  address, port, type of service, time of day or content
  </p></li></ul><p>Currently, not many people are using these advanced features. This is for
several reasons. While the provided documentation is verbose, it is not very
hands-on. Traffic control is almost undocumented.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.INTRO.HOUSKEEPING">2.4. Housekeeping notes</a></h2><p>There are several things which should be noted about this document. While I
wrote most of it, I really don't want it to stay that way. I am a strong
believer in Open Source, so I encourage you to send feedback, updates,
patches etcetera. Do not hesitate to inform me of typos or plain old errors.
If my English sounds somewhat wooden, please realize that I'm not a native
speaker. Feel free to send suggestions.</p><p>If you feel you are better qualified to maintain a section, or think that
you can author and maintain new sections, you are welcome to do so. The SGML
of this HOWTO is available via GIT, I very much envision more people
working on it.</p><p>In aid of this, you will find lots of FIXME notices. Patches are always
welcome! Wherever you find a FIXME, you should know that you are treading in
unknown territory. This is not to say that there are no errors elsewhere,
but be extra careful. If you have validated something, please let us know so
we can remove the FIXME notice.</p><p>About this HOWTO, I will take some liberties along the road. For example, I
postulate a 10Mbit Internet connection, while I know full well that those
are not very common.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.INTRO.GIT">2.5. Access, GIT &amp; submitting updates</a></h2><p>The canonical location for the HOWTO is 
<a href="http://lartc.org/" target="_top">here</a>.</p><p>We now have anonymous GIT access available to the world at large. This is
good in a number of ways. You can easily upgrade to newer versions of this
HOWTO and submitting patches is no work at all.</p><p>Furthermore, it allows the authors to work on the source independently,
which is good too.</p><pre class="SCREEN">$ git clone git://repo.or.cz/lartc.git
or (if you're behind a firewall which only allows HTTP)
$ git clone http://repo.or.cz/r/lartc.git
Enter the checked out directory:
$ cd lartc.git
If you want to update your local copy, run
$ git pull</pre><p>If you made changes and want to contribute them, run <kbd class="USERINPUT">git diff</kbd>,
and mail the output to the LARTC mailing list <code class="EMAIL">&lt;<a href="mailto:lartc@vger.kernel.org">lartc@vger.kernel.org</a>&gt;</code>, we
can then integrate it easily. Thanks! Please make sure that you edit the
.db file, by the way, the other files are generated from that one. </p><p>A Makefile is supplied which should help you create postscript, dvi, pdf,
html and plain text. You may need to install 
<span class="APPLICATION">docbook</span>, <span class="APPLICATION">docbook-utils</span>,
<span class="APPLICATION">ghostscript</span> and <span class="APPLICATION">tetex</span> 
to get all formats.</p><p>Be careful not to edit 2.4routing.sgml! It contains an older version of the
HOWTO. The right file is lartc.db.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.INTRO.MLIST">2.6. Mailing list</a></h2><p>The authors receive an increasing amount of mail about this HOWTO. Because
of the clear interest of the community, it has been decided to start a
mailinglist where people can talk to each other about Advanced Routing and
Traffic Control. You can subscribe to the list
<a href="http://mailman.ds9a.nl/mailman/listinfo/lartc" target="_top">here</a>.</p><p>It should be pointed out that the authors are very hesitant of answering
questions not asked on the list. We would like the archive of the list to
become some kind of knowledge base. If you have a question, please search
the archive, and then post to the mailinglist.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.INTRO.LAYOUT">2.7. Layout of this document</a></h2><p>We will be doing interesting stuff almost immediately, which also means that
there will initially be parts that are explained incompletely or are not
perfect. Please gloss over these parts and assume that all will become clear.</p><p>Routing and filtering are two distinct things. Filtering is documented very
well by Rusty's HOWTOs, available here:</p><p></p><ul><li><p><a href="http://netfilter.samba.org/unreliable-guides/" target="_top">    Rusty's Remarkably Unreliable Guides</a>
  </p></li></ul><p>We will be focusing mostly on what is possible by combining netfilter
and iproute2.</p></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.IPROUTE2"></a>Chapter 3. Introduction to iproute2</h1><div class="SECT1"><h2 class="SECT1"><a name="LARTC.IPROUTE2.WHY">3.1. Why iproute2?</a></h2><p>Most Linux distributions, and most UNIX's, currently use the 
venerable <b class="COMMAND">arp</b>, <b class="COMMAND">ifconfig</b> and 
<b class="COMMAND">route</b> commands.
While these tools work, they show some unexpected behaviour under Linux 2.2 
and up.
For example, GRE tunnels are an integral part of routing these days, but 
require completely different tools.</p><p>With <span class="APPLICATION">iproute2</span>, tunnels are an integral part of 
the tool set.</p><p>The 2.2 and above Linux kernels include a completely redesigned network
subsystem. This new networking code brings Linux performance and a feature
set with little competition in the general OS arena. In fact, the new
routing, filtering, and classifying code is more featureful than the one
provided by many dedicated routers and firewalls and traffic shaping
products.</p><p>As new networking concepts have been invented, people have found ways to
plaster them on top of the existing framework in existing OSes. This
constant layering of cruft has lead to networking code that is filled with
strange behaviour, much like most human languages. In the past, Linux
emulated SunOS's handling of many of these things, which was not ideal.  </p><p>This new framework makes it possible to clearly express features
previously beyond Linux's reach.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.IPROUTE2.TOUR">3.2. iproute2 tour</a></h2><p>Linux has a sophisticated system for bandwidth provisioning called Traffic
Control. This system supports various method for classifying, prioritizing,
sharing, and limiting both inbound and outbound traffic.</p><p>We'll start off with a tiny tour of iproute2 possibilities.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.IPROUTE2.PACKAGE">3.3. Prerequisites</a></h2><p>You should make sure that you have the userland tools installed. This
package is called 'iproute' on both RedHat and Debian, and may otherwise be
found at <tt class="FILENAME">ftp://ftp.inr.ac.ru/ip-routing/iproute2-2.2.4-now-ss??????.tar.gz"</tt>. </p><p>You can also try 
<a href="ftp://ftp.inr.ac.ru/ip-routing/iproute2-current.tar.gz" target="_top">here</a> 
for the latest version.</p><p>Some parts of iproute require you to have certain kernel options enabled. It
should also be noted that all releases of RedHat up to and including 6.2
come without most of the traffic control features in the default kernel. </p><p>RedHat 7.2 has everything in by default.</p><p>Also make sure that you have netlink support, should you choose to roll your
own kernel. Iproute2 needs it.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.IPROUTE2.EXPLORE">3.4. Exploring your current configuration</a></h2><p>This may come as a surprise, but iproute2 is already configured! The current
commands <b class="COMMAND">ifconfig</b> and <b class="COMMAND">route</b> are already using the advanced
syscalls, but mostly with very default (ie. boring) settings.</p><p>The <b class="COMMAND">ip</b> tool is central, and we'll ask it to display our interfaces
for us.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN195">3.4.1. <b class="COMMAND">ip</b> shows us our links</a></h3><pre class="SCREEN">[ahu@home ahu]$ ip link list
1: lo: &lt;LOOPBACK,UP&gt; mtu 3924 qdisc noqueue 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: dummy: &lt;BROADCAST,NOARP&gt; mtu 1500 qdisc noop 
    link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
3: eth0: &lt;BROADCAST,MULTICAST,PROMISC,UP&gt; mtu 1400 qdisc pfifo_fast qlen 100
    link/ether 48:54:e8:2a:47:16 brd ff:ff:ff:ff:ff:ff
4: eth1: &lt;BROADCAST,MULTICAST,PROMISC,UP&gt; mtu 1500 qdisc pfifo_fast qlen 100
    link/ether 00:e0:4c:39:24:78 brd ff:ff:ff:ff:ff:ff
3764: ppp0: &lt;POINTOPOINT,MULTICAST,NOARP,UP&gt; mtu 1492 qdisc pfifo_fast qlen 10
    link/ppp </pre><p>Your mileage may vary, but this is what it shows on my NAT router at
home. I'll only explain part of the output as not everything is directly
relevant.</p><p>We first see the loopback interface. While your computer may function
somewhat without one, I'd advise against it. The MTU size (Maximum Transfer
Unit) is 3924 octets, and it is not supposed to queue. Which makes sense
because the loopback interface is a figment of your kernel's imagination.</p><p>I'll skip the dummy interface for now, and it may not be present on your
computer. Then there are my two physical network interfaces, one at the side
of my cable modem, the other one serves my home ethernet segment.
Furthermore, we see a ppp0 interface.</p><p>Note the absence of IP addresses. iproute disconnects the concept of 'links'
and 'IP addresses'. With IP aliasing, the concept of 'the' IP address had
become quite irrelevant anyhow. </p><p>It does show us the MAC addresses though, the hardware identifier of our
ethernet interfaces.</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN204">3.4.2. <b class="COMMAND">ip</b> shows us our IP addresses</a></h3><pre class="SCREEN">[ahu@home ahu]$ ip address show        
1: lo: &lt;LOOPBACK,UP&gt; mtu 3924 qdisc noqueue 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 brd 127.255.255.255 scope host lo
2: dummy: &lt;BROADCAST,NOARP&gt; mtu 1500 qdisc noop 
    link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
3: eth0: &lt;BROADCAST,MULTICAST,PROMISC,UP&gt; mtu 1400 qdisc pfifo_fast qlen 100
    link/ether 48:54:e8:2a:47:16 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.1/8 brd 10.255.255.255 scope global eth0
4: eth1: &lt;BROADCAST,MULTICAST,PROMISC,UP&gt; mtu 1500 qdisc pfifo_fast qlen 100
    link/ether 00:e0:4c:39:24:78 brd ff:ff:ff:ff:ff:ff
3764: ppp0: &lt;POINTOPOINT,MULTICAST,NOARP,UP&gt; mtu 1492 qdisc pfifo_fast qlen 10
    link/ppp 
    inet 212.64.94.251 peer 212.64.94.1/32 scope global ppp0</pre><p>This contains more information. It shows all our addresses, and to which
cards they belong. 'inet' stands for Internet (IPv4). There are lots of other
address families, but these don't concern us right now.</p><p>Let's examine eth0 somewhat closer. It says that it is related to the inet
address '10.0.0.1/8'. What does this mean? The /8 stands for the number of
bits that are in the Network Address. There are 32 bits, so we have 24 bits
left that are part of our network. The first 8 bits of 10.0.0.1 correspond
to 10.0.0.0, our Network Address, and our netmask is 255.0.0.0.</p><p>The other bits are connected to this interface, so 10.250.3.13 is directly
available on eth0, as is 10.0.0.1 for example. </p><p>With ppp0, the same concept goes, though the numbers are different. Its
address is 212.64.94.251, without a subnet mask. This means that we have a
point-to-point connection and that every address, with the exception of
212.64.94.251, is remote. There is more information, however. It tells us
that on the other side of the link there is, yet again, only one address,
212.64.94.1. The /32 tells us that there are no 'network bits'.</p><p>It is absolutely vital that you grasp these concepts. Refer to the
documentation mentioned at the beginning of this HOWTO if you have trouble.</p><p>You may also note 'qdisc', which stands for Queueing Discipline. This will
become vital later on. </p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN214">3.4.3. <b class="COMMAND">ip</b> shows us our routes</a></h3><p>Well, we now know how to find 10.x.y.z addresses, and we are able to reach
212.64.94.1. This is not enough however, so we need instructions on how to
reach the world. The Internet is available via our ppp connection, and it
appears that 212.64.94.1 is willing to spread our packets around the
world, and deliver results back to us.</p><pre class="SCREEN">[ahu@home ahu]$ ip route show
212.64.94.1 dev ppp0  proto kernel  scope link  src 212.64.94.251 
10.0.0.0/8 dev eth0  proto kernel  scope link  src 10.0.0.1 
127.0.0.0/8 dev lo  scope link 
default via 212.64.94.1 dev ppp0 </pre><p>This is pretty much self explanatory. The first 3 lines of output explicitly
state what was already implied by <b class="COMMAND">ip address show</b>, the last line
tells us that the rest of the world can be found via 212.64.94.1, our
default gateway. We can see that it is a gateway because of the word
via, which tells us that we need to send packets to 212.64.94.1, and that it
will take care of things.</p><p>For reference, this is what the old <b class="COMMAND">route</b> utility shows us:</p><pre class="SCREEN">[ahu@home ahu]$ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use
Iface
212.64.94.1     0.0.0.0         255.255.255.255 UH    0      0        0 ppp0
10.0.0.0        0.0.0.0         255.0.0.0       U     0      0        0 eth0
127.0.0.0       0.0.0.0         255.0.0.0       U     0      0        0 lo
0.0.0.0         212.64.94.1     0.0.0.0         UG    0      0        0 ppp0</pre></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.IPROUTE2.ARP">3.5. ARP</a></h2><p>ARP is the Address Resolution Protocol as described in
<a href="http://www.faqs.org/rfcs/rfc826.html" target="_top">RFC 826</a>.
ARP is used by a networked machine to resolve the hardware location/address of
another machine on the same
local network.  Machines on the Internet are generally known by their names
which resolve to IP
addresses.  This is how a machine on the foo.com network is able to communicate
with another machine which is on the bar.net network.  An IP address, though,
cannot tell you the physical location of a machine.  This is where ARP comes
into the picture.</p><p>Let's take a very simple example.  Suppose I have a network composed of several
machines.  Two of the machines which are currently on my network are foo
with an IP address of 10.0.0.1 and bar with an IP address of 10.0.0.2.
Now foo wants to ping bar to see that he is alive, but alas, foo has no idea
where bar is.  So when foo decides to ping bar he will need to send
out an ARP request.
This ARP request is akin to foo shouting out on the network "Bar (10.0.0.2)!
Where are you?"  As a result of this every machine on the network will hear
foo shouting, but only bar (10.0.0.2) will respond.  Bar will then send an
ARP reply directly back to foo which is akin
bar saying,
"Foo (10.0.0.1) I am here at 00:60:94:E9:08:12."  After this simple transaction
that's used to locate his friend on the network, foo is able to communicate
with bar until he (his arp cache) forgets where bar is (typically after
15 minutes on Unix).</p><p>Now let's see how this works.
You can view your machines current arp/neighbor cache/table like so:</p><pre class="SCREEN">[root@espa041 /home/src/iputils]# ip neigh show
9.3.76.42 dev eth0 lladdr 00:60:08:3f:e9:f9 nud reachable
9.3.76.1 dev eth0 lladdr 00:06:29:21:73:c8 nud reachable</pre><p>As you can see my machine espa041 (9.3.76.41) knows where to find espa042 
(9.3.76.42) and
espagate (9.3.76.1).  Now let's add another machine to the arp cache.</p><pre class="SCREEN">[root@espa041 /home/paulsch/.gnome-desktop]# ping -c 1 espa043
PING espa043.austin.ibm.com (9.3.76.43) from 9.3.76.41 : 56(84) bytes of data.
64 bytes from 9.3.76.43: icmp_seq=0 ttl=255 time=0.9 ms

--- espa043.austin.ibm.com ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 0.9/0.9/0.9 ms

[root@espa041 /home/src/iputils]# ip neigh show
9.3.76.43 dev eth0 lladdr 00:06:29:21:80:20 nud reachable
9.3.76.42 dev eth0 lladdr 00:60:08:3f:e9:f9 nud reachable
9.3.76.1 dev eth0 lladdr 00:06:29:21:73:c8 nud reachable</pre><p>As a result of espa041 trying to contact espa043, espa043's hardware
address/location has now been added to the arp/neighbor cache.
So until the entry for
espa043 times out (as a result of no communication between the two) espa041
knows where to find espa043 and has no need to send an ARP request.</p><p>Now let's delete espa043 from our arp cache:</p><pre class="SCREEN">[root@espa041 /home/src/iputils]# ip neigh delete 9.3.76.43 dev eth0
[root@espa041 /home/src/iputils]# ip neigh show
9.3.76.43 dev eth0  nud failed
9.3.76.42 dev eth0 lladdr 00:60:08:3f:e9:f9 nud reachable
9.3.76.1 dev eth0 lladdr 00:06:29:21:73:c8 nud stale</pre><p>Now espa041 has again forgotten where to find espa043 and will need to send
another ARP request the next time he needs to communicate with espa043.
You can also see from the above output that espagate (9.3.76.1) has been
changed to the "stale" state.  This means that the location shown is still
valid, but it will have to be confirmed at the first transaction to that
machine.</p></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.RPDB"></a>Chapter 4. Rules - routing policy database</h1><p>If you have a large router, you may well cater for the needs of different
people, who should be served differently. The routing policy database allows
you to do this by having multiple sets of routing tables. </p><p>If you want to use this feature, make sure that your kernel is compiled with
the "IP: advanced router" and "IP: policy routing" features.</p><p>When the kernel needs to make a routing decision, it finds out which table
needs to be consulted. By default, there are three tables. The old 'route'
tool modifies the main and local tables, as does the ip tool (by default).</p><p>The default rules:</p><pre class="SCREEN">[ahu@home ahu]$ ip rule list
0:	from all lookup local 
32766:	from all lookup main 
32767:	from all lookup default</pre><p>This lists the priority of all rules. We see that all rules apply to all
packets ('from all'). We've seen the 'main' table before, it is output by
<kbd class="USERINPUT">ip route ls</kbd>, but the 'local' and 'default' table are new.</p><p>If we want to do fancy things, we generate rules which point to different
tables which allow us to override system wide routing rules.</p><p>For the exact semantics on what the kernel does when there are more matching
rules, see Alexey's ip-cref documentation. </p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.RPDB.SIMPLE">4.1. Simple source policy routing</a></h2><p>Let's take a real example once again, I have 2 (actually 3, about time I
returned them) cable modems, connected to a Linux NAT ('masquerading')
router. People living here pay me to use the Internet. Suppose one of my
house mates only visits hotmail and wants to pay less. This is fine with me,
but they'll end up using the low-end cable modem.</p><p>The 'fast' cable modem is known as 212.64.94.251 and is a PPP link to
212.64.94.1. The 'slow' cable modem is known by various ip addresses,
212.64.78.148 in this example and is a link to 195.96.98.253.</p><p>The local table:</p><pre class="SCREEN">[ahu@home ahu]$ ip route list table local
broadcast 127.255.255.255 dev lo  proto kernel  scope link  src 127.0.0.1 
local 10.0.0.1 dev eth0  proto kernel  scope host  src 10.0.0.1 
broadcast 10.0.0.0 dev eth0  proto kernel  scope link  src 10.0.0.1 
local 212.64.94.251 dev ppp0  proto kernel  scope host  src 212.64.94.251 
broadcast 10.255.255.255 dev eth0  proto kernel  scope link  src 10.0.0.1 
broadcast 127.0.0.0 dev lo  proto kernel  scope link  src 127.0.0.1 
local 212.64.78.148 dev ppp2  proto kernel  scope host  src 212.64.78.148 
local 127.0.0.1 dev lo  proto kernel  scope host  src 127.0.0.1 
local 127.0.0.0/8 dev lo  proto kernel  scope host  src 127.0.0.1 </pre><p>Lots of obvious things, but things that need to be specified somewhere.
Well, here they are. The default table is empty.</p><p>Let's view the 'main' table:</p><pre class="SCREEN">[ahu@home ahu]$ ip route list table main 
195.96.98.253 dev ppp2  proto kernel  scope link  src 212.64.78.148 
212.64.94.1 dev ppp0  proto kernel  scope link  src 212.64.94.251 
10.0.0.0/8 dev eth0  proto kernel  scope link  src 10.0.0.1 
127.0.0.0/8 dev lo  scope link 
default via 212.64.94.1 dev ppp0 </pre><p>We now generate a new rule which we call 'John', for our hypothetical
house mate. Although we can work with pure numbers, it's far easier if we add
our tables to /etc/iproute2/rt_tables.</p><pre class="SCREEN"># echo 200 John &gt;&gt; /etc/iproute2/rt_tables
# ip rule add from 10.0.0.10 table John
# ip rule ls
0:	from all lookup local 
32765:	from 10.0.0.10 lookup John
32766:	from all lookup main 
32767:	from all lookup default</pre><p>Now all that is left is to generate John's table, and flush the route cache:</p><pre class="SCREEN"># ip route add default via 195.96.98.253 dev ppp2 table John
# ip route flush cache</pre><p>And we are done. It is left as an exercise for the reader to implement this
in ip-up.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.RPDB.MULTIPLE-LINKS">4.2. Routing for multiple uplinks/providers</a></h2><p>A common configuration is the following, in which there are two providers
that connect a local network (or even a single machine) to the big Internet.

</p><pre class="SCREEN">                                                                 ________
                                          +------------+        /
                                          |            |       |
                            +-------------+ Provider 1 +-------
        __                  |             |            |     /
    ___/  \_         +------+-------+     +------------+    |
  _/        \__      |     if1      |                      /
 /             \     |              |                      |
| Local network -----+ Linux router |                      |     Internet
 \_           __/    |              |                      |
   \__     __/       |     if2      |                      \
      \___/          +------+-------+     +------------+    |
                            |             |            |     \
                            +-------------+ Provider 2 +-------
                                          |            |       |
                                          +------------+        \________</pre><p></p><p>There are usually two questions given this setup.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN267">4.2.1. Split access</a></h3><p>	  The first is how to route answers to packets coming in over a
	  particular provider, say Provider 1, back out again over that same provider.
	</p><p>	  Let us first set some symbolical names. Let <b class="COMMAND">$IF1</b> be the name of the
	  first interface (if1 in the picture above) and <b class="COMMAND">$IF2</b> the name of the
	  second interface. Then let <b class="COMMAND">$IP1</b> be the IP address associated with
	  <b class="COMMAND">$IF1</b> and <b class="COMMAND">$IP2</b> the IP address associated with
	  <b class="COMMAND">$IF2</b>. Next, let <b class="COMMAND">$P1</b> be the IP address of the gateway at
	  Provider 1, and <b class="COMMAND">$P2</b> the IP address of the gateway at provider 2.
	  Finally, let <b class="COMMAND">$P1_NET</b> be the IP network <b class="COMMAND">$P1</b> is in,
	  and <b class="COMMAND">$P2_NET</b> the IP network <b class="COMMAND">$P2</b> is in.
	</p><p>	  One creates two additional routing tables, say <b class="COMMAND">T1</b> and <b class="COMMAND">T2</b>.
	  These are added in /etc/iproute2/rt_tables. Then you set up routing in
	  these tables as follows:
	</p><p>	</p><pre class="SCREEN">	  ip route add $P1_NET dev $IF1 src $IP1 table T1
	  ip route add default via $P1 table T1
	  ip route add $P2_NET dev $IF2 src $IP2 table T2
	  ip route add default via $P2 table T2
	</pre>
	  
	  Nothing spectacular, just build a route to the gateway and build a
	  default route via that gateway, as you would do in the case of a single
	  upstream provider, but put the routes in a separate table per provider.
	  Note that the network route suffices, as it tells you how to find any host
	  in that network, which includes the gateway, as specified above.
	<p></p><p>	  Next you set up the main routing table. It is a good idea to route
	  things to the direct neighbour through the interface connected to that
	  neighbour. Note the `src' arguments, they make sure the right outgoing IP
	  address is chosen.

	  </p><pre class="SCREEN">	    ip route add $P1_NET dev $IF1 src $IP1
	    ip route add $P2_NET dev $IF2 src $IP2
	  </pre>

	  Then, your preference for default route:
	  
	  <pre class="SCREEN">	    ip route add default via $P1
	  </pre>

	  Next, you set up the routing rules. These actually choose what routing table
	  to route with. You want to make sure that you route out a given
	  interface if you already have the corresponding source address:
	  
	  <pre class="SCREEN">	    ip rule add from $IP1 table T1
	    ip rule add from $IP2 table T2
	  </pre>

	  This set of commands makes sure all answers to traffic coming in on a
	  particular interface get answered from that interface.
	<p></p><p>	</p><div class="WARNING"><p></p><table class="WARNING" width="100%" border="0"><tbody><tr><td width="25" align="CENTER" valign="TOP"></td><td align="LEFT" valign="TOP"><p>Reader Rod Roark notes: 'If $P0_NET is the local network and $IF0 is its interface,
the following additional entries are desirable:
</p><pre class="SCREEN">ip route add $P0_NET     dev $IF0 table T1
ip route add $P2_NET     dev $IF2 table T1
ip route add 127.0.0.0/8 dev lo   table T1
ip route add $P0_NET     dev $IF0 table T2
ip route add $P1_NET     dev $IF1 table T2
ip route add 127.0.0.0/8 dev lo   table T2                                      </pre>'<p></p></td></tr></tbody></table></div><p></p><p>	  Now, this is just the very basic setup. It will work for all processes
	  running on the router itself, and for the local network, if it is
	  masqueraded. If it is not, then you either have IP space from both providers
	  or you are going to want to masquerade to one of the two providers. In both
	  cases you will want to add rules selecting which provider to route out from
	  based on the IP address of the machine in the local network.
 	</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN297">4.2.2. Load balancing</a></h3><p>	  The second question is how to balance traffic going out over the two providers.
	  This is actually not hard if you already have set up split access as above.
	  </p><p>	  Instead of choosing one of the two providers as your default route,
	  you now set up the default route to be a multipath route. In the default
	  kernel this will balance routes over the two providers. It is done
	  as follows (once more building on the example in the section on
	  split-access):

	  </p><pre class="SCREEN">	    ip route add default scope global nexthop via $P1 dev $IF1 weight 1 \
	    nexthop via $P2 dev $IF2 weight 1
	  </pre>

	  This will balance the routes over both providers. The <b class="COMMAND">weight</b>
	  parameters can be tweaked to favor one provider over the other.
	<p></p><p>	  Note that balancing will not be perfect, as it is route based, and routes
	  are cached. This means that routes to often-used sites will always
	  be over the same provider.
	</p><p>	  Furthermore, if you really want to do this, you probably also want to look
	  at Julian Anastasov's patches at <a href="http://www.ssi.bg/~ja/#routes" target="_top">http://www.ssi.bg/~ja/#routes 
	    </a>, Julian's route patch page. They will make things nicer to work with.
	</p></div></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.TUNNEL"></a>Chapter 5. GRE and other tunnels</h1><p>There
 are 3 kinds of tunnels in Linux. There's IP in IP tunneling, GRE 
tunneling and tunnels that live outside the kernel (like, for example 
PPTP). </p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.TUNNEL.REMARKS">5.1. A few general remarks about tunnels:</a></h2><p>Tunnels can be used to do some very unusual and very cool stuff. They can
also make things go horribly wrong when you don't configure them right.
Don't point your default route to a tunnel device unless you know
<span class="emphasis"><i class="EMPHASIS">EXACTLY</i></span> what you are doing :-). Furthermore, tunneling increases
overhead, because it needs an extra set of IP headers. Typically this is 20
bytes per packet, so if the normal packet size (MTU) on a network is 1500
bytes, a packet that is sent through a tunnel can only be 1480 bytes big.
This is not necessarily a problem, but be sure to read up on IP packet
fragmentation/reassembly when you plan to connect large networks with
tunnels. Oh, and of course, the fastest way to dig a tunnel is to dig at
both sides.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.TUNNEL.IP-IP">5.2. IP in IP tunneling</a></h2><p>This kind of tunneling has been available in Linux for a long time. It requires 2 kernel modules,
ipip.o and new_tunnel.o.</p><p>Let's say you have 3 networks: Internal networks A and B, and intermediate network C (or let's say, Internet). 
So we have network A:</p><pre class="SCREEN">network 10.0.1.0
netmask 255.255.255.0
router  10.0.1.1</pre><p>The router has address 172.16.17.18 on network C.</p><p>and network B:</p><pre class="SCREEN">network 10.0.2.0
netmask 255.255.255.0
router  10.0.2.1</pre><p>The router has address 172.19.20.21 on network C.</p><p>As far as network C is concerned, we assume that it will pass any packet sent
from A to B and vice versa. You might even use the Internet for this.</p><p>Here's what you do:</p><p>First, make sure the modules are installed:</p><pre class="SCREEN">insmod ipip.o
insmod new_tunnel.o</pre><p>Then, on the router of network A, you do the following:</p><pre class="SCREEN">ifconfig tunl0 10.0.1.1 pointopoint 172.19.20.21
route add -net 10.0.2.0 netmask 255.255.255.0 dev tunl0</pre><p>And on the router of network B:</p><pre class="SCREEN">ifconfig tunl0 10.0.2.1 pointopoint 172.16.17.18
route add -net 10.0.1.0 netmask 255.255.255.0 dev tunl0</pre><p>And if you're finished with your tunnel:</p><pre class="SCREEN">ifconfig tunl0 down</pre><p>Presto,
 you're done. You can't forward broadcast or IPv6 traffic through
an IP-in-IP tunnel, though. You just connect 2 IPv4 networks that 
normally wouldn't be able to talk to each other, that's all. As far as 
compatibility goes, this code has been around a long time, so it's 
compatible all the way back to 1.3 kernels. Linux IP-in-IP tunneling 
doesn't work with other Operating Systems or routers, as far as I know. 
It's simple, it works. Use it if you have to, otherwise use GRE.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.TUNNEL.GRE">5.3. GRE tunneling</a></h2><p>GRE is a tunneling protocol that was originally developed by Cisco, and it
can do a few more things than IP-in-IP tunneling. For example, you can also
transport multicast traffic and IPv6 through a GRE tunnel.</p><p>In Linux, you'll need the ip_gre.o module.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN337">5.3.1. IPv4 Tunneling</a></h3><p>Let's do IPv4 tunneling first:</p><p>Let's say you have 3 networks: Internal networks A and B, and intermediate network C (or let's say, Internet). </p><p>So we have network A:

</p><pre class="SCREEN">network 10.0.1.0
netmask 255.255.255.0
router  10.0.1.1</pre>

The router has address 172.16.17.18 on network C.
Let's call this network neta (ok, hardly original)<p></p><p>and network B:

</p><pre class="SCREEN">network 10.0.2.0
netmask 255.255.255.0
router  10.0.2.1</pre>

The router has address 172.19.20.21 on network C.
Let's call this network netb (still not original)<p></p><p>As far as network C is concerned, we assume that it will pass any packet sent
from A to B and vice versa. How and why, we do not care.</p><p>On the router of network A, you do the following:</p><pre class="SCREEN">ip tunnel add netb mode gre remote 172.19.20.21 local 172.16.17.18 ttl 255
ip link set netb up
ip addr add 10.0.1.1 dev netb
ip route add 10.0.2.0/24 dev netb</pre><p>Let's discuss this for a bit. In line 1, we added a tunnel device, and
called it netb (which is kind of obvious because that's where we want it to
go). Furthermore we told it to use the GRE protocol (mode gre), that the
remote address is 172.19.20.21 (the router at the other end), that our
tunneling packets should originate from 172.16.17.18 (which allows your
router to have several IP addresses on network C and let you decide which
one to use for tunneling) and that the TTL field of the packet should be set
to 255 (ttl 255).</p><p>The second line enables the device.</p><p>In the third line we gave the newly born interface netb the address
10.0.1.1. This is OK for smaller networks, but when you're starting up a
mining expedition (LOTS of tunnels), you might want to consider using
another IP range for tunneling interfaces (in this example, you could use
10.0.3.0).</p><p>In the fourth line we set the route for network B. Note
 the different notation for the netmask. If you're not familiar with 
this notation, here's how it works: you write out the netmask in binary 
form, and you count all the ones. If you don't know how to do that, just
 remember that 255.0.0.0 is /8, 255.255.0.0 is /16 and 255.255.255.0 is 
/24. Oh, and 255.255.254.0 is /23, in case you were wondering.</p><p>But enough about this, let's go on with the router of network B.

</p><pre class="SCREEN">ip tunnel add neta mode gre remote 172.16.17.18 local 172.19.20.21 ttl 255
ip link set neta up
ip addr add 10.0.2.1 dev neta
ip route add 10.0.1.0/24 dev neta</pre>

And when you want to remove the tunnel on router A:

<pre class="SCREEN">ip link set netb down
ip tunnel del netb</pre>

Of course, you can replace netb with neta for router B.<p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN355">5.3.2. IPv6 Tunneling</a></h3><p>See Section 6 for a short bit about IPv6 Addresses.</p><p>On with the tunnels.</p><p>Let's assume that you have the following IPv6 network, and you want to connect it to 6bone, or a friend.</p><p></p><pre class="SCREEN">Network 3ffe:406:5:1:5:a:2:1/96</pre>

Your IPv4 address is 172.16.17.18, and the 6bone router has IPv4 address 172.22.23.24. <p></p><p></p><pre class="SCREEN">ip tunnel add sixbone mode sit remote 172.22.23.24 local 172.16.17.18 ttl 255
ip link set sixbone up
ip addr add 3ffe:406:5:1:5:a:2:1/96 dev sixbone
ip route add 3ffe::/15 dev sixbone </pre><p></p><p>Let's discuss this. 
In the first line, we created a tunnel device called sixbone. We gave it
 mode sit (which is IPv6 in IPv4 tunneling) and told it where to go to 
(remote) and where to come from (local). TTL is set to maximum, 255. 
Next, we made the device active (up). After that, we added our own 
network address, and set a route for 3ffe::/15 (which is currently all 
of 6bone) through the tunnel.</p><p>GRE tunnels are currently the 
preferred type of tunneling. It's a standard that is also widely adopted
 outside the Linux community and therefore a Good Thing.</p></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.TUNNEL.USERLAND">5.4. Userland tunnels</a></h2><p>There
 are literally dozens of implementations of tunneling outside the 
kernel. Best known are of course PPP and PPTP, but there are lots more 
(some proprietary, some secure, some that don't even use IP) and that is
 really beyond the scope of this HOWTO.</p></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.IPV6-TUNNEL"></a>Chapter 6. IPv6 tunneling with Cisco and/or 6bone</h1><p>By Marco Davids &lt;marco@sara.nl&gt;</p><p>NOTE to maintainer:</p><p>As far as I am concerned, this IPv6-IPv4 tunneling is not per definition
GRE tunneling. You could tunnel IPv6 over IPv4 by means of GRE tunnel devices
(GRE tunnels ANY to IPv4), but the device used here ("sit") only tunnels
IPv6 over IPv4 and is therefore something different.</p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.TUNNEL-IPV6.ADDRESSING">6.1. IPv6 Tunneling</a></h2><p>This is another application of the tunneling capabilities of Linux. It is
popular among the IPv6 early adopters, or pioneers if you like.
The 'hands-on' example described below is certainly not the only way
to do IPv6 tunneling. However, it is the method that is often used to tunnel
between Linux and a Cisco IPv6 capable router and experience tells us that
this is just the thing many people are after. Ten to one this applies to
you too ;-)</p><p>A short bit about IPv6 addresses:</p><p>IPv6 addresses are, compared to IPv4 addresses, really big: 128 bits
against 32 bits. And this provides us just with the thing we need: many, many
IP-addresses: 340,282,266,920,938,463,463,374,607,431,768,211,465 to be
precise. Apart from this, IPv6 (or IPng, for IP Next Generation) is supposed
to provide for smaller routing tables on the Internet's backbone routers,
simpler configuration of equipment, better security at the IP level and
better support for QoS.</p><p>An example: 2002:836b:9820:0000:0000:0000:836b:9886</p><p>Writing down IPv6 addresses can be quite a burden. Therefore, to make
life easier there are some rules:</p><p></p><p></p><ul><li><p>Don't use leading zeroes. Same as in IPv4.</p></li><li><p>Use colons to separate every 16 bits or two bytes.</p></li><li><p>When you have lots of consecutive zeroes,
you can write this down as ::. You can only do this once in an
address and only for quantities of 16 bits, though.</p></li></ul><p></p><p>The address 2002:836b:9820:0000:0000:0000:836b:9886 can be written down
as 2002:836b:9820::836b:9886, which is somewhat friendlier.</p><p>Another example, the address 3ffe:0000:0000:0000:0000:0020:34A1:F32C can be
written down as 3ffe::20:34A1:F32C, which is a lot shorter.</p><p>IPv6 is intended to be the successor of the current IPv4. Because it
is relatively new technology, there is no worldwide native IPv6 network
yet. To be able to move forward swiftly, the 6bone was introduced. </p><p>Native IPv6 networks are connected to each other by encapsulating the IPv6
protocol in IPv4 packets and sending them over the existing IPv4 infrastructure
from one IPv6 site to another. </p><p>That is precisely where the tunnel steps in.</p><p>To be able to use IPv6, we should have a kernel that supports it. There
are many good documents on how to achieve this. But it all comes down to
a few steps:

</p><p></p><ul><li><p>Get yourself a recent Linux distribution, with suitable glibc.</p></li><li><p>Then get yourself an up-to-date kernel source.</p></li></ul>

If you are all set, then you can go ahead and compile an IPv6 capable
kernel:

<p></p><ul><li><p>Go to /usr/src/linux and type:</p></li><li><p>make menuconfig</p></li><li><p>Choose "Networking Options"</p></li><li><p>Select "The IPv6 protocol", "IPv6: enable EUI-64 token format", "IPv6:
disable provider based addresses"</p></li></ul>

HINT: Don't go for the 'module' option. Often this won't work well.<p></p><p>In other words, compile IPv6 as 'built-in' in your kernel.
You can then save your config like usual and go ahead with compiling
the kernel.</p><p>HINT: Before doing so, consider editing the Makefile:
EXTRAVERSION = -x ; --&gt; ; EXTRAVERSION = -x-IPv6</p><p>There is a lot of good documentation about compiling and installing
a kernel, however this document is about something else. If you run into
problems at this stage, go and look for documentation about compiling a
Linux kernel according to your own specifications.</p><p>The file /usr/src/linux/README might be a good start.
After you accomplished all this, and rebooted with your brand new kernel,
you might want to issue an '/sbin/ifconfig -a' and notice the brand 
new 'sit0-device'. SIT stands for Simple Internet Transition. You may give
yourself a compliment; you are now one major step closer to IP, the Next
Generation ;-)</p><p>Now on to the next step. You want to connect your host, or maybe even
your entire LAN to another IPv6 capable network. This might be the "6bone"
that is setup especially for this particular purpose.</p><p>Let's assume that you have the following IPv6 network: 3ffe:604:6:8::/64 and
you want to connect it to 6bone, or a friend. Please note that the /64
subnet notation works just like with regular IP addresses.</p><p>Your IPv4 address is 145.100.24.181 and the 6bone router has IPv4 address
145.100.1.5</p><pre class="SCREEN"># ip tunnel add sixbone mode sit remote 145.100.1.5 [local 145.100.24.181 ttl 255]
# ip link set sixbone up
# ip addr add 3FFE:604:6:7::2/126 dev sixbone
# ip route add 3ffe::0/16 dev sixbone</pre><p>Let's discuss this. In the first line, we created a tunnel device called
sixbone. We gave it mode sit (which is IPv6 in IPv4 tunneling) and told it
where to go to (remote) and where to come from (local). TTL is set to
maximum, 255. </p><p>Next, we made the device active (up). After that, we added our own network
address, and set a route for 3ffe::/15 (which is currently all of 6bone)
through the tunnel. If the particular machine you run this on is your IPv6
gateway, then consider adding the following lines:</p><pre class="SCREEN"># echo 1 &gt;/proc/sys/net/ipv6/conf/all/forwarding
# /usr/local/sbin/radvd</pre><p>The latter, radvd is -like zebra- a router advertisement daemon, to
support IPv6's autoconfiguration features. Search for it with your favourite
search-engine if you like.
You can check things like this:</p><pre class="SCREEN"># /sbin/ip -f inet6 addr</pre><p>If you happen to have radvd running on your IPv6 gateway and boot your
IPv6 capable Linux on a machine on your local LAN, you would be able to
enjoy the benefits of IPv6 autoconfiguration:</p><pre class="SCREEN"># /sbin/ip -f inet6 addr
1: lo: &lt;LOOPBACK,UP&gt; mtu 3924 qdisc noqueue inet6 ::1/128 scope host

3: eth0: &lt;BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc pfifo_fast qlen 100
inet6 3ffe:604:6:8:5054:4cff:fe01:e3d6/64 scope global dynamic
valid_lft forever preferred_lft 604646sec inet6 fe80::5054:4cff:fe01:e3d6/10 
scope link</pre><p>You could go ahead and configure your bind for IPv6 addresses. The A
type has an equivalent for IPv6: AAAA. The in-addr.arpa's equivalent is:
ip6.int. There's a lot of information available on this topic.</p><p>There is an increasing number of IPv6-aware applications available,
including secure shell, telnet, inetd, Mozilla the browser, Apache the
webserver and a lot of others. But this is all outside the scope of this
Routing document ;-)</p><p>On the Cisco side the configuration would be something like this:

</p><pre class="SCREEN">!
interface Tunnel1
description IPv6 tunnel
no ip address
no ip directed-broadcast
ipv6 address 3FFE:604:6:7::1/126
tunnel source Serial0
tunnel destination 145.100.24.181
tunnel mode ipv6ip
!
ipv6 route 3FFE:604:6:8::/64 Tunnel1</pre>

But if you don't have a Cisco at your disposal, try one of the many
IPv6 tunnel brokers available on the Internet. They are willing to configure
their Cisco with an extra tunnel for you. Mostly by means of a friendly
web interface. Search for "ipv6 tunnel broker" on your favourite search engine.<p></p></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.IPSEC"></a>Chapter 7. IPSEC: secure IP over the Internet</h1><p>      There are two kinds of IPSEC available for Linux these days. For 2.2
      and 2.4, there is FreeS/WAN, which was the first major implementation. They

      have <a href="http://www.freeswan.org/" target="_top">an official site</a> and <a href="http://www.freeswan.ca/" target="_top">	an unofficial one</a> that is actually maintained. FreeS/WAN has traditionally not been merged with
      the mainline kernel for a number of reasons. Most often mentioned are 'political' issues with Americans
      working on crypto tainting its exportability. Furthermore, it does not integrate too well with the Linux kernel,
      leading it to be a bad candidate for actual merging. 
    </p><p>      Additionally, <a href="http://www.edlug.ed.ac.uk/archive/Sep2002/msg00244.html" target="_top">many</a> parties <a href="http://lists.freeswan.org/pipermail/design/2002-November/003901.html" target="_top">have voiced
worries</a> about the quality of the code. To setup FreeS/WAN, a lot of
<a href="http://www.freeswan.ca/docs/freeswan-1.99/doc/index.html" target="_top">documentation</a>
is <a href="http://www.freeswan.org/doc.html" target="_top">available</a>.
    </p><p>      As of Linux 2.5.47, there is a native IPSEC implementation in the kernel. It was written by Alexey Kuznetsov and
      Dave Miller, inspired by the work of the USAGI IPv6 group. With its merge, James Morris' CrypoAPI also became 
      part of the kernel - it does the actual crypting.
    </p><p>      This HOWTO will only document the 2.5+ version of 
IPSEC. FreeS/WAN is recommended for Linux 2.4 users for now, but be 
aware
      that its configuration will differ from the native IPSEC. In 
related
news, there are now <a href="http://gondor.apana.org.au/~herbert/freeswan/" target="_top">patches</a> to make the FreeS/WAN userspace code work with
the native Linux IPSEC.
    </p><p>	As of 2.5.49, IPSEC works without further patches.
	</p><p>      </p><div class="NOTE"><p></p><table class="NOTE" width="100%" border="0"><tbody><tr><td width="25" align="CENTER" valign="TOP"></td><td align="LEFT" valign="TOP"><p>	  Userspace tools appear to be available <a href="http://sourceforge.net/projects/ipsec-tools" target="_top">here</a>.
There are multiple programs available, the one linked here is based on
Racoon. 
	</p><p>	When compiling your kernel, be sure to turn on 'PF_KEY', 'AH', 'ESP' and
everything in the CryptoAPI!
	</p></td></tr></tbody></table></div>
      <div class="WARNING"><p></p><table class="WARNING" width="100%" border="0"><tbody><tr><td width="25" align="CENTER" valign="TOP"></td><td align="LEFT" valign="TOP"><p>	  The author of this chapter is a complete IPSEC nitwit! If you find the inevitable mistakes, please email
	  bert hubert <code class="EMAIL">&lt;<a href="mailto:ahu@ds9a.nl">ahu@ds9a.nl</a>&gt;</code>. 
	</p></td></tr></tbody></table></div>
    <p></p><p>      First, we'll show how to manually setup secure communication between
      two hosts. A large part of this process can also be automated, but
here we'll do it by hand so as to acquaint ourselves with what is going on
'under the hood'. 
    </p><p>	Feel free to skip the following section if you are only interested
in automatic keying but be aware that some understanding of manual keying is
useful. 
    </p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.IPSEC.INTRO">7.1. Intro with Manual Keying</a></h2><p>	IPSEC is a complicated subject. A lot of information is available online, this HOWTO will concentrate on getting you
	up and running and explaining the basic principles. All examples are
based on Racoon as found on the link above.
      </p><p>	</p><div class="NOTE"><p></p><table class="NOTE" width="100%" border="0"><tbody><tr><td width="25" align="CENTER" valign="TOP"></td><td align="LEFT" valign="TOP"><p>
	    Many iptables configurations drop IPSEC packets! To pass IPSEC, 
use: 'iptables -A xxx -p 50 -j ACCEPT' and 'iptables -A xxx -p 51 -j 
ACCEPT'
	  </p></td></tr></tbody></table></div>
      <p></p><p>	IPSEC offers a secure version of the Internet Protocol.
 Security in this context means two different things: encryption and 
authentication. 
	A naive vision of security offers only encryption but it can easily be 
shown that is insufficient - you may be communicating encyphered,
	but no guarantee is offered that the remote party is the one you expect
 it to be.
      </p><p>	IPSEC supports 'Encapsulated Security Payload' (ESP) for 
encryption and 'Authentication Header' (AH) for authenticating the 
remote partner.
	You can configure both of them, or decided to do only either.
      </p><p>	Both ESP and AH rely on security associations. A security 
association (SA) consists of a source, a destination and an instruction.
 A sample 
	authentication SA may look like this:
	</p><pre class="SCREEN">	  add 10.0.0.11 10.0.0.216 ah 15700 -A hmac-md5 "1234567890123456";
	</pre>
	This says 'traffic going from 10.0.0.11 to 10.0.0.216 that needs an AH 
can be signed using HMAC-MD5 using secret 1234567890123456'. This 
instruction
	is labelled with SPI ('Security Parameter Index') id '15700', more 
about that later.
	The interesting bit about SAs is that they are symmetrical. Both sides 
of a conversation share exactly the same SA, it is not mirrored on the
	other side. Do note however that there is no 'autoreverse' rule - this 
SA only describes a possible authentication from 10.0.0.11 to 
	10.0.0.216. For two-way traffic, two SAs are needed.
      <p></p><p>	A sample ESP SA:
	</p><pre class="SCREEN">add 10.0.0.11 10.0.0.216 esp 15701 -E 3des-cbc "123456789012123456789012";
	</pre>
	This says 'traffic going from 10.0.0.11 to 10.0.0.216 that needs 
encryption can be encyphered using 3des-cbc with key 
123456789012123456789012'. The
	SPI id is '15701'.
      <p></p><p>	So far, we've seen that SAs describe possible 
instructions, but do not in fact describe policy as to when these need 
to be used. In fact,
	there could be an arbitrary number of nearly identical SAs with only 
differing SPI ids. Incidentally, SPI stands for Security Parameter 
Index.
	To do actual crypto, we need to describe a policy. This policy can 
include things as 'use ipsec if available' or 'drop traffic unless we 
have ispec'.
      </p><p>	A typical simple Security Policy (SP) looks like this:
	</p><pre class="SCREEN">spdadd 10.0.0.216 10.0.0.11 any -P out ipsec
   esp/transport//require
   ah/transport//require;
	</pre>
	If entered on host 10.0.0.216, this means that all traffic going out to 10.0.0.11 must be encrypted 
	and be wrapped in an AH authenticating header. Note that this does not describe which SA is to be used,
	that is left as an exercise for the kernel to determine.
      <p></p><p>	In other words, a Security Policy specifies WHAT we want; a Security
Association describes HOW we want it. </p><p>	Outgoing packets are labelled with the SA SPI ('the how') which the
	kernel used for encryption and authentication so the remote can
	lookup the corresponding verification and decryption instruction.
      </p><p>	What follows is a very simple configuration for talking from host 10.0.0.216 to 10.0.0.11 using 
	encryption and authentication. Note that the reverse path is plaintext in this first version and that
	this configuration should not be deployed.
      </p><p>	On host 10.0.0.216:
	</p><pre class="SCREEN">#!/sbin/setkey -f
add 10.0.0.216 10.0.0.11 ah 24500 -A hmac-md5 "1234567890123456";          
add 10.0.0.216 10.0.0.11 esp 24501 -E 3des-cbc "123456789012123456789012";

spdadd 10.0.0.216 10.0.0.11 any -P out ipsec
   esp/transport//require
   ah/transport//require;
	</pre>
      <p></p><p>	On host 10.0.0.11, the same Security Associations, no Security Policy:
	</p><pre class="SCREEN">#!/sbin/setkey -f
add 10.0.0.216 10.0.0.11 ah 24500 -A hmac-md5 "1234567890123456";
add 10.0.0.216 10.0.0.11 esp 24501 -E 3des-cbc "123456789012123456789012";
	</pre>
      <p></p><p>	With the above configuration in place (these files can be executed if 'setkey' is installed in /sbin),
	'ping 10.0.0.11' from 10.0.0.216 looks like this using tcpdump:
	</p><pre class="SCREEN">22:37:52 10.0.0.216 &gt; 10.0.0.11: AH(spi=0x00005fb4,seq=0xa): ESP(spi=0x00005fb5,seq=0xa) (DF)
22:37:52 10.0.0.11 &gt; 10.0.0.216: icmp: echo reply
	</pre>
	Note how the ping back from 10.0.0.11 is indeed plainly visible. The forward ping cannot be read by tcpdump
	of course, but it does show the Security Parameter Index of AH and ESP, which tells 10.0.0.11 how to 
	verify the authenticity of our packet and how to decrypt it.
      <p></p><p>	A few things must be mentioned however. The 
configuration above is shown in a lot of IPSEC examples and it is very 
dangerous.
	The problem is that the above contains policy on how 10.0.0.216 should 
treat packets going to 10.0.0.11, and that it explains how 10.0.0.11
	should treat those packets but it does NOT instruct 10.0.0.11 to 
discard unauthenticated or unencrypted traffic! 
      </p><p>	Anybody can now insert spoofed and completely unencrypted 
data and 10.0.0.11 will accept it. To remedy the above, we need an 
incoming 
	Security Policy on 10.0.0.11, as follows:
	</p><pre class="SCREEN">#!/sbin/setkey -f 
spdadd 10.0.0.216 10.0.0.11 any -P IN ipsec
   esp/transport//require
   ah/transport//require;
	</pre>
	This instructs 10.0.0.11 that any traffic coming to it from 10.0.0.216 is required to have valid ESP and AH.
      <p></p><p>	Now, to complete this configuration, we need return 
traffic to be encrypted and authenticated as well of course. The full 
configuration on
	10.0.0.216:
	</p><pre class="SCREEN">#!/sbin/setkey -f
flush;
spdflush;

# AH
add 10.0.0.11 10.0.0.216 ah 15700 -A hmac-md5 "1234567890123456";
add 10.0.0.216 10.0.0.11 ah 24500 -A hmac-md5 "1234567890123456";

# ESP
add 10.0.0.11 10.0.0.216 esp 15701 -E 3des-cbc "123456789012123456789012";
add 10.0.0.216 10.0.0.11 esp 24501 -E 3des-cbc "123456789012123456789012";

spdadd 10.0.0.216 10.0.0.11 any -P out ipsec
           esp/transport//require
           ah/transport//require;

spdadd 10.0.0.11 10.0.0.216 any -P in ipsec
           esp/transport//require
           ah/transport//require;
	  
	</pre>
      <p></p><p>	And on 10.0.0.11:
	</p><pre class="SCREEN">#!/sbin/setkey -f
flush;
spdflush;

# AH
add 10.0.0.11 10.0.0.216 ah 15700 -A hmac-md5 "1234567890123456";
add 10.0.0.216 10.0.0.11 ah 24500 -A hmac-md5 "1234567890123456";

# ESP
add 10.0.0.11 10.0.0.216 esp 15701 -E 3des-cbc "123456789012123456789012";
add 10.0.0.216 10.0.0.11 esp 24501 -E 3des-cbc "123456789012123456789012";


spdadd 10.0.0.11 10.0.0.216 any -P out ipsec
           esp/transport//require
           ah/transport//require;

spdadd 10.0.0.216 10.0.0.11 any -P in ipsec
           esp/transport//require
           ah/transport//require;

	</pre>
      <p></p><p>	Note that in this example we used identical keys for both directions of traffic. This is not in any way required however.
      </p><p>	To examine the configuration we just created, execute <b class="COMMAND">setkey -D</b>, which shows the Security Associations or 
	<b class="COMMAND">setkey -DP</b> which shows the configured policies.
      </p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.IPSEC.AUTOMATIC.KEYING">7.2. Automatic keying</a></h2><p>	In the previous section, encryption was configured using simple shared secrets. In other words, to remain secure,
	we need to transfer our encryption configuration over a trusted channel. If we were to configure the remote host 
	over telnet, any third party would know our shared secret and the setup would not be secure.
      </p><p>	Furthermore, because the secret is shared, it is not a secret. The remote can't do a lot with our secret, but we do 
	need to make sure that we use a different secret for communicating with all our partners. This requires a large number of keys,
	if there are 10 parties, this needs at least 50 different secrets. 
      </p><p>	Besides the symmetric key problem, there is also the need for key rollover. If a third party manages to sniff enough traffic,
	it may be in a position to reverse engineer the key. This is prevented by moving to a new key every once in a while but that is
	a process that needs to be automated.
      </p><p>	Another problem is that with manual keying as described above we exactly define the algorithms and key lengths used, something
	that requires a lot of coordination with the remote party. It is desirable to be able to have the ability to describe a 
	broader key policy such as 'We can do 3DES and Blowfish with at least the following key lengths'.
      </p><p>	To solve these isses, IPSEC provides Internet Key Exchange to automatically exchange randomly generated keys which are
	transmitted using asymmetric encryption technology, according to negotiated algorithm details.
      </p><p>	The Linux 2.5 IPSEC implementation works with the KAME 'racoon' IKE
	daemon. As of 9 November, the racoon version in Alexey's iptools
	distribution can be compiled, although you may need to remove 
#include &lt;net/route.h&gt; in two files. Alternatively, I've supplied a
<a href="http://ds9a.nl/ipsec/racoon.bz2" target="_top">precompiled version</a>.
      </p><p>	</p><div class="NOTE"><p></p><table class="NOTE" width="100%" border="0"><tbody><tr><td width="25" align="CENTER" valign="TOP"></td><td align="LEFT" valign="TOP"><p>		IKE needs access to UDP port 500, be sure that iptables does
not block it.
	  </p></td></tr></tbody></table></div>
	<p></p><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.IPSEC.KEYING.THEORY">7.2.1. Theory</a></h3><p>		As explained before, automatic keying does a lot of the work
for us. Specifically, it creates Security Associations on the fly. It does
not however set policy for us, which is as it should be.
	</p><p>	So, to benefit from IKE, setup a policy, but do not supply any
SAs. If the kernel discovers that there is an IPSEC policy, but no Security
Association, it will notify the IKE daemon, which then goes to work on
trying to negotiate one.
	</p><p>	Reiterating, a Security Policy specifies WHAT we want; a Security
Association describes HOW we want it. Using automatic keying lets us get
away with only specifying what we want.
	</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.IPSEC.AUTOMATIC.KEYING.EXAMPLE">7.2.2. Example</a></h3><p>	Kame racoon comes with a grand host of options, most of which have
very fine default values, so we don't need to touch them. As described
above, the operator needs to define a Security Policy, but no Security
Associations. We leave their negotiation to the IKE daemon.
	</p><p>	In this example, 10.0.0.11 and 10.0.0.216 are once again going to
setup secure communications, but this time with help from racoon. For
simplicity this configuration will be using pre-shared keys, the
dreaded 'shared secrets'. X.509 certificates are discussed in a separate
section, see <a href="#LARTC.IPSEC.X509">Section 7.2.3</a>.</p><p> We're
going to stick to almost the default configuration, identical on both hosts:
	</p><p></p><pre class="SCREEN">path pre_shared_key "/usr/local/etc/racoon/psk.txt";

remote anonymous
{
 	exchange_mode aggressive,main;
 	doi ipsec_doi;
 	situation identity_only;

	my_identifier address;

	lifetime time 2 min;   # sec,min,hour
	initial_contact on;
	proposal_check obey;	# obey, strict or claim

	proposal {
	        encryption_algorithm 3des;
	        hash_algorithm sha1;
	        authentication_method pre_shared_key;
	        dh_group 2 ;
	}
}
 
sainfo anonymous
{
 	pfs_group 1;
 	lifetime time 2 min;
 	encryption_algorithm 3des ;
 	authentication_algorithm hmac_sha1;
		compression_algorithm deflate ;
}</pre>
	<p></p><p>	Lots of settings - I think yet more can be removed to get closer to
the default configuration. A few noteworthy things. We've configured two
anonymous settings which hold for all remotes, making further configuration
easy. There is no need for per-host stanzas here, unless we really want
them.</p><p>	Furthermore, we've set it up such that we identify ourselves based
on our IP address ('my_identifier address'), and declare that we can do
3des, sha1, and that we will be using a pre-shared key, located in psk.txt.
	</p><p>	In psk.txt, we now setup two entries, which do differ on both hosts.
On 10.0.0.11:
</p><pre class="SCREEN">10.0.0.216	password2</pre>
On 10.0.0.216:
<pre class="SCREEN">10.0.0.11	password2</pre>
	Make sure these files are owned by root, and set to mode 0600,
racoon will not trust their contents otherwise. Note that these files are
mirrors from eachother.
	<p></p><p>	Now we are ready to setup our desired policy, which is simple
enough. On host 10.0.0.216:
</p><pre class="SCREEN">#!/sbin/setkey -f
flush;
spdflush;

spdadd 10.0.0.216 10.0.0.11 any -P out ipsec
	esp/transport//require;

spdadd 10.0.0.11 10.0.0.216 any -P in ipsec
	esp/transport//require;</pre>
And on 10.0.0.11:
<pre class="SCREEN">#!/sbin/setkey -f
flush;
spdflush;

spdadd 10.0.0.11 10.0.0.216 any -P out ipsec
	esp/transport//require;

spdadd 10.0.0.216 10.0.0.11 any -P in ipsec
	esp/transport//require;</pre>
Note how again these policies are mirrored.
	<p></p><p>	We are now ready to launch racoon! Once launched, the moment we try
to telnet from 10.0.0.11 to 10.0.0.216, or the other way around, racoon
will start negotiating:
</p><pre class="SCREEN">12:18:44: INFO: isakmp.c:1689:isakmp_post_acquire(): IPsec-SA
  request for 10.0.0.11 queued due to no phase1 found.
12:18:44: INFO: isakmp.c:794:isakmp_ph1begin_i(): initiate new
  phase 1 negotiation: 10.0.0.216[500]&lt;=&gt;10.0.0.11[500]
12:18:44: INFO: isakmp.c:799:isakmp_ph1begin_i(): begin Aggressive mode.
12:18:44: INFO: vendorid.c:128:check_vendorid(): received Vendor ID: 
  KAME/racoon
12:18:44: NOTIFY: oakley.c:2037:oakley_skeyid(): couldn't find
  the proper pskey, try to get one by the peer's address.
12:18:44: INFO: isakmp.c:2417:log_ph1established(): ISAKMP-SA
  established 10.0.0.216[500]-10.0.0.11[500] spi:044d25dede78a4d1:ff01e5b4804f0680
12:18:45: INFO: isakmp.c:938:isakmp_ph2begin_i(): initiate new phase 2 
  negotiation: 10.0.0.216[0]&lt;=&gt;10.0.0.11[0]
12:18:45: INFO: pfkey.c:1106:pk_recvupdate(): IPsec-SA established: 
  ESP/Transport 10.0.0.11-&gt;10.0.0.216 spi=44556347(0x2a7e03b)
12:18:45: INFO: pfkey.c:1318:pk_recvadd(): IPsec-SA established:
  ESP/Transport 10.0.0.216-&gt;10.0.0.11 spi=15863890(0xf21052)</pre><p></p><p>	If we now run setkey -D, which shows the Security Associations, they
are indeed there:
</p><pre class="SCREEN">10.0.0.216 10.0.0.11 
	esp mode=transport spi=224162611(0x0d5c7333) reqid=0(0x00000000)
	E: 3des-cbc  5d421c1b d33b2a9f 4e9055e3 857db9fc 211d9c95 ebaead04
	A: hmac-sha1  c5537d66 f3c5d869 bd736ae2 08d22133 27f7aa99
	seq=0x00000000 replay=4 flags=0x00000000 state=mature 
	created: Nov 11 12:28:45 2002	current: Nov 11 12:29:16 2002
	diff: 31(s)	hard: 600(s)	soft: 480(s)
	last: Nov 11 12:29:12 2002	hard: 0(s)	soft: 0(s)
	current: 304(bytes)	hard: 0(bytes)	soft: 0(bytes)
	allocated: 3	hard: 0	soft: 0
	sadb_seq=1 pid=17112 refcnt=0
10.0.0.11 10.0.0.216 
	esp mode=transport spi=165123736(0x09d79698) reqid=0(0x00000000)
	E: 3des-cbc  d7af8466 acd4f14c 872c5443 ec45a719 d4b3fde1 8d239d6a
	A: hmac-sha1  41ccc388 4568ac49 19e4e024 628e240c 141ffe2f
	seq=0x00000000 replay=4 flags=0x00000000 state=mature 
	created: Nov 11 12:28:45 2002	current: Nov 11 12:29:16 2002
	diff: 31(s)	hard: 600(s)	soft: 480(s)
	last:                     	hard: 0(s)	soft: 0(s)
	current: 231(bytes)	hard: 0(bytes)	soft: 0(bytes)
	allocated: 2	hard: 0	soft: 0
	sadb_seq=0 pid=17112 refcnt=0</pre>
As are the Security Policies we configured ourselves:
<pre class="SCREEN">10.0.0.11[any] 10.0.0.216[any] tcp
	in ipsec
	esp/transport//require
	created:Nov 11 12:28:28 2002 lastused:Nov 11 12:29:12 2002
	lifetime:0(s) validtime:0(s)
	spid=3616 seq=5 pid=17134
	refcnt=3
10.0.0.216[any] 10.0.0.11[any] tcp
	out ipsec
	esp/transport//require
	created:Nov 11 12:28:28 2002 lastused:Nov 11 12:28:44 2002
	lifetime:0(s) validtime:0(s)
	spid=3609 seq=4 pid=17134
	refcnt=3</pre><p></p><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN525">7.2.2.1. Problems and known defects</a></h4><p>		If this does not work, check that all configuration files
are owned by root, and can only be read by root. To start racoon on the
foreground, use '-F'. To force it to read a certain configuration file,
instead of at the compiled location, use '-f'. For staggering amounts of
detail, add a 'log debug;' statement to racoon.conf.
	</p></div></div><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.IPSEC.X509">7.2.3. Automatic keying using X.509 certificates</a></h3><p>	As mentioned before, the use of shared secrets is hard because they
aren't easily shared and once shared, are no longer secret. Luckily, there
is asymmetric encryption technology to help resolve this.
	</p><p>	If each IPSEC participant makes a public and a private key, secure
communications can be setup by both parties publishing their public key, and
configuring policy.
	</p><p>	Building a key is relatively easy, although it requires some work.
The following is based on the 'openssl' tool. 
	</p><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN533">7.2.3.1. Building an X.509 certificate for your host</a></h4><p>	OpenSSL has a lot of infrastructure for keys that may or may not be
signed by certificate authorities. Right now, we need to circumvent all that
infrastructure and practice some good old Snake Oil security, and do without
a certificate authority.
	</p><p>	First we issue a 'certificate request' for our host, called
'laptop':
</p><pre class="SCREEN">$ openssl req -new -nodes -newkey rsa:1024 -sha1 -keyform PEM -keyout \
  laptop.private -outform PEM -out request.pem</pre>
This asks us some questions:
<pre class="SCREEN">Country Name (2 letter code) [AU]:NL
State or Province Name (full name) [Some-State]:.
Locality Name (eg, city) []:Delft
Organization Name (eg, company) [Internet Widgits Pty Ltd]:Linux Advanced
Routing &amp; Traffic Control
Organizational Unit Name (eg, section) []:laptop
Common Name (eg, YOUR name) []:bert hubert
Email Address []:ahu@ds9a.nl

Please enter the following 'extra' attributes
to be sent with your certificate request
A challenge password []:
An optional company name []:</pre>
	It is left to your own discretion how completely you want to fill
this out. You may or may not want to put your hostname in there, depending
on your security needs. In this example, we have.<p></p><p>	We'll now 'self sign' this request:
</p><pre class="SCREEN">$ openssl x509 -req -in request.pem -signkey laptop.private -out \
  laptop.public
Signature ok
subject=/C=NL/L=Delft/O=Linux Advanced Routing &amp; Traffic \
  Control/OU=laptop/CN=bert hubert/Email=ahu@ds9a.nl
Getting Private key</pre>	
	The 'request.pem' file can now be discarded. 
	<p></p><p>	Repeat this procedure for all hosts you need a key for. You can
distribute the '.public' file with impunity, but keep the '.private' one
private!
	</p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN542">7.2.3.2. Setting up and launching</a></h4><p>	Once we have a public and a private key for our hosts we can tell
	racoon to use them.
	</p><p>	We return to our previous configuration and the two hosts, 10.0.0.11
('upstairs') and 10.0.0.216 ('laptop').
	</p><p>	To the <tt class="FILENAME">racoon.conf</tt> file on 10.0.0.11, we add:
</p><pre class="SCREEN">path certificate "/usr/local/etc/racoon/certs";

remote 10.0.0.216
{
 	exchange_mode aggressive,main;
	my_identifier asn1dn;
	peers_identifier asn1dn;

	certificate_type x509 "upstairs.public" "upstairs.private";

	peers_certfile "laptop.public";
	proposal {
                encryption_algorithm 3des;
		hash_algorithm sha1;
		authentication_method rsasig;
		dh_group 2 ;
	}
}</pre>
	This tells racoon that certificates are to be found in
<tt class="FILENAME">/usr/local/etc/racoon/certs/</tt>. Furthermore, it contains
configuration items specific for remote 10.0.0.216.
	<p></p><p>	The 'asn1dn' lines tell racoon that the identifier for both the
local and remote ends are to be extracted from the public keys. This is the
'subject=/C=NL/L=Delft/O=Linux Advanced Routing &amp; Traffic 
  Control/OU=laptop/CN=bert hubert/Email=ahu@ds9a.nl' output from above.
	</p><p>	The <b class="COMMAND">certificate_type</b> line configures the local
public and private key. The <b class="COMMAND">peers_certfile</b> statement
configures racoon to read the public key of the remote peer from the file
<tt class="FILENAME">laptop.public</tt>.
	</p><p>	The <b class="COMMAND">proposal</b> stanza is unchanged from what we've
seen earlier, with the exception that the
<b class="COMMAND">authentication_method</b> is now <b class="COMMAND">rsasig</b>,
indicating the use of RSA public/private keys for authentication.
	</p><p>	The addition to the configuration of 10.0.0.216 is nearly identical, except for the
usual mirroring:
</p><pre class="SCREEN">path certificate "/usr/local/etc/racoon/certs";

remote 10.0.0.11
{
 	exchange_mode aggressive,main;
	my_identifier asn1dn;
        peers_identifier asn1dn;

        certificate_type x509 "laptop.public" "laptop.private";
 
 	peers_certfile "upstairs.public";

	proposal {
                encryption_algorithm 3des;
	        hash_algorithm sha1;
		authentication_method rsasig;
	        dh_group 2 ;
	}
}</pre><p></p><p>	Now that we've added these statements to both hosts, we only need to
move the key files in place. The 'upstairs' machine needs 
<tt class="FILENAME">upstairs.private</tt>, <tt class="FILENAME">upstairs.public</tt>, 
and <tt class="FILENAME">laptop.public</tt> in
<tt class="FILENAME">/usr/local/etc/racoon/certs</tt>. Make sure that this
directory is owned by root and has mode 0700 or racoon may refuse to read
it!</p><p>The 'laptop' machine needs 
<tt class="FILENAME">laptop.private</tt>, <tt class="FILENAME">laptop.public</tt>, 
and <tt class="FILENAME">upstairs.public</tt> in
<tt class="FILENAME">/usr/local/etc/racoon/certs</tt>. In other words, each host
needs its own public and private key and additionally, the public key of the
remote.</p><p>	Verify that a Security Policy is in place (execute the 'spdadd' lines in
<a href="#LARTC.IPSEC.AUTOMATIC.KEYING.EXAMPLE">Section 7.2.2</a>). Then launch racoon and everything should
work.</p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN573">7.2.3.3. How to setup tunnels securely</a></h4><p>	To setup secure communications with a remote party, we must exchange
public keys. While the public key does not need to be kept a secret, on the
contrary, it is very important to be sure that it is in fact the unaltered
key. In other words, you need to be certain there is no 'man in the middle'.
	</p><p>To make this easy, OpenSSL provides the 'digest' command:
</p><pre class="SCREEN">$ openssl dgst upstairs.public 
MD5(upstairs.public)= 78a3bddafb4d681c1ca8ed4d23da4ff1</pre><p></p><p>	Now all we need to do is verify if our remote partner sees the same
digest. This might be done by meeting in real life or perhaps over the
phone, making sure the number of the remote party was not in fact sent over
the same email containing the key!
	</p><p>	Another way of doing this is the use of a Trusted Third Party which
runs a Certificate Authority. This CA would then sign your key, which we've
done ourselves above.
	</p></div></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.IPSEC.TUNNEL">7.3. IPSEC tunnels</a></h2><p>
	So far, we've only seen IPSEC in so called 'transport' mode where both 
endpoints understand IPSEC directly. As this is often not
	the case, it may be necessary to have only routers understand IPSEC, 
and have them do the work for the hosts behind them. 
	This is called 'tunnel mode'.
      </p><p>	Setting this up is a breeze. To tunnel all traffic to 130.161.0.0/16 from 10.0.0.216 via 10.0.0.11, we issue the following on
	10.0.0.216:
</p><pre class="SCREEN">#!/sbin/setkey -f
flush;
spdflush;

add 10.0.0.216 10.0.0.11 esp 34501
	-m tunnel
	-E 3des-cbc "123456789012123456789012";

spdadd 10.0.0.0/24 130.161.0.0/16 any -P out ipsec
           esp/tunnel/10.0.0.216-10.0.0.11/require;</pre>
	Note the '-m tunnel', it is vitally important! This first configures an ESP encryption SA between our tunnel endpoints,
	10.0.0.216 and 10.0.0.11. 
      <p></p><p>	Next the actual tunnel is configured. It instructs the kernel to encrypt all traffic it has to route from 10.0.0.0/24 to
	130.161.0.0. Furthermore, this traffic then has to be shipped to 10.0.0.11.
      </p><p>	10.0.0.11 also needs some configuration:
</p><pre class="SCREEN">#!/sbin/setkey -f
flush;
spdflush;

add 10.0.0.216 10.0.0.11 esp 34501
	-m tunnel
	-E 3des-cbc "123456789012123456789012";

spdadd 10.0.0.0/24 130.161.0.0/16 any -P in ipsec
           esp/tunnel/10.0.0.216-10.0.0.11/require;</pre>
	Note that this is exactly identical, except for the change from '-P out' to '-P in'. As with earlier examples,
	we've now only configured traffic going one way. Completing the other half of the tunnel is left as an
	exercise for the reader.
      <p></p><p>	Another name for this setup is 'proxy ESP', which is somewhat clearer.
      </p><p>	</p><div class="NOTE"><p></p><table class="NOTE" width="100%" border="0"><tbody><tr><td width="25" align="CENTER" valign="TOP"></td><td align="LEFT" valign="TOP"><p>	    The IPSEC tunnel needs to have IP Forwarding enabled in the kernel!
	  </p></td></tr></tbody></table></div>
      <p></p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.IPSEC.OTHER">7.4. Other IPSEC software</a></h2><p>	Thomas Walpuski reports that he wrote a patch to make OpenBSD isakpmd work with Linux 2.5 IPSEC.
Furthermore, the main isakpmd CVS repository now contains this code!
	Some notes are <a href="http://bender.thinknerd.de/~thomas/IPsec/isakmpd-linux.html" target="_top">on his page</a>.
      </p><p>	isakpmd is quite different from racoon mentioned above but many
	people like it. It can be found <a href="http://www.openbsd.org/cgi-bin/cvsweb/src/sbin/isakmpd/" target="_top">here</a>.
Read more about OpenBSD CVS <a href="http://www.openbsd.org/anoncvs.html" target="_top">here</a>. Thomas also made a
<a href="http://bender.thinknerd.de/~thomas/IPsec/isakmpd.tgz" target="_top">tarball</a>
available for those uncomfortable with CVS or patch.

      </p><p>	Furthermore, there are patches to make the FreeS/WAN userspace tools
work with the native Linux 2.5 IPSEC, you can find them <a href="http://gondor.apana.org.au/~herbert/freeswan/" target="_top">here</a>.
      </p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.IPSEC.INTEROP">7.5. IPSEC interoperation with other systems</a></h2><p>	FIXME: Write this
      </p><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.IPSEC.INTEROP.WIN32">7.5.1. Windows</a></h3><p>
	Andreas Jellinghaus &lt;aj@dungeon.inka.de&gt; reports: "win2k: it 
works. pre_shared key with ip address for authentication (I don't
think windows supports fqdn or userfqdn strings).  Certificates should 
also work, didn't
try.".

	</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.IPSEC.INTEROP.CHECKPOINT">7.5.2. Check Point VPN-1
NG</a></h3><p>	Peter Bieringer reports: 
</p><pre class="SCREEN">Here are some results (tunnel mode only tested, auth=SHA1):

DES:     ok 
3DES:    ok 
AES-128: ok 
AES-192: not supported by CP VPN-1
AES-256: ok 
CAST* :  not supported by used Linux kernel

Tested version: FP4 aka R54 aka w/AI</pre>
	<p></p><p>	More information <a href="http://www.fw-1.de/aerasec/ng/vpn-racoon/CP-VPN1-NG-Linux-racoon.html" target="_top">here</a>.
	</p></div></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.MULTICAST"></a>Chapter 8. Multicast routing</h1><p>FIXME: Editor Vacancy!</p><p>The Multicast-HOWTO is ancient (relatively-speaking) and may be inaccurate
or misleading in places, for that reason.</p><p>Before you can do any multicast routing, you need to configure the Linux
kernel to support the type of multicast routing you want to do. This, in
turn, requires you to decide what type of multicast routing you expect to
be using. There are essentially four "common" types - DVMRP (the Multicast
version of the RIP unicast protocol), MOSPF (the same, but for OSPF), PIM-SM
("Protocol Independent Multicasting - Sparse Mode", which assumes that users
of any multicast group are spread out, rather than clumped) and PIM-DM (the
same, but "Dense Mode", which assumes that there will be significant clumps
of users of the same multicast group).</p><p>In the Linux kernel, you will notice that these options don't appear. This is
because the protocol itself is handled by a routing application, such as
Zebra, mrouted, or pimd. However, you still have to have a good idea of which
you're going to use, to select the right options in the kernel.</p><p>For all multicast routing, you will definitely need to enable "multicasting"
and "multicast routing". For DVMRP and MOSPF, this is sufficient. If you are
going to use PIM, you must also enable PIMv1 or PIMv2, depending on whether
the network you are connecting to uses version 1 or 2 of the PIM protocol.</p><p>Once you have all that sorted out, and your new Linux kernel compiled, you
will see that the IP protocols listed, at boot time, now include IGMP. This
is a protocol for managing multicast groups. At the time of writing, Linux
supports IGMP versions 1 and 2 only, although version 3 does exist and has
been documented. This doesn't really affect us that much, as IGMPv3 is still
new enough that the extra capabilities of IGMPv3 aren't going to be that
much use. Because IGMP deals with groups, only the features present in the
simplest version of IGMP over the entire group are going to be used. For the
most part, that will be IGMPv2, although IGMPv1 is sill going to be
encountered.</p><p>So far, so good. We've enabled multicasting. Now, we have to tell the Linux
kernel to actually do something with it, so we can start routing. This means
adding the Multicast virtual network to the router table:</p><p>ip route add 224.0.0.0/4 dev eth0</p><p>(Assuming, of course, that you're multicasting over eth0! Substitute the
device of your choice, for this.)</p><p>Now, tell Linux to forward packets...</p><p>echo 1 &gt; /proc/sys/net/ipv4/ip_forward</p><p>At this point, you may be wondering if this is ever going to do anything. So,
to test our connection, we ping the default group, 224.0.0.1, to see if anyone
is alive. All machines on your LAN with multicasting enabled <span class="emphasis"><i class="EMPHASIS">should</i></span>
respond, but nothing else. You'll notice that none of the machines that
respond have an IP address of 224.0.0.1. What a surprise! :) This is a group
address (a "broadcast" to subscribers), and all members of the group will
respond with their own address, not the group address.</p><p>ping -c 2 224.0.0.1</p><p>At this point, you're ready to do actual multicast routing. Well, assuming
that you have two networks to route between.</p><p>(To Be Continued!)</p></div><div class="CHAPTER"><hr><h1><a name="LARTC.QDISC"></a>Chapter 9. Queueing Disciplines for Bandwidth Management</h1><p>Now, when I discovered this, it <span class="emphasis"><i class="EMPHASIS">really</i></span> blew me away. Linux 2.2/2.4
comes with everything to manage bandwidth in ways comparable to high-end
dedicated bandwidth management systems.</p><p>Linux even goes far beyond what Frame and ATM provide. </p><p>Just to prevent confusion, <b class="COMMAND">tc</b> uses the following 
rules for bandwith specification:
 
</p><pre class="LITERALLAYOUT">mbps = 1024 kbps = 1024 * 1024 bps =&gt; byte/s
mbit = 1024 kbit =&gt; kilo bit/s.
mb = 1024 kb = 1024 * 1024 b =&gt; byte
mbit = 1024 kbit =&gt; kilo bit.</pre>

Internally, the number is stored in bps and b.<p></p><p>But when <b class="COMMAND">tc</b> prints the rate, it uses following :</p><pre class="LITERALLAYOUT">1Mbit = 1024 Kbit = 1024 * 1024 bps =&gt; byte/s</pre><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.QDISC.EXPLAIN">9.1. Queues and Queueing Disciplines explained</a></h2><p>With queueing we determine the way in which data is <span class="emphasis"><i class="EMPHASIS">SENT</i></span>.
It is important to realise that we can only shape data that we transmit.</p><p>With the way the Internet works, we have no direct control of what people
send us. It's a bit like your (physical!) mailbox at home. There is no way
you can influence the world to modify the amount of mail they send you,
short of contacting everybody.</p><p>However, the Internet is mostly based on TCP/IP which has a few features
that help us. TCP/IP has no way of knowing the capacity of the network
between two hosts, so it just starts sending data faster and faster ('slow
start') and when packets start getting lost, because there is no room to
send them, it will slow down. In fact it is a bit smarter than this, but
more about that later.</p><p>This is the equivalent of not reading half of your mail, and hoping that
people will stop sending it to you. With the difference that it works for
the Internet :-)</p><p>If you have a router and wish to prevent certain hosts within your network
from downloading too fast, you need to do your shaping on the *inner* interface
of your router, the one that sends data to your own computers.</p><p>You also have to be sure you are controlling the bottleneck of the link.
If you have a 100Mbit NIC and you have a router that has a 256kbit link,
you have to make sure you are not sending more data than your router can
handle.  Otherwise, it will be the router who is controlling the link and
shaping the available bandwith. We need to 'own the queue' so to speak, and
be the slowest link in the chain. Luckily this is easily possible.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.QDISC.CLASSLESS">9.2. Simple, classless Queueing Disciplines</a></h2><p>As said, with queueing disciplines, we change the way data is sent.
Classless queueing disciplines are those that, by and large accept data and
only reschedule, delay or drop it.</p><p>These can be used to shape traffic for an entire interface, without any
subdivisions. It is vital that you understand this part of queueing before
we go on the classful qdisc-containing-qdiscs!</p><p>By far the most widely used discipline is the pfifo_fast qdisc - this is the
default. This also explains why these advanced features are so robust. They
are nothing more than 'just another queue'.</p><p>Each of these queues has specific strengths and weaknesses. Not all of them
may be as well tested.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN658">9.2.1. pfifo_fast</a></h3><p>This queue is, as the name says, First In, First Out, which means that no
packet receives special treatment. At least, not quite. This queue has 3 so
called 'bands'. Within each band, FIFO rules apply. However, as long as
there are packets waiting in band 0, band 1 won't be processed. Same goes
for band 1 and band 2.</p><p>The kernel honors the so called Type of Service flag of packets, and takes
care to insert 'minimum delay' packets in band 0. </p><p>Do not confuse this classless simple qdisc with the classful PRIO one!
Although they behave similarly, pfifo_fast is classless and you cannot add
other qdiscs to it with the tc command.</p><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN663">9.2.1.1. Parameters &amp; usage</a></h4><p>You can't configure the pfifo_fast qdisc as it is the hardwired default.
This is how it is configured by default:
</p><p></p><div class="VARIABLELIST"><dl><dt>priomap</dt><dd><p>Determines how packet priorities, as assigned by the kernel, map to bands.
Mapping occurs based on the TOS octet of the packet, which looks like this:</p><p></p><pre class="SCREEN">   0     1     2     3     4     5     6     7
+-----+-----+-----+-----+-----+-----+-----+-----+
|                 |                       |     |
|   PRECEDENCE    |          TOS          | MBZ |
|                 |                       |     |
+-----+-----+-----+-----+-----+-----+-----+-----+</pre><p></p><p>The four TOS bits (the 'TOS field') are defined as:

</p><pre class="SCREEN">Binary Decimcal  Meaning
-----------------------------------------
1000   8         Minimize delay (md)
0100   4         Maximize throughput (mt)
0010   2         Maximize reliability (mr)
0001   1         Minimize monetary cost (mmc)
0000   0         Normal Service</pre><p></p><p>As there is 1 bit to the right of these four bits, the actual value of the
TOS field is double the value of the TOS bits. Tcpdump -v -v shows you the
value of the entire TOS field, not just the four bits. It is the value you
see in the first column of this table:</p><p></p><pre class="SCREEN">TOS     Bits  Means                    Linux Priority    Band
------------------------------------------------------------
0x0     0     Normal Service           0 Best Effort     1
0x2     1     Minimize Monetary Cost   1 Filler          2
0x4     2     Maximize Reliability     0 Best Effort     1
0x6     3     mmc+mr                   0 Best Effort     1
0x8     4     Maximize Throughput      2 Bulk            2
0xa     5     mmc+mt                   2 Bulk            2
0xc     6     mr+mt                    2 Bulk            2
0xe     7     mmc+mr+mt                2 Bulk            2
0x10    8     Minimize Delay           6 Interactive     0
0x12    9     mmc+md                   6 Interactive     0
0x14    10    mr+md                    6 Interactive     0
0x16    11    mmc+mr+md                6 Interactive     0
0x18    12    mt+md                    4 Int. Bulk       1
0x1a    13    mmc+mt+md                4 Int. Bulk       1
0x1c    14    mr+mt+md                 4 Int. Bulk       1
0x1e    15    mmc+mr+mt+md             4 Int. Bulk       1</pre><p></p><p>Lots of numbers. The second column contains the value of the relevant four
TOS bits, followed by their translated meaning. For example, 15 stands for a
packet wanting Minimal Monetary Cost, Maximum Reliability, Maximum
Throughput AND Minimum Delay. I would call this a 'Dutch Packet'.</p><p>The fourth column lists the way the Linux kernel interprets the TOS bits, by
showing to which Priority they are mapped. </p><p>The last column shows the result of the default priomap. On the command line,
the default priomap looks like this:

</p><pre class="SCREEN">1, 2, 2, 2, 1, 2, 0, 0 , 1, 1, 1, 1, 1, 1, 1, 1</pre><p></p><p>This means that priority 4, for example, gets mapped to band number 1. The
priomap also allows you to list higher priorities (&gt; 7) which do not
correspond to TOS mappings, but which are set by other means.</p><p>This table from RFC 1349 (read it for more details) tells you how
applications might very well set their TOS bits:

</p><pre class="SCREEN">TELNET                   1000           (minimize delay)
FTP
	Control          1000           (minimize delay)
        Data             0100           (maximize throughput)

TFTP                     1000           (minimize delay)

SMTP 
	Command phase    1000           (minimize delay)
        DATA phase       0100           (maximize throughput)

Domain Name Service
	UDP Query        1000           (minimize delay)
	TCP Query        0000
	Zone Transfer    0100           (maximize throughput)

NNTP                     0001           (minimize monetary cost)

ICMP
	Errors           0000
	Requests         0000 (mostly)
	Responses        &lt;same as request&gt; (mostly)</pre><p></p></dd><dt>txqueuelen</dt><dd><p>The length of this queue is gleaned from the interface configuration, which
you can see and set with ifconfig and ip. To set the queue length to 10,
execute: ifconfig eth0 txqueuelen 10</p><p>You can't set this parameter with tc!</p></dd></dl></div><p></p></div></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN690">9.2.2. Token Bucket Filter</a></h3><p>The Token Bucket Filter (TBF) is a simple qdisc that only passes packets
arriving at a rate which is not exceeding some administratively set rate, but
with the possibility to allow short bursts in excess of this rate.</p><p>TBF is very precise, network- and processor friendly. It should be your
first choice if you simply want to slow an interface down!</p><p>The TBF implementation consists of a buffer (bucket), constantly filled by
some virtual pieces of information called tokens, at a specific rate (token
rate). The most important parameter of the bucket is its size, that is the
number of tokens it can store.</p><p>Each arriving token collects one incoming data packet from the data queue
and is then deleted from the bucket. Associating this algorithm
with the two flows -- token and data, gives us three possible scenarios:</p><p></p><p></p><ul><li><p> The data arrives in TBF at a rate that's <span class="emphasis"><i class="EMPHASIS">equal</i></span> to the rate
of incoming tokens. In this case each incoming packet has its matching token
and passes the queue without delay.</p></li><li><p> The data arrives in TBF at a rate that's <span class="emphasis"><i class="EMPHASIS">smaller</i></span> than the
token rate. Only a part of the tokens are deleted at output of each data packet
that's sent out the queue, so the tokens accumulate, up to the bucket size.
The unused tokens can then be used to send data at a speed that's exceeding the
standard token rate, in case short data bursts occur.</p></li><li><p> The data arrives in TBF at a rate <span class="emphasis"><i class="EMPHASIS">bigger</i></span> than the token rate.
This means that the bucket will soon be devoid of tokens, which causes the
TBF to throttle itself for a while. This is called an 'overlimit situation'.
If packets keep coming in, packets will start to get dropped.</p></li></ul><p></p><p>The last scenario is very important, because it allows to
administratively shape the bandwidth available to data that's passing
the filter.</p><p>The accumulation of tokens allows a short burst of overlimit data to be
still passed without loss, but any lasting overload will cause packets to be
constantly delayed, and then dropped.</p><p>Please note that in the actual implementation, tokens correspond to bytes,
not packets.</p><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN710">9.2.2.1. Parameters &amp; usage</a></h4><p>Even though you will probably not need to change them, tbf has some knobs
available. First the parameters that are always available:
</p><p></p><div class="VARIABLELIST"><dl><dt>limit or latency</dt><dd><p>Limit is the number of bytes that can be queued waiting for tokens to become
available. You can also specify this the other way around by setting the
latency parameter, which specifies the maximum amount of time a packet can
sit in the TBF. The latter calculation takes into account the size of the
bucket, the rate and possibly the peakrate (if set).</p></dd><dt>burst/buffer/maxburst</dt><dd><p>Size of the bucket, in bytes. This is the maximum amount of bytes that
tokens can be available for instantaneously. In general, larger shaping
rates require a larger buffer. For 10mbit/s on Intel, you need at least
10kbyte buffer if you want to reach your configured rate!</p><p>If your buffer is too small, packets may be dropped because more tokens
arrive per timer tick than fit in your bucket.</p></dd><dt>mpu</dt><dd><p>A zero-sized packet does not use zero bandwidth. For ethernet, no packet
uses less than 64 bytes. The Minimum Packet Unit determines the minimal
token usage for a packet.</p></dd><dt>rate</dt><dd><p>The speedknob. See remarks above about limits!</p></dd></dl></div><p></p><p>If the bucket contains tokens and is allowed to empty, by default it does so
at infinite speed. If this is unacceptable, use the following parameters:</p><p></p><p></p><div class="VARIABLELIST"><dl><dt>peakrate</dt><dd><p>If tokens are available, and packets arrive, they are sent out immediately
by default, at 'lightspeed' so to speak. That may not be what you want,
especially if you have a large bucket. </p><p>The peakrate can be used to specify how quickly the bucket is allowed to be
depleted. If doing everything by the book, this is achieved by releasing a
packet, and then wait just long enough, and release the next. We calculated
our waits so we send just at peakrate.</p><p>However, due to the default 10ms timer resolution of Unix, with 10.000 bits
average packets, we are limited to 1mbit/s of peakrate!</p></dd><dt>mtu/minburst</dt><dd><p>The 1mbit/s peakrate is not very useful if your regular rate is more than
that. A higher peakrate is possible by sending out more packets per
timertick, which effectively means that we create a second bucket!</p><p>This second bucket defaults to a single packet, which is not a bucket at
all.</p><p>To calculate the maximum possible peakrate, multiply the configured mtu by
100 (or more correctly, HZ, which is 100 on Intel, 1024 on Alpha).</p></dd></dl></div><p></p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN746">9.2.2.2. Sample configuration</a></h4><p>A simple but *very* useful configuration is this:

</p><pre class="SCREEN"># tc qdisc add dev ppp0 root tbf rate 220kbit latency 50ms burst 1540</pre><p></p><p>Ok, why is this useful? If you have a networking device with a large queue,
like a DSL modem or a cable modem, and you talk to it over a fast device,
like over an ethernet interface, you will find that uploading absolutely
destroys interactivity.</p><p>This is because uploading will fill the queue in the modem, which is
probably *huge* because this helps actually achieving good data throughput
uploading. But this is not what you want, you want to have the queue not too
big so interactivity remains and you can still do other stuff while sending
data.</p><p>The line above slows down sending to a rate that does not lead to a queue in
the modem - the queue will be in Linux, where we can control it to a limited
size.</p><p>Change 220kbit to your uplink's *actual* speed, minus a few percent. If you
have a really fast modem, raise 'burst' a bit. </p></div></div><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.SFQ">9.2.3. Stochastic Fairness Queueing</a></h3><p>Stochastic Fairness Queueing (SFQ) is a simple implementation of the fair
queueing algorithms family. It's less accurate than others, but it also
requires less calculations while being almost perfectly fair.</p><p>The key word in SFQ is conversation (or flow), which mostly corresponds to a
TCP session or a UDP stream. Traffic is divided into a pretty large number
of FIFO queues, one for each conversation. Traffic is then sent in a round
robin fashion, giving each session the chance to send data in turn.</p><p>This leads to very fair behaviour and disallows any single conversation from
drowning out the rest. SFQ is called 'Stochastic' because it doesn't really
allocate a queue for each session, it has an algorithm which divides traffic
over a limited number of queues using a hashing algorithm. </p><p>Because of the hash, multiple sessions might end up in the same bucket, which
would halve each session's chance of sending a packet, thus halving the
effective speed available. To prevent this situation from becoming
noticeable, SFQ changes its hashing algorithm quite often so that any two
colliding sessions will only do so for a small number of seconds.</p><p>It is important to note that SFQ is only useful in case your actual outgoing
interface is really full! If it isn't then there will be no queue on your
linux machine and hence no effect. Later on we will describe how to combine
SFQ with other qdiscs to get a best-of-both worlds situation.</p><p>Specifically, setting SFQ on the ethernet interface heading to your
cable modem or DSL router is pointless without further shaping!</p><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN762">9.2.3.1. Parameters &amp; usage</a></h4><p>The SFQ is pretty much self tuning:
</p><p></p><div class="VARIABLELIST"><dl><dt>perturb</dt><dd><p>Reconfigure hashing once this many seconds. If unset, hash will never be
reconfigured. Not recommended. 10 seconds is probably a good value.</p></dd><dt>quantum</dt><dd><p>Amount of bytes a stream is allowed to dequeue before the next queue gets a
turn. Defaults to 1 maximum sized packet (MTU-sized). Do not set below the
MTU!</p></dd><dt>limit</dt><dd><p>   The total number of packets that will be queued by this SFQ (after that it
   starts dropping them).
   </p></dd></dl></div><p></p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN778">9.2.3.2. Sample configuration</a></h4><p>If you have a device which has identical link speed and actual available
rate, like a phone modem, this configuration will help promote fairness:

</p><pre class="SCREEN"># tc qdisc add dev ppp0 root sfq perturb 10
# tc -s -d qdisc ls
qdisc sfq 800c: dev ppp0 quantum 1514b limit 128p flows 128/1024 perturb 10sec 
 Sent 4812 bytes 62 pkts (dropped 0, overlimits 0) </pre><p></p><p>The number 800c: is the automatically assigned handle number, limit means
that 128 packets can wait in this queue. There are 1024 hashbuckets
available for accounting, of which 128 can be active at a time (no more
packets fit in the queue!) Once every 10 seconds, the hashes are
reconfigured.</p></div></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.QDISC.ADVICE">9.3. Advice for when to use which queue</a></h2><p>Summarizing, these are the simple queues that actually manage traffic by
reordering, slowing or dropping packets.</p><p>The following tips may help in choosing which queue to use. It mentions some
qdiscs described in the
<i class="CITETITLE"><a href="#LARTC.ADV-QDISC">Chapter 14</a></i> chapter.</p><p></p><ul><li><p>To purely slow down outgoing traffic, use the Token Bucket Filter. Works up
to huge bandwidths, if you scale the bucket.</p></li><li><p>If your link is truly full and you want to make sure that no single session
can dominate your outgoing bandwidth, use Stochastical Fairness Queueing.</p></li><li><p>If you have a big backbone and know what you are doing, consider Random
Early Drop (see Advanced chapter).</p></li><li><p>To 'shape' incoming traffic which you are not forwarding, use the Ingress
Policer. Incoming shaping is called 'policing', by the way, not 'shaping'.  </p></li><li><p>If you *are* forwarding it, use a TBF on the interface you are forwarding
the data to. Unless you want to shape traffic that may go out over several
interfaces, in which case the only common factor is the incoming interface.
In that case use the Ingress Policer.</p></li><li><p>If you don't want to shape, but only want to see if your interface is so
loaded that it has to queue, use the pfifo queue (not pfifo_fast). It lacks
internal bands but does account the size of its backlog.</p></li><li><p>Finally - you can also do <span class="QUOTE">"social shaping"</span>.
You may not always be able to use technology to achieve what you want.
Users experience technical constraints as hostile.
A kind word may also help with getting your bandwidth to be divided right!</p></li></ul></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.QDISC.TERMINOLOGY">9.4. Terminology</a></h2><p>To properly understand more complicated configurations it is necessary to
explain a few concepts first. Because of the complexity and the relative
youth of the subject, a lot of different words are used when people in fact
mean the same thing.</p><p>The following is loosely based on 
<tt class="FILENAME">draft-ietf-diffserv-model-06.txt</tt>,
<i class="CITETITLE">An Informal Management Model for Diffserv Routers</i>.
It can currently be found at 
<a href="http://www.ietf.org/internet-drafts/draft-ietf-diffserv-model-06.txt" target="_top">  http://www.ietf.org/internet-drafts/draft-ietf-diffserv-model-06.txt</a>.</p><p>Read it for the strict definitions of the terms used.
</p><p></p><div class="VARIABLELIST"><dl><dt>Queueing Discipline (qdisc)</dt><dd><p>An algorithm that manages the queue of a device, either incoming (ingress)
or outgoing (egress).</p></dd><dt>root qdisc</dt><dd><p>The root qdisc is the qdisc attached to the device.</p></dd><dt>Classless qdisc</dt><dd><p>A qdisc with no configurable internal subdivisions. </p></dd><dt>Classful qdisc</dt><dd><p>A classful qdisc contains multiple classes. Some of these classes contains a
further qdisc, which may again be classful, but need not be. According to
the strict definition, pfifo_fast *is* classful, because it contains three
bands which are, in fact, classes. However, from the user's configuration
perspective, it is classless as the classes can't be touched with the tc
tool. </p></dd><dt>Classes</dt><dd><p>A classful qdisc may have many classes, each of which is internal to the
qdisc.  A class, in turn, may have several classes added to it.  So a class
can have a qdisc as parent or an other class.

A leaf class is a class with no child classes.  This class has 1 qdisc attached
to it.  This qdisc is responsible to send the data from that class.  When
you create a class, a fifo qdisc is attached to it.  When you add a child class,
this qdisc is removed.
For a leaf class, this fifo qdisc can be replaced with
an other more suitable qdisc.  You can even replace this fifo qdisc with a
classful qdisc so you can add extra classes.</p></dd><dt>Classifier</dt><dd><p>Each classful qdisc needs to determine to which class it needs to send a
packet. This is done using the classifier.</p></dd><dt>Filter</dt><dd><p>Classification can be performed using filters. A filter contains a number of
conditions which if matched, make the filter match.</p></dd><dt>Scheduling</dt><dd><p>A qdisc may, with the help of a classifier, decide that some packets need to
go out earlier than others. This process is called Scheduling, and is
performed for example by the pfifo_fast qdisc mentioned earlier. Scheduling
is also called 'reordering', but this is confusing.</p></dd><dt>Shaping</dt><dd><p>The process of delaying packets before they go out to make traffic confirm
to a configured maximum rate. Shaping is performed on egress. Colloquially, 
dropping packets to slow traffic down is also often called Shaping.</p></dd><dt>Policing</dt><dd><p>Delaying or dropping packets in order to make traffic stay below a
configured bandwidth. In Linux, policing can only drop a packet and not
delay it - there is no 'ingress queue'.</p></dd><dt>Work-Conserving</dt><dd><p>A work-conserving qdisc always delivers a packet if one is available. In
other words, it never delays a packet if the network adaptor is ready to
send one (in the case of an egress qdisc).</p></dd><dt>non-Work-Conserving</dt><dd><p>Some queues, like for example the Token Bucket Filter, may need to hold on
to a packet for a certain time in order to limit the bandwidth. This means
that they sometimes refuse to pass a packet, even though they have one
available.</p></dd></dl></div><p></p><p>Now that we have our terminology straight, let's see where all these things
are.</p><p></p><pre class="SCREEN">                Userspace programs
                     ^
                     |
     +---------------+-----------------------------------------+
     |               Y                                         |
     |    -------&gt; IP Stack                                    |
     |   |              |                                      |
     |   |              Y                                      |
     |   |              Y                                      |
     |   ^              |                                      |
     |   |  / ----------&gt; Forwarding -&gt;                        |
     |   ^ /                           |                       |
     |   |/                            Y                       |
     |   |                             |                       |
     |   ^                             Y          /-qdisc1-\   |
     |   |                            Egress     /--qdisc2--\  |
  ---&gt;-&gt;Ingress                       Classifier ---qdisc3---- | -&gt;
     |   Qdisc                                   \__qdisc4__/  |
     |                                            \-qdiscN_/   |
     |                                                         |
     +----------------------------------------------------------+</pre>

Thanks to Jamal Hadi Salim for this ASCII representation.<p></p><p>The big block represents the kernel. The leftmost arrow represents traffic
entering your machine from the network. It is then fed to the Ingress
Qdisc which may apply Filters to a packet, and decide to drop it. This
is called 'Policing'.</p><p>This happens at a very early stage, before it has seen a lot of the kernel.
It is therefore a very good place to drop traffic very early, without
consuming a lot of CPU power.</p><p>If the packet is allowed to continue, it may be destined for a local
application, in which case it enters the IP stack in order to be processed,
and handed over to a userspace program. The packet may also be forwarded
without entering an application, in which case it is destined for egress.
Userspace programs may also deliver data, which is then examined and
forwarded to the Egress Classifier.</p><p>There it is investigated and enqueued to any of a number of qdiscs. In the
unconfigured default case, there is only one egress qdisc installed, the
pfifo_fast, which always receives the packet. This is called 'enqueueing'.</p><p>The packet now sits in the qdisc, waiting for the kernel to ask for
it for transmission over the network interface. This is called 'dequeueing'.</p><p>This picture also holds in case there is only one network adaptor - the
arrows entering and leaving the kernel should not be taken too literally.
Each network adaptor has both ingress and egress hooks.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.QDISC.CLASSFUL">9.5. Classful Queueing Disciplines</a></h2><p>Classful qdiscs are very useful if you have different kinds of traffic which
should have differing treatment. One of the classful qdiscs is called 'CBQ',
'Class Based Queueing' and it is so widely mentioned that people identify
queueing with classes solely with CBQ, but this is not the case.</p><p>CBQ is merely the oldest kid on the block - and also the most complex one.
It may not always do what you want.  This may come as something of a shock
to many who fell for the 'sendmail effect', which teaches us that any
complex technology which doesn't come with documentation must be the best
available.</p><p>More about CBQ and its alternatives shortly.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN876">9.5.1. Flow within classful qdiscs &amp; classes</a></h3><p>When traffic enters a classful qdisc, it needs to be sent to any of the
classes within - it needs to be 'classified'. To determine what to do with a
packet, the so called 'filters' are consulted. It is important to know that
the filters are called from within a qdisc, and not the other way around!</p><p>The filters attached to that qdisc then return with a decision, and the
qdisc uses this to enqueue the packet into one of the classes. Each subclass
may try other filters to see if further instructions apply. If not, the
class enqueues the packet to the qdisc it contains.</p><p>Besides containing other qdiscs, most classful qdiscs also perform shaping.
This is useful to perform both packet scheduling (with SFQ, for example) and
rate control. You need this in cases where you have a high speed
interface (for example, ethernet) to a slower device (a cable modem).</p><p>If you were only to run SFQ, nothing would happen, as packets enter &amp;
leave your router without delay: the output interface is far faster than
your actual link speed. There is no queue to schedule then.</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN882">9.5.2. The qdisc family: roots, handles, siblings and parents</a></h3><p>Each interface has one egress 'root qdisc'. By default, it is the earlier mentioned
classless pfifo_fast queueing discipline. Each qdisc and class is assigned a
handle, which can be used by later configuration statements to refer to that
qdisc. Besides an egress qdisc, an interface may also have an ingress qdisc ,
which polices traffic coming in.</p><p>The handles of these qdiscs consist of two parts, a major number and a minor
number : &lt;major&gt;:&lt;minor&gt;. It is customary to name the root qdisc '1:', which
is equal to '1:0'.  The minor number of a qdisc is always 0. </p><p>Classes need to have the same major number as their parent.  This major number
must be unique within a egress or ingress setup.  The minor number must be
unique within a qdisc and his classes.</p><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN887">9.5.2.1. How filters are used to classify traffic</a></h4><p>Recapping, a typical hierarchy might look like this:

</p><pre class="SCREEN">                     1:   root qdisc
                      |
                     1:1    child class
                   /  |  \
                  /   |   \
                 /    |    \
                 /    |    \
              1:10  1:11  1:12   child classes
               |      |     | 
               |     11:    |    leaf class
               |            | 
               10:         12:   qdisc
              /   \       /   \
           10:1  10:2   12:1  12:2   leaf classes</pre><p></p><p>But don't let this tree fool you! You should *not* imagine the kernel to be
at the apex of the tree and the network below, that is just not the case.
Packets get enqueued and dequeued at the root qdisc, which is the only thing
the kernel talks to. </p><p>A packet might get classified in a chain like this:</p><p>1: -&gt; 1:1 -&gt; 1:12 -&gt; 12: -&gt; 12:2</p><p>The packet now resides in a queue in a qdisc attached to class 12:2. In this
example, a filter was attached to each 'node' in the tree, each choosing a
branch to take next. This can make sense. However, this is also possible:</p><p>1: -&gt; 12:2</p><p>In this case, a filter attached to the root decided to send the packet
directly to 12:2.</p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN897">9.5.2.2. How packets are dequeued to the hardware</a></h4><p>When the kernel decides that it needs to extract packets to send to the
interface, the root qdisc 1: gets a dequeue request, which is passed to
1:1, which is in turn passed to 10:, 11: and 12:, each of which queries its
siblings, and tries to dequeue() from them. In this case, the kernel needs to
walk the entire tree, because only 12:2 contains a packet. </p><p>In short, nested classes ONLY talk to their parent qdiscs, never to an
interface. Only the root qdisc gets dequeued by the kernel!</p><p>The upshot of this is that classes never get dequeued faster than their
parents allow. And this is exactly what we want: this way we can have SFQ in
an inner class, which doesn't do any shaping, only scheduling, and have a
shaping outer qdisc, which does the shaping.</p></div></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN902">9.5.3. The PRIO qdisc</a></h3><p>The PRIO qdisc doesn't actually shape, it only subdivides traffic based on
how you configured your filters. You can consider the PRIO qdisc a kind
of pfifo_fast on steroids, whereby each band is a separate class instead of
a simple FIFO.</p><p>When a packet is enqueued to the PRIO qdisc, a class is chosen based on the
filter commands you gave. By default, three classes are created. These
classes by default contain pure FIFO qdiscs with no internal
structure, but you can replace these by any qdisc you have available.</p><p>Whenever a packet needs to be dequeued, class :1 is tried first. Higher
classes are only used if lower bands all did not give up a packet.</p><p>This qdisc is very useful in case you want to prioritize certain kinds of
traffic without using only TOS-flags but using all the power of the tc
filters. You can also add an other qdisc to the 3 predefined classes,
whereas pfifo_fast is limited to simple fifo qdiscs.</p><p>Because it doesn't actually shape, the same warning as for SFQ holds: either
use it only if your physical link is really full or wrap it inside a
classful qdisc that does shape. The latter holds for almost all cable modems
and DSL devices.</p><p>In formal words, the PRIO qdisc is a Work-Conserving scheduler.</p><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN910">9.5.3.1. PRIO parameters &amp; usage</a></h4><p>The following parameters are recognized by tc:
</p><p></p><div class="VARIABLELIST"><dl><dt>bands</dt><dd><p>Number of bands to create. Each band is in fact a class. If you change this
number, you must also change:</p></dd><dt>priomap</dt><dd><p>If you do not provide tc filters to classify traffic, the PRIO qdisc looks
at the TC_PRIO priority to decide how to enqueue traffic. </p><p>This works just like with the pfifo_fast qdisc mentioned earlier, see there
for lots of detail.</p></dd></dl></div>
The bands are classes, and are called major:1 to major:3 by default, so if
your PRIO qdisc is called 12:, tc filter traffic to 12:1 to grant it more
priority.<p></p><p>Reiterating, band 0 goes to minor number 1! Band 1 to minor number 2, etc.</p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN924">9.5.3.2. Sample configuration</a></h4><p>We will create this tree:

</p><pre class="SCREEN">          1:   root qdisc
         / | \ 
       /   |   \
       /   |   \
     1:1  1:2  1:3    classes
      |    |    |
     10:  20:  30:    qdiscs    qdiscs
     sfq  tbf  sfq
band  0    1    2</pre><p></p><p>Bulk traffic will go to 30:, interactive traffic to 20: or 10:.</p><p>Command lines:

</p><pre class="SCREEN"># tc qdisc add dev eth0 root handle 1: prio 
## This *instantly* creates classes 1:1, 1:2, 1:3
  
# tc qdisc add dev eth0 parent 1:1 handle 10: sfq
# tc qdisc add dev eth0 parent 1:2 handle 20: tbf rate 20kbit buffer 1600 limit 3000
# tc qdisc add dev eth0 parent 1:3 handle 30: sfq                                </pre><p></p><p>Now let's see what we created:

</p><pre class="SCREEN"># tc -s qdisc ls dev eth0 
qdisc sfq 30: quantum 1514b 
 Sent 0 bytes 0 pkts (dropped 0, overlimits 0) 

 qdisc tbf 20: rate 20Kbit burst 1599b lat 667.6ms 
 Sent 0 bytes 0 pkts (dropped 0, overlimits 0) 

 qdisc sfq 10: quantum 1514b 
 Sent 132 bytes 2 pkts (dropped 0, overlimits 0) 

 qdisc prio 1: bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1
 Sent 174 bytes 3 pkts (dropped 0, overlimits 0) </pre>

As you can see, band 0 has already had some traffic, and one packet was sent
while running this command!<p></p><p>We now do some bulk data transfer with a tool that properly sets TOS flags,
and take another look:

</p><pre class="SCREEN"># scp tc ahu@10.0.0.11:./
ahu@10.0.0.11's password: 
tc                   100% |*****************************|   353 KB    00:00    
# tc -s qdisc ls dev eth0
qdisc sfq 30: quantum 1514b 
 Sent 384228 bytes 274 pkts (dropped 0, overlimits 0) 

 qdisc tbf 20: rate 20Kbit burst 1599b lat 667.6ms 
 Sent 2640 bytes 20 pkts (dropped 0, overlimits 0) 

 qdisc sfq 10: quantum 1514b 
 Sent 2230 bytes 31 pkts (dropped 0, overlimits 0) 

 qdisc prio 1: bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1
 Sent 389140 bytes 326 pkts (dropped 0, overlimits 0) </pre>

As you can see, all traffic went to handle 30:, which is the lowest priority
band, just as intended. Now to verify that interactive traffic goes to
higher bands, we create some interactive traffic:<p></p><p></p><pre class="SCREEN"># tc -s qdisc ls dev eth0
qdisc sfq 30: quantum 1514b 
 Sent 384228 bytes 274 pkts (dropped 0, overlimits 0) 

 qdisc tbf 20: rate 20Kbit burst 1599b lat 667.6ms 
 Sent 2640 bytes 20 pkts (dropped 0, overlimits 0) 

 qdisc sfq 10: quantum 1514b 
 Sent 14926 bytes 193 pkts (dropped 0, overlimits 0) 

 qdisc prio 1: bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1
 Sent 401836 bytes 488 pkts (dropped 0, overlimits 0) </pre><p></p><p>It worked - all additional traffic has gone to 10:, which is our highest
priority qdisc. No traffic was sent to the lowest priority, which previously
received our entire scp.</p></div></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN938">9.5.4. The famous CBQ qdisc</a></h3><p>As said before, CBQ is the most complex qdisc available, the most hyped, the
least understood, and probably the trickiest one to get right. This is not
because the authors are evil or incompetent, far from it, it's just that the
CBQ algorithm isn't all that precise and doesn't really match the way Linux
works.</p><p>Besides being classful, CBQ is also a shaper and it is in that aspect that
it really doesn't work very well. It should work like this. If you try to
shape a 10mbit/s connection to 1mbit/s, the link should be idle 90% of the
time. If it isn't, we need to throttle so that it IS idle 90% of the time.</p><p>This is pretty hard to measure, so CBQ  instead derives the idle time from
the number of microseconds that elapse between requests from the hardware
layer for more data. Combined, this can be used to approximate how full or
empty the link is.</p><p>This is rather tortuous and doesn't always arrive at proper results. For
example, what if the actual link speed of an interface that is not really
able to transmit the full 100mbit/s of data, perhaps because of a badly
implemented driver? A PCMCIA network card will also never achieve 100mbit/s
because of the way the bus is designed - again, how do we calculate the idle
time?</p><p>It gets even worse if we consider not-quite-real network devices like PPP
over Ethernet or PPTP over TCP/IP. The effective bandwidth in that case is
probably determined by the efficiency of pipes to userspace - which is huge.</p><p>People who have done measurements discover that CBQ is not always very
accurate and sometimes completely misses the mark.</p><p>In many circumstances however it works well. With the documentation provided
here, you should be able to configure it to work well in most cases.</p><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN947">9.5.4.1. CBQ shaping in detail</a></h4><p>As said before, CBQ works by making sure that the link is idle just long
enough to bring down the real bandwidth to the configured rate. To do so, it
calculates the time that should pass between average packets. </p><p>During operations, the effective idletime is measured using an exponential
weighted moving average (EWMA), which considers recent packets to be
exponentially more important than past ones. The UNIX loadaverage is
calculated in the same way.</p><p>The calculated idle time is subtracted from the EWMA measured one, the
resulting number is called 'avgidle'. A perfectly loaded link has an avgidle
of zero: packets arrive exactly once every calculated interval.  </p><p>An overloaded link has a negative avgidle and if it gets too negative, CBQ
shuts down for a while and is then 'overlimit'.</p><p>Conversely, an idle link might amass a huge avgidle, which would then allow
infinite bandwidths after a few hours of silence. To prevent this, avgidle is
capped at maxidle.</p><p>If overlimit, in theory, the CBQ could throttle itself for exactly the
amount of time that was calculated to pass between packets, and then pass
one packet, and throttle again. But see the 'minburst' parameter below.</p><p>These are parameters you can specify in order to configure shaping:
</p><p></p><div class="VARIABLELIST"><dl><dt>avpkt</dt><dd><p>Average size of a packet, measured in bytes. Needed for calculating maxidle,
which is derived from maxburst, which is specified in packets.</p></dd><dt>bandwidth</dt><dd><p>The physical bandwidth of your device, needed for idle time
calculations.</p></dd><dt>cell</dt><dd><p>The time a packet takes to be transmitted over a device may grow in steps,
based on the packet size. An 800 and an 806 size packet may take just as long
to send, for example - this sets the granularity. Most often set to '8'.
Must be an integral power of two.</p></dd><dt>maxburst</dt><dd><p>This number of packets is used to calculate maxidle so that when avgidle is
at maxidle, this number of average packets can be burst before avgidle drops
to 0. Set it higher to be more tolerant of bursts. You can't set maxidle
directly, only via this parameter.</p></dd><dt>minburst</dt><dd><p>As mentioned before, CBQ needs to throttle in case of overlimit. The ideal
solution is to do so for exactly the calculated idle time, and pass 1
packet. For Unix kernels, however, it is generally hard to schedule events
shorter than 10ms, so it is better to throttle for a longer period, and then
pass minburst packets in one go, and then sleep minburst times longer.</p><p>The time to wait is called the offtime. Higher values of minburst lead to
more accurate shaping in the long term, but to bigger bursts at millisecond
timescales.</p></dd><dt>minidle</dt><dd><p>If avgidle is below 0, we are overlimits and need to wait until avgidle will
be big enough to send one packet. To prevent a sudden burst from shutting
down the link for a prolonged period of time, avgidle is reset to minidle if
it gets too low.</p><p>Minidle is specified in negative microseconds, so 10 means that avgidle is
capped at -10us.</p></dd><dt>mpu</dt><dd><p>Minimum packet size - needed because even a zero size packet is padded
to 64 bytes on ethernet, and so takes a certain time to transmit. CBQ needs
to know this to accurately calculate the idle time.</p></dd><dt>rate</dt><dd><p>Desired rate of traffic leaving this qdisc - this is the 'speed knob'!</p></dd></dl></div><p></p><p>Internally, CBQ has a lot of fine tuning. For example, classes which are
known not to have data enqueued to them aren't queried. Overlimit classes
are penalized by lowering their effective priority. All very smart &amp;
complicated.</p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN992">9.5.4.2. CBQ classful behaviour</a></h4><p>Besides shaping, using the aforementioned idletime approximations, CBQ also
acts like the PRIO queue in the sense that classes can have differing
priorities and that lower priority numbers will be polled before the higher
priority ones.</p><p>Each time a packet is requested by the hardware layer to be sent out to the
network, a weighted round robin process ('WRR') starts, beginning with the
lower-numbered priority classes.</p><p>These are then grouped and queried if they have data available. If so, it is
returned. After a class has been allowed to dequeue a number of bytes, the
next class within that priority is tried.</p><p>The following parameters control the WRR process:
</p><p></p><div class="VARIABLELIST"><dl><dt>allot</dt><dd><p>When the outer CBQ is asked for a packet to send out on the interface, it
will try all inner qdiscs (in the classes) in turn, in order of 
the 'priority' parameter. Each time a class gets its turn, it can only send out
a limited amount of data. 'Allot' is the base unit of this amount. See 
the 'weight' parameter for more information.</p></dd><dt>prio</dt><dd><p>The CBQ can also act like the PRIO device. Inner classes with higher priority
are tried first and as long as they have traffic, other classes are not
polled for traffic.</p></dd><dt>weight</dt><dd><p>Weight helps in the Weighted Round Robin process. Each class gets a chance
to send in turn. If you have classes with significantly more bandwidth than
other classes, it makes sense to allow them to send more data in one round
than the others.</p><p>A CBQ adds up all weights under a class, and normalizes them, so you can use
arbitrary numbers: only the ratios are important. People have been 
using 'rate/10' as a rule of thumb and it appears to work well. The renormalized
weight is multiplied by the 'allot' parameter to determine how much data can
be sent in one round. </p></dd></dl></div><p></p><p>Please note that all classes within an CBQ hierarchy need to share the same
major number!</p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN1013">9.5.4.3. CBQ parameters that determine link sharing &amp; borrowing</a></h4><p>Besides purely limiting certain kinds of traffic, it is also possible to
specify which classes can borrow capacity from other classes or, conversely,
lend out bandwidth.</p><p></p><p></p><div class="VARIABLELIST"><dl><dt>Isolated/sharing</dt><dd><p>A class that is configured with 'isolated' will not lend out bandwidth to
sibling classes. Use this if you have competing or mutually-unfriendly
agencies on your link who do not want to give each other freebies.</p><p>The control program tc also knows about 'sharing', which is the reverse 
of 'isolated'.</p></dd><dt>bounded/borrow</dt><dd><p>A class can also be 'bounded', which means that it will not try to borrow
bandwidth from sibling classes. tc also knows about 'borrow', which is the
reverse of 'bounded'.</p></dd></dl></div>
A typical situation might be where you have two agencies on your link which
are both 'isolated' and 'bounded', which means that they are really limited
to their assigned rate, and also won't allow each other to borrow.<p></p><p>Within such an agency class, there might be other classes which are allowed
to swap bandwidth.</p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN1028">9.5.4.4. Sample configuration</a></h4><pre class="SCREEN">               1:           root qdisc
               |
              1:1           child class
             /   \
            /     \
          1:3     1:4       leaf classes
           |       |
          30:     40:       qdiscs
         (sfq)   (sfq)</pre><p>This configuration limits webserver traffic to 5mbit and SMTP traffic to 3
mbit. Together, they may not get more than 6mbit. We have a 100mbit NIC and
the classes may borrow bandwidth from each other.

</p><pre class="SCREEN"># tc qdisc add dev eth0 root handle 1:0 cbq bandwidth 100Mbit         \
  avpkt 1000 cell 8
# tc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 100Mbit  \
  rate 6Mbit weight 0.6Mbit prio 8 allot 1514 cell 8 maxburst 20      \
  avpkt 1000 bounded</pre>

This part installs the root and the customary 1:1 class. The 1:1 class is
bounded, so the total bandwidth can't exceed 6mbit.<p></p><p>As said before, CBQ requires a *lot* of knobs. All parameters are explained
above, however. The corresponding HTB configuration is lots simpler.</p><p></p><pre class="SCREEN"># tc class add dev eth0 parent 1:1 classid 1:3 cbq bandwidth 100Mbit  \
  rate 5Mbit weight 0.5Mbit prio 5 allot 1514 cell 8 maxburst 20      \
  avpkt 1000                       
# tc class add dev eth0 parent 1:1 classid 1:4 cbq bandwidth 100Mbit  \
  rate 3Mbit weight 0.3Mbit prio 5 allot 1514 cell 8 maxburst 20      \
  avpkt 1000</pre><p></p><p>These are our two leaf classes. Note how we scale the weight with the configured
rate. Both classes are not bounded, but they are connected to class 1:1
which is bounded.  So the sum of bandwith of the 2 classes will never be
more than 6mbit. The classids need to be within the same major number as
the parent qdisc, by the way!</p><p></p><pre class="SCREEN"># tc qdisc add dev eth0 parent 1:3 handle 30: sfq
# tc qdisc add dev eth0 parent 1:4 handle 40: sfq</pre><p></p><p>Both classes have a FIFO qdisc by default.  But we replaced these with an SFQ
queue so each flow of data is treated equally.

</p><pre class="SCREEN"># tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 match ip \
  sport 80 0xffff flowid 1:3
# tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 match ip \
  sport 25 0xffff flowid 1:4</pre><p></p><p>These commands, attached directly to the root, send traffic to the right
qdiscs.</p><p>Note that we use 'tc class add' to CREATE classes within a qdisc, but that
we use 'tc qdisc add' to actually add qdiscs to these classes.</p><p>You may wonder what happens to traffic that is not classified by any of the
two rules. It appears that in this case, data will then be processed within
1:0, and be unlimited. </p><p>If SMTP+web together try to exceed the set limit of 6mbit/s, bandwidth will
be divided according to the weight parameter, giving 5/8 of traffic to  the
webserver and 3/8 to the mail server.</p><p>With this configuration you can also say that webserver traffic will always
get at minimum 5/8 * 6 mbit = 3.75 mbit.</p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN1046">9.5.4.5. Other CBQ parameters: split &amp; defmap</a></h4><p>As said before, a classful qdisc needs to call filters to determine
which class a packet will be enqueued to. </p><p>Besides calling the filter, CBQ offers other options, defmap &amp; split.
This is pretty complicated to understand, and it is not vital. But as this
is the only known place where defmap &amp; split are properly explained, I'm
doing my best. </p><p>As you will often want to filter on the Type of Service field only, a special
syntax is provided. Whenever the CBQ needs to figure out where a packet
needs to be enqueued, it checks if this node is a 'split node'. If so, one
of the sub-qdiscs has indicated that it wishes to receive all packets with
a certain configured priority, as might be derived from the TOS field, or
socket options set by applications.</p><p>The packets' priority bits are and-ed with the defmap field to see if a match
exists. In other words, this is a short-hand way of creating a very fast
filter, which only matches certain priorities. A defmap of ff (hex) will
match everything, a map of 0 nothing. A sample configuration may help make
things clearer:</p><p></p><pre class="SCREEN"># tc qdisc add dev eth1 root handle 1: cbq bandwidth 10Mbit allot 1514 \
  cell 8 avpkt 1000 mpu 64
 
# tc class add dev eth1 parent 1:0 classid 1:1 cbq bandwidth 10Mbit    \
  rate 10Mbit allot 1514 cell 8 weight 1Mbit prio 8 maxburst 20        \
  avpkt 1000</pre>

Standard CBQ preamble. I never get used to the sheer amount of numbers
required!<p></p><p>Defmap refers to TC_PRIO bits, which are defined as follows:</p><p></p><pre class="SCREEN">TC_PRIO..          Num  Corresponds to TOS
-------------------------------------------------
BESTEFFORT         0    Maximize Reliablity        
FILLER             1    Minimize Cost              
BULK               2    Maximize Throughput (0x8)  
INTERACTIVE_BULK   4                               
INTERACTIVE        6    Minimize Delay (0x10)      
CONTROL            7                               </pre><p></p><p>The TC_PRIO.. number corresponds to bits, counted from the right. See the
pfifo_fast section for more details how TOS bits are converted to
priorities.</p><p>Now the interactive and the bulk classes:</p><p></p><pre class="SCREEN"># tc class add dev eth1 parent 1:1 classid 1:2 cbq bandwidth 10Mbit     \
  rate 1Mbit allot 1514 cell 8 weight 100Kbit prio 3 maxburst 20        \
  avpkt 1000 split 1:0 defmap c0

# tc class add dev eth1 parent 1:1 classid 1:3 cbq bandwidth 10Mbit     \
  rate 8Mbit allot 1514 cell 8 weight 800Kbit prio 7 maxburst 20        \
  avpkt 1000 split 1:0 defmap 3f</pre><p></p><p>The 'split qdisc' is 1:0, which is where the choice will be made. C0 is
binary for 11000000, 3F for 00111111, so these two together will match
everything. The first class matches bits 7 &amp; 6, and thus corresponds 
to 'interactive' and 'control' traffic. The second class matches the rest.</p><p>Node 1:0 now has a table like this:

</p><pre class="SCREEN">priority	send to
0		1:3
1		1:3
2		1:3
3		1:3
4		1:3
5		1:3
6		1:2
7		1:2</pre><p></p><p>For additional fun, you can also pass a 'change mask', which indicates
exactly which priorities you wish to change. You only need to use this if you
are running 'tc class change'. For example, to add best effort traffic to
1:2, we could run this:</p><p></p><pre class="SCREEN"># tc class change dev eth1 classid 1:2 cbq defmap 01/01</pre><p></p><p>The priority map at 1:0 now looks like this:</p><p></p><pre class="SCREEN">priority	send to
0		1:2
1		1:3
2		1:3
3		1:3
4		1:3
5		1:3
6		1:2
7		1:2</pre><p></p><p>FIXME: did not test 'tc class change', only looked at the source.</p></div></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1071">9.5.5. Hierarchical Token Bucket</a></h3><p>Martin Devera (&lt;devik&gt;) rightly realised that CBQ is complex and does
not seem optimized for many typical situations. His Hierarchical approach is
well suited for setups where you have a fixed amount of bandwidth which you
want to divide for different purposes, giving each purpose a guaranteed
bandwidth, with the possibility of specifying how much bandwidth can be
borrowed.</p><p>HTB works just like CBQ but does not resort to idle time calculations to
shape. Instead, it is a classful Token Bucket Filter - hence the name. It
has only a few parameters, which are well documented on his 
<a href="http://luxik.cdi.cz/~devik/qos/htb/" target="_top">site</a>.</p><p>As your HTB configuration gets more complex, your configuration scales
well. With CBQ it is already complex even in simple cases! HTB3 (check
<a href="http://luxik.cdi.cz/~devik/qos/htb/" target="_top">its homepage</a> for
details on HTB versions) is now part of the official kernel sources 
(from 2.4.20-pre1 and 2.5.31 onwards). However, maybe you still need to
get a HTB3 patched version of 'tc': HTB kernel and userspace parts must
be the same major version, or 'tc' will not work with HTB.</p><p>If you already have a modern kernel, or are in a position to patch your 
kernel, by all means consider HTB.</p><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN1079">9.5.5.1. Sample configuration</a></h4><p>Functionally almost identical to the CBQ sample configuration above:</p><p></p><pre class="SCREEN"># tc qdisc add dev eth0 root handle 1: htb default 30

# tc class add dev eth0 parent 1: classid 1:1 htb rate 6mbit burst 15k

# tc class add dev eth0 parent 1:1 classid 1:10 htb rate 5mbit burst 15k
# tc class add dev eth0 parent 1:1 classid 1:20 htb rate 3mbit ceil 6mbit burst 15k
# tc class add dev eth0 parent 1:1 classid 1:30 htb rate 1kbit ceil 6mbit burst 15k</pre><p></p><p>The author then recommends SFQ for beneath these classes:

</p><pre class="SCREEN"># tc qdisc add dev eth0 parent 1:10 handle 10: sfq perturb 10
# tc qdisc add dev eth0 parent 1:20 handle 20: sfq perturb 10
# tc qdisc add dev eth0 parent 1:30 handle 30: sfq perturb 10</pre>
 <p></p><p>Add the filters which direct traffic to the right classes:

</p><pre class="SCREEN"># U32="tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32"
# $U32 match ip dport 80 0xffff flowid 1:10
# $U32 match ip sport 25 0xffff flowid 1:20</pre>

And that's it - no unsightly unexplained numbers, no undocumented
parameters. <p></p><p>HTB certainly looks wonderful - if 10: and 20: both have their guaranteed
bandwidth, and more is left to divide, they borrow in a 5:3 ratio, just as
you would expect.</p><p>Unclassified traffic gets routed to 30:, which has little bandwidth of its
own but can borrow everything that is left over. Because we chose SFQ
internally, we get fairness thrown in for free!</p></div></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.QDISC.FILTERS">9.6. Classifying packets with filters</a></h2><p>To determine which class shall process a packet, the so-called 'classifier
chain' is called each time a choice needs to be made. This chain consists of
all filters attached to the classful qdisc that needs to decide.</p><p>To reiterate the tree, which is not a tree:</p><pre class="SCREEN">                    root 1:
                      |
                    _1:1_
                   /  |  \
                  /   |   \
                 /    |    \
               10:   11:   12:
              /   \       /   \
           10:1  10:2   12:1  12:2</pre><p>When enqueueing a packet, at each branch the filter chain is consulted for a
relevant instruction. A typical setup might be to have a filter in 1:1 that
directs a packet to 12: and a filter on 12: that sends the packet to 12:2.</p><p>You might also attach this latter rule to 1:1, but you can make efficiency
gains by having more specific tests lower in the chain.</p><p>You can't filter a packet 'upwards', by the way. Also, with HTB, you should
attach all filters to the root!</p><p>And again - packets are only enqueued downwards! When they are dequeued,
they go up again, where the interface lives. They do NOT fall off the end of
the tree to the network adaptor!</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1099">9.6.1. Some simple filtering examples</a></h3><p>As explained in the Classifier chapter, you can match on literally anything,
using a very complicated syntax. To start, we will show how to do the
obvious things, which luckily are quite easy.</p><p>Let's say we have a PRIO qdisc called '10:' which contains three classes, and
we want to assign all traffic from and to port 22 to the highest priority
band, the filters would be:</p><p></p><pre class="SCREEN"># tc filter add dev eth0 protocol ip parent 10: prio 1 u32 match \ 
  ip dport 22 0xffff flowid 10:1
# tc filter add dev eth0 protocol ip parent 10: prio 1 u32 match \
  ip sport 80 0xffff flowid 10:1
# tc filter add dev eth0 protocol ip parent 10: prio 2 flowid 10:2</pre><p></p><p>What does this say? It says: attach to eth0, node 10: a  priority 1 u32
filter that matches on IP destination port 22 *exactly* and send it to band
10:1. And it then repeats the same for source port 80. The last command says
that anything unmatched so far should go to band 10:2, the next-highest
priority.</p><p>You need to add 'eth0', or whatever your interface is called, because each
interface has a unique namespace of handles.</p><p>To select on an IP address, use this:

</p><pre class="SCREEN"># tc filter add dev eth0 parent 10:0 protocol ip prio 1 u32 \ 
  match ip dst 4.3.2.1/32 flowid 10:1
# tc filter add dev eth0 parent 10:0 protocol ip prio 1 u32 \
  match ip src 1.2.3.4/32 flowid 10:1
# tc filter add dev eth0 protocol ip parent 10: prio 2      \
  flowid 10:2</pre><p></p><p>This assigns traffic to 4.3.2.1 and traffic from 1.2.3.4 to the highest
priority queue, and the rest to the next-highest one.</p><p>You can concatenate matches, to match on traffic from 1.2.3.4 and from port
80, do this:

</p><pre class="SCREEN"># tc filter add dev eth0 parent 10:0 protocol ip prio 1 u32 match ip src 4.3.2.1/32 \
  match ip sport 80 0xffff flowid 10:1</pre><p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.FILTERING.SIMPLE">9.6.2. All the filtering commands you will normally need</a></h3><p>Most shaping commands presented here start with this preamble:

</p><pre class="SCREEN"># tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 ..</pre>

These are the so called 'u32' matches, which can match on ANY part of a
packet.
<p></p><div class="VARIABLELIST"><dl><dt>On source/destination address</dt><dd><p>Source mask 'match ip src 1.2.3.0/24', destination mask 'match ip dst
4.3.2.0/24'. To match a single host, use /32, or omit the mask.</p></dd><dt>On source/destination port, all IP protocols</dt><dd><p>Source: 'match ip sport 80 0xffff', destination: 'match ip dport 80 0xffff'</p></dd><dt>On ip protocol (tcp, udp, icmp, gre, ipsec)</dt><dd><p>Use the numbers from /etc/protocols, for example, icmp is 1: 'match ip
protocol 1 0xff'. </p></dd><dt>On fwmark</dt><dd><p>You can mark packets with either ipchains or iptables and have that mark
survive routing across interfaces. This is really useful to for example only
shape traffic on eth1 that came in on eth0. Syntax:
</p><pre class="SCREEN"># tc filter add dev eth1 protocol ip parent 1:0 prio 1 handle 6 fw flowid 1:1</pre>
Note that this is not a u32 match!<p></p><p>You can place a mark like this:

</p><pre class="SCREEN"># iptables -A PREROUTING -t mangle -i eth0 -j MARK --set-mark 6</pre>

The number 6 is arbitrary.<p></p><p>If you don't want to understand the full tc filter syntax, just use
iptables, and only learn to select on fwmark. You can also have iptables
print basic statistics that will help you debug your rules.
The following command will show you all the rules that mark packages
in the mangle table, also how many packages and bytes have matched.

</p><pre class="SCREEN"># iptables -L -t mangle -n -v</pre>
<p></p></dd><dt>On the TOS field</dt><dd><p>To select interactive, minimum delay traffic:

</p><pre class="SCREEN"># tc filter add dev ppp0 parent 1:0 protocol ip prio 10 u32 \
      match ip tos 0x10 0xff \
     flowid 1:4</pre>

Use 0x08 0xff for bulk traffic.<p></p></dd></dl></div><p></p><p>For more filtering commands, see the Advanced Filters chapter.</p></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.IMQ">9.7. The Intermediate queueing device (IMQ)</a></h2><p>The Intermediate queueing device is not a qdisc but its usage is tightly bound
to qdiscs. Within linux, qdiscs are attached to network devices and everything
that is queued to the device is first queued to the qdisc. From this concept,
two limitations arise:</p><p></p><ol type="1"><li><p>Only egress shaping is possible (an ingress qdisc exists, but its
possibilities are very limited compared to classful qdiscs).</p></li><li><p>A qdisc can only see traffic of one interface, global limitations can't be
placed.</p></li></ol><p>IMQ is there to help solve those two limitations. In short, you can put 
everything you choose in a qdisc. Specially marked packets get intercepted
in netfilter NF_IP_PRE_ROUTING and NF_IP_POST_ROUTING hooks and pass through
the qdisc attached to an imq device. An iptables target is used for marking
the packets.</p><p>This enables you to do ingress shaping as you can 
just mark packets coming in from somewhere and/or treat interfaces as 
classes to set global limits.
You can also do lots of other stuff like just putting your http traffic 
in a
qdisc, put new connection requests in a qdisc, ...</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1154">9.7.1. Sample configuration</a></h3><p>The first thing that might come to mind is use ingress shaping to give yourself
a high guaranteed bandwidth. ;)
Configuration is just like with any other interface:

</p><pre class="SCREEN">tc qdisc add dev imq0 root handle 1: htb default 20

tc class add dev imq0 parent 1: classid 1:1 htb rate 2mbit burst 15k

tc class add dev imq0 parent 1:1 classid 1:10 htb rate 1mbit
tc class add dev imq0 parent 1:1 classid 1:20 htb rate 1mbit

tc qdisc add dev imq0 parent 1:10 handle 10: pfifo
tc qdisc add dev imq0 parent 1:20 handle 20: sfq

tc filter add dev imq0 parent 10:0 protocol ip prio 1 u32 match \
		ip dst 10.0.0.230/32 flowid 1:10</pre>

In this example u32 is used for classification. Other classifiers should work as
expected.
Next traffic has to be selected and marked to be enqueued to imq0.

<pre class="SCREEN">iptables -t mangle -A PREROUTING -i eth0 -j IMQ --todev 0

ip link set imq0 up</pre><p></p><p>The IMQ iptables targets is valid in the PREROUTING and POSTROUTING chains of
the mangle table. It's syntax is 

</p><pre class="SCREEN">IMQ [ --todev n ]	n : number of imq device</pre>

An ip6tables target is also provided.<p></p><p>Please note traffic is not enqueued when the target is hit but afterwards.
The exact location where traffic enters the imq device depends on the
direction of the traffic (in/out).
These are the predefined netfilter hooks used by iptables:

</p><pre class="SCREEN">enum nf_ip_hook_priorities {
        NF_IP_PRI_FIRST = INT_MIN,
        NF_IP_PRI_CONNTRACK = -200,
        NF_IP_PRI_MANGLE = -150,
        NF_IP_PRI_NAT_DST = -100,
        NF_IP_PRI_FILTER = 0,
        NF_IP_PRI_NAT_SRC = 100,
        NF_IP_PRI_LAST = INT_MAX,
};</pre><p></p><p>For ingress traffic, imq registers itself with NF_IP_PRI_MANGLE + 1 priority
which means packets enter the imq device directly after the mangle PREROUTING
chain has been passed.</p><p>For egress imq uses NF_IP_PRI_LAST which honours the fact that packets dropped
by the filter table won't occupy bandwidth.</p><p>The patches and some more information can be found at the
<a href="http://luxik.cdi.cz/~patrick/imq/" target="_top">imq site</a>.</p></div></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.LOADSHARE"></a>Chapter 10. Load sharing over multiple interfaces</h1><p>There are several ways of doing this. One of the easiest and straightforward
ways is 'TEQL' - "True" (or "trivial") link equalizer. Like most things
having to do with queueing, load sharing goes both ways. Both ends of a link
may need to participate for full effect.</p><p>Imagine this situation:</p><p></p><pre class="SCREEN">                 +-------+   eth1   +-------+
                 |       |==========|       |
 'network 1' ----|   A   |          |   B   |---- 'network 2'
                 |       |==========|       |
                 +-------+   eth2   +-------+</pre><p></p><p>A and B are routers, and for the moment we'll assume both run Linux. If
traffic is going from network 1 to network 2, router A needs to distribute
the packets over both links to B. Router B needs to be configured to accept
this. Same goes the other way around, when packets go from network 2 to
network 1, router B needs to send the packets over both eth1 and eth2.</p><p>The distributing part is done by a 'TEQL' device, like this (it couldn't be
easier):</p><p></p><pre class="SCREEN"># tc qdisc add dev eth1 root teql0
# tc qdisc add dev eth2 root teql0
# ip link set dev teql0 up</pre><p></p><p>Don't forget the 'ip link set up' command!</p><p>This needs to be done on both hosts. The device teql0 is basically a
roundrobbin distributor over eth1 and eth2, for sending packets. No data
ever comes in over an teql device, that just appears on the 'raw' eth1 and
eth2.</p><p>But now we just have devices, we also need proper routing. One way to do
this is to assign a /31 network to both links, and a /31 to the teql0 device
as well:</p><p>On router A:

</p><pre class="SCREEN"># ip addr add dev eth1 10.0.0.0/31
# ip addr add dev eth2 10.0.0.2/31
# ip addr add dev teql0 10.0.0.4/31</pre><p></p><p>On router B:

</p><pre class="SCREEN"># ip addr add dev eth1 10.0.0.1/31
# ip addr add dev eth2 10.0.0.3/31
# ip addr add dev teql0 10.0.0.5/31</pre><p></p><p>Router A should now be able to ping 10.0.0.1, 10.0.0.3 and 10.0.0.5 over the
2 real links and the 1 equalized device. Router B should be able to ping
10.0.0.0, 10.0.0.2 and 10.0.0.4 over the links.</p><p>If this works, Router A should make 10.0.0.5 its route for reaching network
2, and Router B should make 10.0.0.4 its route for reaching network 1. For
the special case where network 1 is your network at home, and network 2 is
the Internet, Router A should make 10.0.0.5 its default gateway.</p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.LOADSHARE.CAVEATS">10.1. Caveats</a></h2><p>Nothing is as easy as it seems. eth1 and eth2 on both router A and B need to
have return path filtering turned off, because they will otherwise drop
packets destined for ip addresses other than their own:</p><p></p><pre class="SCREEN"># echo 0 &gt; /proc/sys/net/ipv4/conf/eth1/rp_filter
# echo 0 &gt; /proc/sys/net/ipv4/conf/eth2/rp_filter</pre><p></p><p>Then there is the nasty problem of packet reordering. Let's say 6 packets
need to be sent from A to B - eth1 might get 1, 3 and 5. eth2 would then do
2, 4 and 6. In an ideal world, router B would receive this in order, 1, 2,
3, 4, 5, 6. But the possibility is very real that the kernel gets it like
this: 2, 1, 4, 3, 6, 5. The problem is that this confuses TCP/IP. While not
a problem for links carrying many different TCP/IP sessions, you won't be
able to bundle multiple links and get to ftp a single file lots faster,
except when your receiving or sending OS is Linux, which is not easily
shaken by some simple reordering.</p><p>However, for lots of applications, link load balancing is a great idea.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.LOADSHARE.OTHER">10.2. Other possibilities</a></h2><p>William Stearns has used an advanced tunneling setup to achieve good use of
multiple, unrelated, internet connections together. It can be found on
<a href="http://www.stearns.org/tunnel/" target="_top">his tunneling page</a>.</p><p>The HOWTO may feature more about this in the future.</p></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.NETFILTER"></a>Chapter 11. Netfilter &amp; iproute - marking packets</h1><p>So far we've seen how iproute works, and netfilter was mentioned a few
times. This would be a good time to browse through <a href="http://netfilter.samba.org/unreliable-guides/" target="_top">Rusty's Remarkably Unreliable Guides</a>. Netfilter itself
can be found <a href="http://netfilter.filewatcher.org/" target="_top">here</a>.</p><p>Netfilter allows us to filter packets, or mangle their headers. One special
feature is that we can mark a packet with a number. This is done with the
--set-mark facility. </p><p>As an example, this command marks all packets destined for port 25, outgoing
mail:</p><p></p><pre class="SCREEN"># iptables -A PREROUTING -i eth0 -t mangle -p tcp --dport 25 \
 -j MARK --set-mark 1</pre><p></p><p>Let's say that we have multiple connections, one that is fast (and
expensive, per megabyte) and one that is slower, but flat fee. We would most
certainly like outgoing mail to go via the cheap route.</p><p>We've already marked the packets with a '1', we now instruct the routing
policy database to act on this:</p><p></p><pre class="SCREEN"># echo 201 mail.out &gt;&gt; /etc/iproute2/rt_tables
# ip rule add fwmark 1 table mail.out
# ip rule ls
0:	from all lookup local 
32764:	from all fwmark        1 lookup mail.out 
32766:	from all lookup main 
32767:	from all lookup default </pre><p></p><p>Now we generate a route to the slow but cheap link in the mail.out table:

</p><pre class="SCREEN"># /sbin/ip route add default via 195.96.98.253 dev ppp0 table mail.out</pre><p></p><p>And we are done. Should we want to make exceptions, there are lots of ways
to achieve this. We can modify the netfilter statement to exclude certain
hosts, or we can insert a rule with a lower priority that points to the main
table for our excepted hosts.</p><p>We can also use this feature to honour TOS bits by marking packets with a
different type of service with different numbers, and creating rules to act
on that. This way you can even dedicate, say, an ISDN line to interactive
sessions.</p><p>Needless to say, this also works fine on a host that's doing NAT
('masquerading').</p><p>IMPORTANT: We received a report that MASQ and SNAT at least collide
with marking packets. Rusty Russell explains it in
<a href="http://lists.samba.org/pipermail/netfilter/2000-November/006089.html" target="_top">this posting</a>. Turn off the reverse path filter to make it work
properly.</p><p>Note: to mark packets, you need to have some options enabled in your
kernel:</p><p></p><pre class="SCREEN">IP: advanced router (CONFIG_IP_ADVANCED_ROUTER) [Y/n/?]
IP: policy routing (CONFIG_IP_MULTIPLE_TABLES) [Y/n/?]
IP: use netfilter MARK value as routing key (CONFIG_IP_ROUTE_FWMARK) [Y/n/?]</pre><p></p><p>See also the <a href="#LARTC.COOKBOOK.SQUID">Section 15.5</a> in the
<i class="CITETITLE"><a href="#LARTC.COOKBOOK">Cookbook</a></i>.</p></div><div class="CHAPTER"><hr><h1><a name="LARTC.ADV-FILTER"></a>Chapter 12. Advanced filters for (re-)classifying packets</h1><p>As explained in the section on classful queueing disciplines, filters are
needed to classify packets into any of the sub-queues. These filters are
called from within the classful qdisc.</p><p>Here is an incomplete list of classifiers available:
</p><p></p><div class="VARIABLELIST"><dl><dt>fw</dt><dd><p>Bases the decision on how the firewall has marked the packet. This can be
the easy way out if you don't want to learn tc filter syntax. See the
Queueing chapter for details.</p></dd><dt>u32</dt><dd><p>Bases the decision on fields within the packet (i.e. source IP address, etc)</p></dd><dt>route</dt><dd><p>Bases the decision on which route the packet will be routed by</p></dd><dt>rsvp, rsvp6</dt><dd><p>Routes packets based on <a href="http://www.isi.edu/div7/rsvp/overview.html" target="_top">RSVP </a>. Only useful
on networks you control - the Internet does not respect RSVP.</p></dd><dt>tcindex</dt><dd><p>Used in the DSMARK qdisc, see the relevant section.</p></dd></dl></div><p></p><p>Note that in general there are many ways in which you can classify packet
and that it generally comes down to preference as to which system you wish
to use.</p><p>Classifiers in general accept a few arguments in common. They are listed
here for convenience:</p><p></p><p></p><div class="VARIABLELIST"><dl><dt>protocol</dt><dd><p>The protocol this classifier will accept. Generally you will only be
accepting only IP traffic. Required.</p></dd><dt>parent</dt><dd><p>The handle this classifier is to be attached to. This handle must be
an already existing class. Required.</p></dd><dt>prio</dt><dd><p>The priority of this classifier. Lower numbers get tested first.</p></dd><dt>handle</dt><dd><p>This handle means different things to different filters.</p></dd></dl></div><p></p><p>All the following sections will assume you are trying to shape the traffic
going to <tt class="LITERAL">HostA</tt>. They will assume that the root class has been
configured on 1: and that the class you want to send the selected traffic to
is 1:1.</p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-FILTER.U32">12.1. The <code class="OPTION">u32</code> classifier</a></h2><p>The U32 filter is the most advanced filter available in the current
implementation. It entirely based on hashing tables, which make it
robust when there are many filter rules.</p><p>In its simplest form the U32 filter is a list of records, each
consisting of two fields: a selector and an action. The selectors,
described below, are compared with the currently processed IP packet
until the first match occurs, and then the associated action is performed.
The simplest type of action would be directing the packet into defined
class.</p><p>The command line of <tt class="LITERAL">tc filter</tt> program, used to configure the filter,
consists of three parts: filter specification, a selector and an action.
The filter specification can be defined as:</p><p></p><pre class="SCREEN">tc filter add dev IF [ protocol PROTO ]
                     [ (preference|priority) PRIO ]
                     [ parent CBQ ]</pre><p></p><p>The <tt class="LITERAL">protocol</tt> field describes protocol that the filter will be
applied to. We will only discuss case of <tt class="LITERAL">ip</tt> protocol. The
<tt class="LITERAL">preference</tt> field (<tt class="LITERAL">priority</tt> can be used alternatively)
sets the priority of currently defined filter. This is important, since
you can have several filters (lists of rules) with different priorities.
Each list will be passed in the order the rules were added, then list with
lower priority (higher preference number) will be processed. The <tt class="LITERAL">parent</tt>
field defines the CBQ tree top (e.g. 1:0), the filter should be attached
to.</p><p>The options described above apply to all filters, not only U32.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1289">12.1.1. U32 selector</a></h3><p>The U32 selector contains definition of the pattern, that will be matched
to the currently processed packet. Precisely, it defines which bits are
to be matched in the packet header and nothing more, but this simple
method is very powerful. Let's take a look at the following examples,
taken directly from a pretty complex, real-world filter:</p><p></p><pre class="SCREEN"># tc filter add dev eth0 protocol ip parent 1:0 pref 10 u32 \
  match u32 00100000 00ff0000 at 0 flowid 1:10</pre><p></p><p>For now, leave the first line alone - all these parameters describe
the filter's hash tables. Focus on the selector line, containing
<tt class="LITERAL">match</tt> keyword. This selector will match to IP headers, whose
second byte will be 0x10 (0010). As you can guess, the 00ff number is
the match mask, telling the filter exactly which bits to match. Here
it's 0xff, so the byte will match if it's exactly 0x10. The <tt class="LITERAL">at</tt>
keyword means that the match is to be started at specified offset (in
bytes) -- in this case it's beginning of the packet.  Translating all
that to human language, the packet will match if its Type of Service
field will have `low delay' bits set. Let's analyze another rule:</p><p></p><pre class="SCREEN"># tc filter add dev eth0 protocol ip parent 1:0 pref 10 u32 \
  match u32 00000016 0000ffff at nexthdr+0 flowid 1:10</pre><p></p><p>The <tt class="LITERAL">nexthdr</tt> option means next header encapsulated in the IP packet,
i.e. header of upper-layer protocol. The match will also start here
at the beginning of the next header. The match should occur in the
second, 32-bit word of the header. In TCP and UDP protocols this field
contains packet's destination port. The number is given in big-endian
format, i.e. older bits first, so we simply read 0x0016 as 22 decimal,
which stands for SSH service if this was TCP. As you guess, this match
is ambiguous without a context, and we will discuss this later.</p><p>Having understood all the above, we will find the following selector
quite easy to read: <tt class="LITERAL">match c0a80100 ffffff00 at 16</tt>. What we
got here is a three byte match at 17-th byte, counting from the IP
header start. This will match for packets with destination address
anywhere in 192.168.1/24 network. After analyzing the examples, we
can summarize what we have learned.</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1303">12.1.2. General selectors</a></h3><p>General selectors define the pattern, mask and offset the pattern
will be matched to the packet contents. Using the general selectors
you can match virtually any single bit in the IP (or upper layer)
header. They are more difficult to write and read, though, than
specific selectors that described below. The general selector syntax
is:</p><p></p><pre class="SCREEN">match [ u32 | u16 | u8 ] PATTERN MASK at [OFFSET | nexthdr+OFFSET]</pre><p></p><p>One of the keywords <tt class="LITERAL">u32</tt>, <tt class="LITERAL">u16</tt> or <tt class="LITERAL">u8</tt> specifies
length of the pattern in bits. PATTERN and MASK should follow, of length
defined by the previous keyword. The OFFSET parameter is the offset,
in bytes, to start matching. If <tt class="LITERAL">nexthdr+</tt> keyword is given,
the offset is relative to start of the upper layer header.</p><p>Some examples:</p><p>Packet will match to this rule, if its time to live (TTL) is 64.
TTL is the field starting just after 8-th byte of the IP header.

</p><pre class="SCREEN"># tc filter add dev ppp14 parent 1:0 prio 10 u32 \
     match u8 64 0xff at 8 \
     flowid 1:4</pre><p></p><p>The following matches all TCP packets which have the ACK bit set:

</p><pre class="SCREEN"># tc filter add dev ppp14 parent 1:0 prio 10 u32 \
     match ip protocol 6 0xff \
     match u8 0x10 0xff at nexthdr+13 \
     flowid 1:3 </pre><p></p><p>Use this to match ACKs on packets smaller than 64 bytes:

</p><pre class="SCREEN">## match acks the hard way,
## IP protocol 6,
## IP header length 0x5(32 bit words),
## IP Total length 0x34 (ACK + 12 bytes of TCP options)
## TCP ack set (bit 5, offset 33)
# tc filter add dev ppp14 parent 1:0 protocol ip prio 10 u32 \
            match ip protocol 6 0xff \
            match u8 0x05 0x0f at 0 \
            match u16 0x0000 0xffc0 at 2 \
            match u8 0x10 0xff at 33 \
            flowid 1:3</pre><p></p><p>This rule will only match TCP packets with ACK bit set, and no further
payload. Here we can see an example of using two selectors, the final result
will be logical AND of their results. If we take a look at TCP header
diagram, we can see that the ACK bit is second older bit (0x10) in the 14-th
byte of the TCP header (<tt class="LITERAL">at nexthdr+13</tt>).  As for the second
selector, if we'd like to make our life harder, we could write <tt class="LITERAL">match u8
0x06 0xff at 9</tt> instead of using the specific selector <tt class="LITERAL">protocol
tcp</tt>, because 6 is the number of TCP protocol, present in 10-th byte of
the IP header. On the other hand, in this example we couldn't use any
specific selector for the first match - simply because there's no specific
selector to match TCP ACK bits.</p><p>The filter below is a modified version of the filter above. The difference is, that it
doesn't check the ip header length. Why? Because the filter above does only work on 32
bit systems.</p><p></p><pre class="SCREEN">tc filter add dev ppp14 parent 1:0 protocol ip prio 10 u32 \
     match ip protocol 6 0xff \
     match u8 0x10 0xff at nexthdr+13 \
     match u16 0x0000 0xffc0 at 2 \
     flowid 1:3</pre><p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1327">12.1.3. Specific selectors</a></h3><p>The following table contains a list of all specific selectors 
the author of this section has found in the <tt class="LITERAL">tc</tt> program
source code. They simply make your life easier and increase readability
of your filter's configuration.</p><p>FIXME: table placeholder - the table is in separate file ,,selector.html''</p><p>FIXME: it's also still in Polish :-(</p><p>FIXME: must be sgml'ized</p><p>Some examples:</p><p></p><pre class="SCREEN"># tc filter add dev ppp0 parent 1:0 prio 10 u32 \
     match ip tos 0x10 0xff \
     flowid 1:4</pre><p></p><p>FIXME: tcp dport match does not work as described below:</p><p>The above rule will match packets which have the TOS field set to 0x10.
The TOS field starts at second byte of the packet and is one byte big,
so we could write an equivalent general selector: <tt class="LITERAL">match u8 0x10 0xff
at 1</tt>. This gives us hint to the internals of U32 filter -- the
specific rules are always translated to general ones, and in this
form they are stored in the kernel memory. This leads to another conclusion
-- the <tt class="LITERAL">tcp</tt> and <tt class="LITERAL">udp</tt> selectors are exactly the same
and this is why you can't use single <tt class="LITERAL">match tcp dport 53 0xffff</tt>
selector to match TCP packets sent to given port -- they will also
match UDP packets sent to this port. You must remember to also specify
the protocol and end up with the following rule:</p><p></p><pre class="SCREEN"># tc filter add dev ppp0 parent 1:0 prio 10 u32 \
        match tcp dport 53 0xffff \
        match ip protocol 0x6 0xff \
        flowid 1:2</pre><p></p></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-FILTER.ROUTE">12.2. The <code class="OPTION">route</code> classifier</a></h2><p>This classifier filters based on the results of the routing tables. When a
packet that is traversing through the classes reaches one that is marked
with the "route" filter, it splits the packets up based on information in
the routing table.</p><p></p><pre class="SCREEN"># tc filter add dev eth1 parent 1:0 protocol ip prio 100 route</pre><p></p><p>Here we add a route classifier onto the parent node 1:0 with priority 100. 
When a packet reaches this node (which, since it is the root, will happen
immediately) it will consult the routing table. If the packet matches, it will
be send to the given class and have a priority of 100. Then, to finally
kick it into action, you add the appropriate routing entry:</p><p>The trick here is to define 'realm' based on either destination or source. 
The way to do it is like this:</p><p></p><pre class="SCREEN"># ip route add Host/Network via Gateway dev Device realm RealmNumber</pre><p></p><p>For instance, we can define our destination network 192.168.10.0 with a realm
number 10:</p><p></p><pre class="SCREEN"># ip route add 192.168.10.0/24 via 192.168.10.1 dev eth1 realm 10</pre>
  <p></p><p>When adding route filters, we can use realm numbers to represent the
networks or hosts and specify how the routes match the filters.</p><p></p><pre class="SCREEN"># tc filter add dev eth1 parent 1:0 protocol ip prio 100 \
  route to 10 classid 1:10</pre>
  <p></p><p>The above rule matches the packets going to the network 192.168.10.0.</p><p>Route filter can also be used to match source routes. For example, there is 
a subnetwork attached to the Linux router on eth2.</p><p></p><pre class="SCREEN"># ip route add 192.168.2.0/24 dev eth2 realm 2
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 \
  route from 2 classid 1:2</pre><p></p><p>Here the filter specifies that packets from the subnetwork 192.168.2.0
(realm 2) will match class id 1:2.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-FILTER.POLICING">12.3. Policing filters</a></h2><p>To make even more complicated setups possible, you can have filters that
only match up to a certain bandwidth. You can declare a filter either to entirely
cease matching above a certain rate, or not to match only the bandwidth
exceeding a certain rate.</p><p>So if you decided to police at 4mbit/s, but 5mbit/s of traffic is present,
you can stop matching either the entire 5mbit/s, or only not match 1mbit/s,
and do send 4mbit/s to the configured class.</p><p>If bandwidth exceeds the configured rate, you can drop a packet, reclassify
it, or see if another filter will match it.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1371">12.3.1. Ways to police</a></h3><p>There are basically two ways to police. If you compiled the kernel 
with 'Estimators', the kernel can measure for each filter how much traffic
it is passing, more or less. These estimators are very easy on the CPU, as
they simply count 25 times per second how many data has been passed, and
calculate the bitrate from that.</p><p>The other way works again via a Token Bucket Filter, this time living within
your filter. The TBF only matches traffic UP TO your configured bandwidth,
if more is offered, only the excess is subject to the configured overlimit
action.</p><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN1375">12.3.1.1. With the kernel estimator</a></h4><p>This is very simple and has only one parameter: avrate. Either the flow
remains below avrate, and the filter classifies the traffic to the classid
configured, or your rate exceeds it in which case the specified action is
taken, which is 'reclassify' by default.</p><p>The kernel uses an Exponential Weighted Moving Average for your bandwidth
which makes it less sensitive to short bursts.</p></div><div class="SECT3"><hr><h4 class="SECT3"><a name="AEN1379">12.3.1.2. With Token Bucket Filter</a></h4><p>Uses the following parameters:

</p><p></p><ul><li><p>burst/buffer/maxburst</p></li><li><p>mtu/minburst</p></li><li><p>mpu</p></li><li><p>rate</p></li></ul><p></p><p>Which behave mostly identical to those described in the Token Bucket Filter
section. Please note however that if you set the mtu of a TBF policer too
low, *no* packets will pass, whereas the egress TBF qdisc will just pass
them slower.</p><p>Another difference is that a policer can only let a packet pass, or drop it.
It cannot hold it in order to delay it.</p></div></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1393">12.3.2. Overlimit actions</a></h3><p>If your filter decides that it is overlimit, it can take 'actions'.
Currently, four actions are available:
</p><p></p><div class="VARIABLELIST"><dl><dt>continue</dt><dd><p>Causes this filter not to match, but perhaps other filters will.</p></dd><dt>drop</dt><dd><p>This is a very fierce option which simply discards traffic exceeding a
certain rate. It is often used in the ingress policer and has limited uses.
For example, you may have a name server that falls over if offered more than
5mbit/s of packets, in which case an ingress filter could be used to make
sure no more is ever offered.</p></dd><dt>Pass/OK</dt><dd><p>Pass on traffic ok. Might be used to disable a complicated filter, but leave
it in place.</p></dd><dt>reclassify</dt><dd><p>Most often comes down to reclassification to Best Effort. This is the
default action.</p></dd></dl></div><p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1413">12.3.3. Examples</a></h3><p>The only real example known is mentioned in the 'Protecting your host 
from SYN floods' section. </p><p>Limit incoming icmp traffic to 2kbit, drop packets
over the limit:</p><pre class="SCREEN">tc filter add dev $DEV parent ffff: \
    protocol ip prio 20 \
    u32 match ip protocol 1 0xff \
    police rate 2kbit buffer 10k drop \
    flowid :1</pre><p>Limit packets to a certain size (i.e. all packets
with a length greater than 84 bytes will get dropped):</p><pre class="SCREEN">tc filter add dev $DEV parent ffff: \
   protocol ip prio 20 \
   u32 match tos 0 0 \
   police mtu 84 drop \
   flowid :1</pre><p>This method can be used to drop all packets:</p><pre class="SCREEN">tc filter add dev $DEV parent ffff: \
   protocol ip prio 20 \
   u32 match ip protocol 1 0xff \
   police mtu 1 drop \
   flowid :1</pre><p>It actually drops icmp packets greater-than 1 byte. While packets with
a size of 1 byte are possible in theory, you will not find these in a real network.</p></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-FILTER.HASHING">12.4. Hashing filters for very fast massive filtering</a></h2><p>If you have a need for thousands of rules, for example if you have a lot of
clients or computers, all with different QoS specifications, you may find
that the kernel spends a lot of time matching all those rules.</p><p>By default, all filters reside in one big chain which is matched in
descending order of priority. If you have 1000 rules, 1000 checks may be
needed to determine what to do with a packet.</p><p>Matching would go much quicker if you would have 256 chains with each four
rules - if you could divide packets over those 256 chains, so that the right
rule will be there.</p><p>Hashing makes this possible. Let's say you have 1024 cable modem customers in
your network, with IP addresses ranging from 1.2.0.0 to 1.2.3.255, and each
has to go in another bin, for example 'lite', 'regular' and 'premium'. You
would then have 1024 rules like this:</p><p></p><pre class="SCREEN"># tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.0.0 classid 1:1
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.0.1 classid 1:1
...
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.3.254 classid 1:3
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.3.255 classid 1:2</pre><p></p><p>To speed this up, we can use the last part of the IP address as a 'hash
key'. We then get 256 tables, the first of which looks like this:

</p><pre class="SCREEN"># tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.0.0 classid 1:1
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.1.0 classid 1:1
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.2.0 classid 1:3
# tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.3.0 classid 1:2</pre><p></p><p>The next one starts like this:

</p><pre class="SCREEN"># tc filter add dev eth1 parent 1:0 protocol ip prio 100 match ip src \
  1.2.0.1 classid 1:1
...</pre><p></p><p>This way, only four checks are needed at most, two on average. </p><p>Configuration is pretty complicated, but very worth it by the time you have
this many rules. First we make a filter root, then we create a table with
256 entries:

</p><pre class="SCREEN"># tc filter add dev eth1 parent 1:0 prio 5 protocol ip u32
# tc filter add dev eth1 parent 1:0 prio 5 handle 2: protocol ip u32 divisor 256</pre><p></p><p>Now we add some rules to entries in the created table:</p><p></p><pre class="SCREEN"># tc filter add dev eth1 protocol ip parent 1:0 prio 5 u32 ht 2:7b: \
        match ip src 1.2.0.123 flowid 1:1
# tc filter add dev eth1 protocol ip parent 1:0 prio 5 u32 ht 2:7b: \
        match ip src 1.2.1.123 flowid 1:2
# tc filter add dev eth1 protocol ip parent 1:0 prio 5 u32 ht 2:7b: \
        match ip src 1.2.3.123 flowid 1:3
# tc filter add dev eth1 protocol ip parent 1:0 prio 5 u32 ht 2:7b: \
        match ip src 1.2.4.123 flowid 1:2</pre>

This is entry 123, which contains matches for 1.2.0.123, 1.2.1.123,
1.2.2.123, 1.2.3.123, and sends them to 1:1, 1:2, 1:3 and 1:2 respectively.
Note that we need to specify our hash bucket in hex, 0x7b is 123.<p></p><p>Next create a 'hashing filter' that directs traffic to the right entry in
the hashing table:

</p><pre class="SCREEN"># tc filter add dev eth1 protocol ip parent 1:0 prio 5 u32 ht 800:: \
        match ip src 1.2.0.0/16 \
        hashkey mask 0x000000ff at 12 \
        link 2:</pre>

Ok, some numbers need explaining. The default hash table is called 800:: and
all filtering starts there. Then we select the source address, which lives
as position 12, 13, 14 and 15 in the IP header, and indicate that we are
only interested in the last part. This will be sent to hash table 2:, which we
created earlier.<p></p><p>It is quite complicated, but it does work in practice and performance will
be staggering. Note that this example could be improved to the ideal case
where each chain contains 1 filter!</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-FILTER.IPV6">12.5. Filtering IPv6 Traffic</a></h2><div class="SECT2"><h3 class="SECT2"><a name="AEN1446">12.5.1. How come that IPv6 tc filters do not work?</a></h3><p>The Routing Policy Database (RPDB) replaced the IPv4 routing and
addressing structure within the Linux Kernel which lead to all the
wonderful features this HOWTO describes. Unfortunately, the IPv6
structure within Linux was implemented outside of this core structure.
Although they do share some facilities, the essential RPDB structure
does not particpate in or with the IPv6 addressing and routing
structures.</p><p>This will change for sure, we just have to wait a little longer.</p><p>FIXME: Any ideas if someone is working on this? Plans?</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1451">12.5.2. Marking IPv6 packets using ip6tables</a></h3><p>ip6tables is able to mark a packet and assign a number to it:</p><pre class="SCREEN"># ip6tables -A PREROUTING -i eth0 -t mangle -p tcp -j MARK --mark 1</pre><p>But still, this will not help because the packet will not pass through the
RPDB structure.</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1456">12.5.3. Using the u32 selector to match IPv6 packet</a></h3><p>IPv6 is normally encapsulated in a SIT tunnel and transported
over IPv4 networks. See section IPv6 Tunneling for information on
howto setup such a tunnel. This allows us to filter on the IPv4 packets
holding the IPv6 packets as payload.</p><p>The following filter matches all IPv6 encapsulated in IPv4 packets:</p><pre class="SCREEN"># tc filter add dev $DEV parent 10:0 protocol ip prio 10 u32 \
            match ip protocol 41 0xff flowid 42:42</pre><p>Let's carry on with that. Assume your IPv6 packets get sent out
over IPv4 and these packets have no options set. One could use
the following filter to match ICMPv6 in IPv6 in IPv4 with no options.
0x3a (58) is the Next-Header type for ICMPv6.</p><pre class="SCREEN"># tc filter add dev $DEV parent 10:0 protocol ip prio 10 u32 \
           match ip protocol 41 0xff \
           match u8 0x05 0x0f at 0 \
           match u8 0x3a 0xff at 26 \
           flowid 42:42</pre><p>Matching the destination IPv6 address is a bit more work. The following
filter matches on the destination address
3ffe:202c:ffff:32:230:4fff:fe08:358d:</p><pre class="SCREEN"># tc filter add dev $DEV parent 10:0 protocol ip prio 10 u32 \
            match ip protocol 41 0xff \
            match u8 0x05 0x0f at 0 \
            match u8 0x3f 0xff at 44 \
            match u8 0xfe 0xff at 45 \
            match u8 0x20 0xff at 46 \
            match u8 0x2c 0xff at 47 \
            match u8 0xff 0xff at 48 \
            match u8 0xff 0xff at 49 \
            match u8 0x00 0xff at 50 \
            match u8 0x32 0xff at 51 \
            match u8 0x02 0xff at 52 \
            match u8 0x30 0xff at 53 \
            match u8 0x4f 0xff at 54 \
            match u8 0xff 0xff at 55 \
            match u8 0xfe 0xff at 56 \
            match u8 0x08 0xff at 57 \
            match u8 0x35 0xff at 58 \
            match u8 0x8d 0xff at 59 \
            flowid 10:13</pre><p>The same technique can be used to match subnets. For example 2001::</p><pre class="SCREEN"># tc filter add dev $DEV parent 10:0 protocol ip prio 10 u32 \
            match ip protocol 41 0xff \
            match u8 0x05 0x0f at 0 \
            match u8 0x20 0xff at 28 \
            match u8 0x01 0xff at 29 \
            flowid 10:13</pre></div></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.KERNEL"></a>Chapter 13. Kernel network parameters </h1><p> 
The kernel has lots of parameters which
can be tuned for different circumstances. While, as usual, the default
parameters serve 99% of installations very well, we don't call this the
Advanced HOWTO for the fun of it!</p><p>The interesting bits are in /proc/sys/net, take a look there. Not everything
will be documented here initially, but we're working on it.</p><p>In the meantime you may want to have a look at the Linux-Kernel sources;
read the file Documentation/filesystems/proc.txt. Most of the
features are explained there.</p><p>(FIXME)</p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.KERNEL.RPF">13.1. Reverse Path Filtering</a></h2><p>By default, routers route everything, even packets which 'obviously' don't
belong on your network. A common example is private IP space escaping onto
the Internet. If you have an interface with a route of 195.96.96.0/24 to it,
you do not expect packets from 212.64.94.1 to arrive there.</p><p>Lots of people will want to turn this feature off, so the kernel hackers
have made it easy. There are files in /proc where you can tell
the kernel to do this for you. The method is called "Reverse Path
Filtering". Basically, if the reply to a packet wouldn't go out the
interface this packet came in, then this is a bogus packet and should be
ignored.</p><p>The following fragment will turn this on for all current and future
interfaces.</p><p></p><pre class="SCREEN"># for i in /proc/sys/net/ipv4/conf/*/rp_filter ; do
&gt;  echo 2 &gt; $i 
&gt; done</pre><p></p><p>Going by the example above, if a packet arrived on the Linux router on eth1
claiming to come from the Office+ISP subnet, it would be dropped. Similarly,
if a packet came from the Office subnet, claiming to be from somewhere
outside your firewall, it would be dropped also.</p><p>The above is full reverse path filtering. The default is to only filter
based on IPs that are on directly connected networks. This is because the
full filtering breaks in the case of asymmetric routing (where packets come
in one way and go out another, like satellite traffic, or if you have
dynamic (bgp, ospf, rip) routes in your network. The data comes down
through the satellite dish and replies go back through normal land-lines).</p><p>If this exception applies to you (and you'll probably know if it does) you
can simply turn off the rp_filter on the interface where the
satellite data comes in. If you want to see if any packets are being
dropped, the log_martians file in the same directory will tell
the kernel to log them to your syslog.</p><p></p><pre class="SCREEN"># echo 1 &gt;/proc/sys/net/ipv4/conf/&lt;interfacename&gt;/log_martians</pre><p></p><p>FIXME: is setting the conf/{default,all}/* files enough? - martijn</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.KERNEL.OBSCURE">13.2. Obscure settings</a></h2><p>Ok, there are a lot of parameters which can be modified. We try to list them
all. Also documented (partly) in Documentation/ip-sysctl.txt.</p><p>Some of these settings have different defaults based on whether you 
answered 'Yes' to 'Configure as router and not host' while compiling your
kernel.</p><p>Oskar Andreasson also has a page on all these flags and it appears to be
better than ours, so also check 
<a href="http://ipsysctl-tutorial.frozentux.net/" target="_top">http://ipsysctl-tutorial.frozentux.net/</a>.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1492">13.2.1. Generic ipv4</a></h3><p>As a generic note, most rate limiting features don't work on loopback, so
don't test them locally. The limits are supplied in 'jiffies', and are
enforced using the earlier mentioned token bucket filter.</p><p>The kernel has an internal clock which runs at 'HZ' ticks (or 'jiffies') per
second. On Intel, 'HZ' is mostly 100. So setting a *_rate file to, say 50,
would allow for 2 packets per second. The token bucket filter is also
configured to allow for a burst of at most 6 packets, if enough tokens have
been earned.</p><p>Several entries in the following list have been copied from
/usr/src/linux/Documentation/networking/ip-sysctl.txt, written by Alexey
Kuznetsov &lt;kuznet@ms2.inr.ac.ru&gt; and Andi Kleen &lt;ak@muc.de&gt;
</p><p></p><div class="VARIABLELIST"><dl><dt>/proc/sys/net/ipv4/icmp_destunreach_rate</dt><dd><p>If the kernel decides that it can't deliver a packet, it will drop it, and
send the source of the packet an ICMP notice to this effect.</p></dd><dt>/proc/sys/net/ipv4/icmp_echo_ignore_all</dt><dd><p>Don't act on echo packets at all. Please don't set this by default, but if
you are used as a relay in a DoS attack, it may be useful.</p></dd><dt>/proc/sys/net/ipv4/icmp_echo_ignore_broadcasts [Useful]</dt><dd><p>If you ping the broadcast address of a network, all hosts are supposed to
respond. This makes for a dandy denial-of-service tool. Set this to 1 to
ignore these broadcast messages.</p></dd><dt>/proc/sys/net/ipv4/icmp_echoreply_rate</dt><dd><p>The rate at which echo replies are sent to any one destination.</p></dd><dt>/proc/sys/net/ipv4/icmp_ignore_bogus_error_responses</dt><dd><p>Set this to ignore ICMP errors caused by hosts in the network reacting badly
to frames sent to what they perceive to be the broadcast address.</p></dd><dt>/proc/sys/net/ipv4/icmp_paramprob_rate</dt><dd><p>A relatively unknown ICMP message, which is sent in response to incorrect
packets with broken IP or TCP headers. With this file you can control the
rate at which it is sent.</p></dd><dt>/proc/sys/net/ipv4/icmp_timeexceed_rate</dt><dd><p>This is the famous cause of the 'Solaris middle star' in traceroutes. Limits
the rate of ICMP Time Exceeded messages sent. </p></dd><dt>/proc/sys/net/ipv4/igmp_max_memberships</dt><dd><p>Maximum number of listening igmp (multicast) sockets on the host.
FIXME: Is this true?</p></dd><dt>/proc/sys/net/ipv4/inet_peer_gc_maxtime</dt><dd><p>FIXME: Add a little explanation about the inet peer storage?

Miximum interval between garbage collection passes.  This interval is in
effect under low (or absent) memory pressure on the pool. Measured in
jiffies.</p></dd><dt>/proc/sys/net/ipv4/inet_peer_gc_mintime</dt><dd><p>Minimum interval between garbage collection passes.  This interval is in
effect under high memory pressure on the pool. Measured in jiffies.</p></dd><dt>/proc/sys/net/ipv4/inet_peer_maxttl</dt><dd><p>Maximum time-to-live of entries.  Unused entries will expire after this
period of time if there is no memory pressure on the pool (i.e. when the
number of entries in the pool is very small). Measured in jiffies.</p></dd><dt>/proc/sys/net/ipv4/inet_peer_minttl</dt><dd><p>Minimum time-to-live of entries.  Should be enough to cover fragment
time-to-live on the reassembling side.  This minimum time-to-live
is guaranteed if the pool size is less than inet_peer_threshold.
Measured in jiffies.</p></dd><dt>/proc/sys/net/ipv4/inet_peer_threshold</dt><dd><p>The approximate size of the INET peer storage.  Starting from this threshold
entries will be thrown aggressively.  This threshold also determines
entries' time-to-live and time intervals between garbage collection passes. 
More entries, less time-to-live, less GC interval.</p></dd><dt>/proc/sys/net/ipv4/ip_autoconfig</dt><dd><p>This file contains the number one if the host received its IP configuration by
RARP, BOOTP, DHCP or a similar mechanism. Otherwise it is zero.</p></dd><dt>/proc/sys/net/ipv4/ip_default_ttl</dt><dd><p>Time To Live of packets. Set to a safe 64. Raise it if you have a huge
network. Don't do so for fun - routing loops cause much more damage that
way. You might even consider lowering it in some circumstances.</p></dd><dt>/proc/sys/net/ipv4/ip_dynaddr</dt><dd><p>You
 need to set this if you use dial-on-demand with a dynamic interface
address. Once your demand interface comes up, any local TCP sockets 
which haven't seen replies will be rebound to have the right address. 
This solves the problem that the
connection that brings up your interface itself does not work, but the
second try does.</p></dd><dt>/proc/sys/net/ipv4/ip_forward</dt><dd><p>If the kernel should attempt to forward packets. Off by default.</p></dd><dt>/proc/sys/net/ipv4/ip_local_port_range</dt><dd><p>Range of local ports for outgoing connections. Actually quite small by
default, 1024 to 4999.</p></dd><dt>/proc/sys/net/ipv4/ip_no_pmtu_disc</dt><dd><p>Set this if you want to disable Path MTU discovery - a technique to
determine the largest Maximum Transfer Unit possible on your path. See also
the section on Path MTU discovery in the 
<i class="CITETITLE"><a href="#LARTC.COOKBOOK">Cookbook</a></i> chapter.</p></dd><dt>/proc/sys/net/ipv4/ipfrag_high_thresh</dt><dd><p>Maximum memory used to reassemble IP fragments. When 
ipfrag_high_thresh bytes of memory is allocated for this purpose,
the fragment handler will toss packets until ipfrag_low_thresh
is reached.</p></dd><dt>/proc/sys/net/ipv4/ip_nonlocal_bind</dt><dd><p>Set this if you want your applications to be able to bind to an address
which doesn't belong to a device on your system. This can be useful when
your machine is on a non-permanent (or even dynamic) link, so your services
are able to start up and bind to a specific address when your link is down.</p></dd><dt>/proc/sys/net/ipv4/ipfrag_low_thresh</dt><dd><p>Minimum memory used to reassemble IP fragments.</p></dd><dt>/proc/sys/net/ipv4/ipfrag_time</dt><dd><p>Time in seconds to keep an IP fragment in memory.</p></dd><dt>/proc/sys/net/ipv4/tcp_abort_on_overflow</dt><dd><p>A boolean flag controlling the behaviour under lots of incoming connections.
When enabled, this causes the kernel to actively send RST packets when a
service is overloaded.</p></dd><dt>/proc/sys/net/ipv4/tcp_fin_timeout</dt><dd><p>Time to hold socket in state FIN-WAIT-2, if it was closed by our side. Peer
can be broken and never close its side, or even died unexpectedly. Default
value is 60sec. Usual value used in 2.2 was 180 seconds, you may restore it,
but remember that if your machine is even underloaded WEB server, you risk
to overflow memory with kilotons of dead sockets, FIN-WAIT-2 sockets are
less dangerous than FIN-WAIT-1, because they eat maximum 1.5K of memory, but
they tend to live longer. Cf. tcp_max_orphans.</p></dd><dt>/proc/sys/net/ipv4/tcp_keepalive_time</dt><dd><p>How often TCP sends out keepalive messages when keepalive is enabled. 

Default: 2hours.</p></dd><dt>/proc/sys/net/ipv4/tcp_keepalive_intvl</dt><dd><p>How frequent probes are retransmitted, when a probe isn't acknowledged. 

Default: 75 seconds.</p></dd><dt>/proc/sys/net/ipv4/tcp_keepalive_probes</dt><dd><p>How many keepalive probes TCP will send, until it decides that the
connection is broken. 

Default value: 9. 

Multiplied with tcp_keepalive_intvl, this gives the time a link can be
non-responsive after a keepalive has been sent.</p></dd><dt>/proc/sys/net/ipv4/tcp_max_orphans</dt><dd><p>Maximal number of TCP sockets not attached to any user file handle, held by
system. If this number is exceeded orphaned connections are reset
immediately and warning is printed. This limit exists only to prevent simple
DoS attacks, you _must_ not rely on this or lower the limit artificially,
but rather increase it (probably, after increasing installed memory), if
network conditions require more than default value, and tune network
services to linger and kill such states more aggressively. Let me remind you
again: each orphan eats up to &nbsp;64K of unswappable memory.</p></dd><dt>/proc/sys/net/ipv4/tcp_orphan_retries</dt><dd><p>How may times to retry before killing TCP connection, closed by our side.
Default value 7 corresponds to &nbsp;50sec-16min depending on RTO. If your machine
is a loaded WEB server, you should think about lowering this value, such
sockets may consume significant resources. Cf. tcp_max_orphans.</p></dd><dt>/proc/sys/net/ipv4/tcp_max_syn_backlog</dt><dd><p>Maximal number of remembered connection requests, which still did not
receive an acknowledgment from connecting client. Default value is 1024 for
systems with more than 128Mb of memory, and 128 for low memory machines. If
server suffers of overload, try to increase this number. Warning! If you
make it greater than 1024, it would be better to change TCP_SYNQ_HSIZE in
include/net/tcp.h to keep TCP_SYNQ_HSIZE*16&lt;=tcp_max_syn_backlog and to
recompile kernel.</p></dd><dt>/proc/sys/net/ipv4/tcp_max_tw_buckets</dt><dd><p>Maximal number of timewait sockets held by system simultaneously. If this
number is exceeded time-wait socket is immediately destroyed and warning is
printed. This limit exists only to prevent simple DoS attacks, you _must_
not lower the limit artificially, but rather increase it (probably, after
increasing installed memory), if network conditions require more than
default value.</p></dd><dt>/proc/sys/net/ipv4/tcp_retrans_collapse</dt><dd><p>Bug-to-bug compatibility with some broken printers.
On retransmit try to send bigger packets to work around bugs in
certain TCP stacks.</p></dd><dt>/proc/sys/net/ipv4/tcp_retries1</dt><dd><p>How many times to retry before deciding that something is wrong
and it is necessary to report this suspicion to network layer.
Minimal RFC value is 3, it is default, which corresponds
to &nbsp;3sec-8min depending on RTO.</p></dd><dt>/proc/sys/net/ipv4/tcp_retries2</dt><dd><p>How may times to retry before killing alive TCP connection.
<a href="http://www.ietf.org/rfc/rfc1122.txt" target="_top">RFC 1122</a>
says that the limit should be longer than 100 sec.
It is too small number. Default value 15 corresponds to &nbsp;13-30min
depending on RTO.</p></dd><dt>/proc/sys/net/ipv4/tcp_rfc1337</dt><dd><p>This boolean enables a fix for 'time-wait assassination hazards in tcp', described
in RFC 1337. If enabled, this causes the kernel to drop RST packets for
sockets in the time-wait state.

Default: 0</p></dd><dt>/proc/sys/net/ipv4/tcp_sack</dt><dd><p>Use Selective ACK which can be used to signify that specific packets are
missing - therefore helping fast recovery.</p></dd><dt>/proc/sys/net/ipv4/tcp_stdurg</dt><dd><p>Use the Host requirements interpretation of the TCP urg pointer
field. 

Most hosts use the older BSD interpretation, so if you turn this on
Linux might not communicate correctly with them. 

Default: FALSE </p></dd><dt>/proc/sys/net/ipv4/tcp_syn_retries</dt><dd><p>Number of SYN packets the kernel will send before giving up on the new
connection.</p></dd><dt>/proc/sys/net/ipv4/tcp_synack_retries</dt><dd><p>To open the other side of the connection, the kernel sends a SYN with a
piggybacked ACK on it, to acknowledge the earlier received SYN. This is part
2 of the threeway handshake. This setting determines the number of SYN+ACK
packets sent before the kernel gives up on the connection.</p></dd><dt>/proc/sys/net/ipv4/tcp_timestamps</dt><dd><p>Timestamps are used, amongst other things, to protect against wrapping
sequence numbers. A 1 gigabit link might conceivably re-encounter a previous
sequence number with an out-of-line value, because it was of a previous
generation. The timestamp will let it recognize this 'ancient packet'.</p></dd><dt>/proc/sys/net/ipv4/tcp_tw_recycle</dt><dd><p>Enable fast recycling TIME-WAIT sockets. Default value is 1.
It should not be changed without advice/request of technical experts.</p></dd><dt>/proc/sys/net/ipv4/tcp_window_scaling</dt><dd><p>TCP/IP normally allows windows up to 65535 bytes big. For really fast
networks, this may not be enough. The window scaling options allows for
almost gigabyte windows, which is good for high bandwidth*delay products.</p></dd></dl></div><p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1673">13.2.2. Per device settings</a></h3><p>DEV can either stand for a real interface, or for 'all' or 'default'.
Default also changes settings for interfaces yet to be created.
</p><p></p><div class="VARIABLELIST"><dl><dt>/proc/sys/net/ipv4/conf/DEV/accept_redirects</dt><dd><p>If a router decides that you are using it for a wrong purpose (ie, it needs
to resend your packet on the same interface), it will send us a ICMP
Redirect. This is a slight security risk however, so you may want to turn it
off, or use secure redirects.</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/accept_source_route</dt><dd><p>Not used very much anymore. You used to be able to give a packet a list of
IP addresses it should visit on its way. Linux can be made to honor this IP
option.</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/bootp_relay</dt><dd><p>Accept packets  with source address 0.b.c.d with destinations not to this host
as local ones. It is supposed that a BOOTP relay daemon will catch and forward
such packets.</p><p>The default  is  0,  since this feature is not implemented yet (kernel version
2.2.12).</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/forwarding</dt><dd><p>Enable or disable IP forwarding on this interface.</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/log_martians</dt><dd><p>See the section on 
<i class="CITETITLE"><a href="#LARTC.KERNEL.RPF">Reverse Path Filtering</a></i>.</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/mc_forwarding</dt><dd><p>If we do multicast forwarding on this interface</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/proxy_arp</dt><dd><p>If you set this to 1, this interface will respond to ARP requests for
addresses the kernel has routes to. Can be very useful when building 'ip
pseudo bridges'. Do take care that your netmasks are very correct before
enabling this! Also be aware that the rp_filter, mentioned elsewhere, also
operates on ARP queries!</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/rp_filter</dt><dd><p>See the section on 
<i class="CITETITLE"><a href="#LARTC.KERNEL.RPF">Reverse Path Filtering</a></i>.</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/secure_redirects</dt><dd><p>Accept ICMP  redirect  messages  only  for gateways, listed in default gateway
list. Enabled by default.</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/send_redirects</dt><dd><p>If we send the above mentioned redirects.</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/shared_media</dt><dd><p>If it  is  not  set  the kernel does not assume that different subnets on this
device can communicate directly. Default setting is 'yes'.</p></dd><dt>/proc/sys/net/ipv4/conf/DEV/tag</dt><dd><p>FIXME: fill this in</p></dd></dl></div><p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1730">13.2.3. Neighbor policy</a></h3><p>Dev can either stand for a real interface, or for 'all' or 'default'.
Default also changes settings for interfaces yet to be created.
</p><p></p><div class="VARIABLELIST"><dl><dt>/proc/sys/net/ipv4/neigh/DEV/anycast_delay</dt><dd><p>Maximum for  random  delay  of  answers  to  neighbor solicitation messages in
jiffies (1/100  sec). Not yet implemented (Linux does not have anycast support
yet).</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/app_solicit</dt><dd><p>Determines the  number of requests to send to the user level ARP daemon. Use 0
to turn off.</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/base_reachable_time</dt><dd><p>A base  value  used for computing the random reachable time value as specified
in RFC2461.</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/delay_first_probe_time</dt><dd><p>Delay for  the  first  time  probe  if  the  neighbor  is  reachable.  (see
gc_stale_time)</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/gc_stale_time</dt><dd><p>Determines how  often  to  check  for stale ARP entries. After an ARP entry is
stale it  will  be resolved again (which is useful when an IP address migrates
to another  machine).  When  ucast_solicit is greater than 0 it first tries to
send an  ARP  packet  directly  to  the  known  host  When  that  fails  and
mcast_solicit is greater than 0, an ARP request is broadcast.</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/locktime</dt><dd><p>An ARP/neighbor  entry  is only replaced with a new one if the old is at least
locktime old. This prevents ARP cache thrashing.</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/mcast_solicit</dt><dd><p>Maximum number of retries for multicast solicitation.</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/proxy_delay</dt><dd><p>Maximum time  (real  time is random  [0..proxytime]) before answering to an ARP
request for  which  we have an proxy ARP entry. In some cases, this is used to
prevent network flooding.</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/proxy_qlen</dt><dd><p>Maximum queue length of the delayed proxy arp timer. (see proxy_delay).</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/retrans_time</dt><dd><p>The time,  expressed  in  jiffies  (1/100 sec), between retransmitted Neighbor
Solicitation messages.  Used  for  address  resolution  and  to determine if a
neighbor is unreachable.</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/ucast_solicit</dt><dd><p>Maximum number of retries for unicast solicitation.</p></dd><dt>/proc/sys/net/ipv4/neigh/DEV/unres_qlen</dt><dd><p>Maximum queue  length  for a pending arp request - the number of packets which
are accepted from other layers while the ARP address is still resolved.</p></dd></dl></div><p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1782">13.2.4. Routing settings</a></h3><p></p><p></p><div class="VARIABLELIST"><dl><dt>/proc/sys/net/ipv4/route/error_burst and /proc/sys/net/ipv4/route/error_cost</dt><dd><p>This parameters are used to limit the warning messages written to the kernel
log from  the  routing  code.  The  higher the error_cost factor is, the fewer
messages will  be written. Error_burst controls when messages will be dropped.
The default settings limit warning messages to one every five seconds.</p></dd><dt>/proc/sys/net/ipv4/route/flush</dt><dd><p>Writing to this file results in a flush of the routing cache.</p></dd><dt>/proc/sys/net/ipv4/route/gc_elasticity</dt><dd><p>Values to  control  the  frequency  and  behavior  of  the  garbage collection
algorithm for the routing cache. This can be important for when doing
fail over. At least gc_timeout seconds will elapse before Linux will skip
to another route because the previous one has died. By default set to 300,
you may want to lower it if you want to have a speedy fail over.</p><p>Also see <a href="http://mailman.ds9a.nl/pipermail/lartc/2002q1/002667.html" target="_top">this post</a> by Ard van Breemen.</p></dd><dt>/proc/sys/net/ipv4/route/gc_interval</dt><dd><p>See /proc/sys/net/ipv4/route/gc_elasticity.</p></dd><dt>/proc/sys/net/ipv4/route/gc_min_interval</dt><dd><p>See /proc/sys/net/ipv4/route/gc_elasticity.</p></dd><dt>/proc/sys/net/ipv4/route/gc_thresh</dt><dd><p>See /proc/sys/net/ipv4/route/gc_elasticity.</p></dd><dt>/proc/sys/net/ipv4/route/gc_timeout</dt><dd><p>See /proc/sys/net/ipv4/route/gc_elasticity.</p></dd><dt>/proc/sys/net/ipv4/route/max_delay</dt><dd><p>Maximum delay for flushing the routing cache.</p></dd><dt>/proc/sys/net/ipv4/route/max_size</dt><dd><p>Maximum size  of  the routing cache. Old entries will be purged once the cache
reached has this size.</p></dd><dt>/proc/sys/net/ipv4/route/min_adv_mss</dt><dd><p>FIXME: fill this in</p></dd><dt>/proc/sys/net/ipv4/route/min_delay</dt><dd><p>Minimum delay for flushing the routing cache.</p></dd><dt>/proc/sys/net/ipv4/route/min_pmtu</dt><dd><p>FIXME: fill this in</p></dd><dt>/proc/sys/net/ipv4/route/mtu_expires</dt><dd><p>FIXME: fill this in</p></dd><dt>/proc/sys/net/ipv4/route/redirect_load</dt><dd><p>Factors which  determine  if  more ICMP redirects should be sent to a specific
host. No  redirects  will be sent once the load limit or the maximum number of
redirects has been reached.</p></dd><dt>/proc/sys/net/ipv4/route/redirect_number</dt><dd><p>See /proc/sys/net/ipv4/route/redirect_load.</p></dd><dt>/proc/sys/net/ipv4/route/redirect_silence</dt><dd><p>Timeout for redirects. After this period redirects will be sent again, even if
this has been stopped, because the load or number limit has been reached.</p></dd></dl></div><p></p></div></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.ADV-QDISC"></a>Chapter 14. Advanced &amp; less common queueing disciplines</h1><p>Should you find that you have needs not addressed by the queues mentioned
earlier, the kernel contains some other more specialized queues mentioned here.</p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-QDISC.BFIFO-PFIFO">14.1. <tt class="LITERAL">bfifo</tt>/<tt class="LITERAL">pfifo</tt></a></h2><p>These classless queues are even simpler than pfifo_fast in that they lack
the internal bands - all traffic is really equal. They have one important
benefit though, they have some statistics. So even if you don't need shaping
or prioritizing, you can use this qdisc to determine the backlog on your
interface.</p><p>pfifo has a length measured in packets, bfifo in bytes. </p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1861">14.1.1. Parameters &amp; usage</a></h3><p></p><p></p><div class="VARIABLELIST"><dl><dt>limit</dt><dd><p>Specifies the length of the queue. Measured in bytes for bfifo, in packets
for pfifo. Defaults to the interface txqueuelen (see pfifo_fast chapter)
packets long or txqueuelen*mtu bytes for bfifo.</p></dd></dl></div><p></p></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-QDISC.CSZ">14.2. Clark-Shenker-Zhang algorithm (CSZ)</a></h2><p>This is so theoretical that not even Alexey (the main CBQ author) claims to
understand it. From his source:</p><a name="AEN1872"></a><blockquote class="BLOCKQUOTE"><p>David D. Clark, Scott Shenker and Lixia Zhang
<i class="CITETITLE">Supporting Real-Time Applications in an Integrated Services Packet
Network: Architecture and Mechanism</i>.</p><p>As I understand it, the main idea is to create WFQ flows for each guaranteed
service and to allocate the rest of bandwith to dummy flow-0. Flow-0
comprises the predictive services and the best effort traffic; it is handled
by a priority scheduler with the highest priority band allocated for
predictive services, and the rest --- to the best effort packets.</p><p>Note that in CSZ flows are NOT limited to their bandwidth.  It is supposed
that the flow passed admission control at the edge of the QoS network and it
doesn't need further shaping. Any attempt to improve the flow or to shape it
to a token bucket at intermediate hops will introduce undesired delays and
raise jitter.</p><p>At the moment CSZ is the only scheduler that provides true guaranteed
service. Another schemes (including CBQ) do not provide guaranteed delay and
randomize jitter."</p><p>Does not currently seem like a good candidate to use, unless you've read and
understand the article mentioned.</p></blockquote></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-QDISC.DSMARK">14.3. DSMARK</a></h2><blockquote class="ABSTRACT"><div class="ABSTRACT"><p></p><a name="AEN1881"></a><p>      Esteve Camps
      </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:marvin@grn.es">marvin@grn.es</a>&gt;</code></p>
      This text is an extract from my thesis on
      <i class="CITETITLE">QoS Support in Linux</i>, September 2000.
    <p></p><p></p></div></blockquote><p>Source documents:</p><p></p><ul><li><p>    <a href="ftp://icaftp.epfl.ch/pub/linux/diffserv/misc/dsid-01.txt.gz" target="_top">      Draft-almesberger-wajhak-diffserv-linux-01.txt</a>.
  </p></li><li><p>Examples in iproute2 distribution.
  </p></li><li><p>    <a href="http://www.qosforum.com/white-papers/qosprot_v3.pdf" target="_top">      White Paper-QoS protocols and architectures</a> and
    <a href="http://www.qosforum.com/docs/faq" target="_top">      IP QoS Frequently Asked Questions</a> both by 
    <i class="CITETITLE">Quality of Service Forum</i>.
  </p></li></ul><p>This chapter was written by Esteve Camps &lt;esteve@hades.udg.es&gt;.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1902">14.3.1. Introduction</a></h3><p>First of all, it would be a great idea for you to read RFCs
written about this (RFC2474, RFC2475, RFC2597 and RFC2598) at 
<a href="http://www.ietf.org/html.charters/diffserv-charter.html" target="_top">  IETF DiffServ working Group web site</a> and
<a href="http://diffserv.sf.net/" target="_top">  Werner Almesberger web site</a>
(he wrote the code to support Differentiated Services on Linux).</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1907">14.3.2. What is Dsmark related to?</a></h3><p>Dsmark is a queueing discipline that offers the capabilities needed in
Differentiated Services (also called DiffServ or, simply, DS). DiffServ is
one of two actual QoS architectures (the other one is called Integrated
Services) that is based on a value carried by packets in the DS field of the
IP header.</p><p>One of the first solutions in IP designed to offer some QoS level was
the Type of Service field (TOS byte) in IP header. By changing that value,
we could choose a high/low level of throughput, delay or reliability.
But this didn't provide sufficient flexibility to the needs of new
services (such as real-time applications, interactive applications and
others). After this, new architectures appeared. One of these was DiffServ
which kept TOS bits and renamed DS field.</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1911">14.3.3. Differentiated Services guidelines</a></h3><p>Differentiated Services is group-oriented. I mean, we don't know anything
about flows (this will be the Integrated Services purpose); we know about
flow aggregations and we will apply different behaviours depending on which
aggregation a packet belongs to.</p><p>When a packet arrives to an edge node (entry node to a DiffServ domain)
entering to a DiffServ Domain we'll have to policy, shape and/or mark those
packets (marking refers to assigning a value to the DS field. It's just like the
cows :-) ). This will be the mark/value that the internal/core nodes on our
DiffServ Domain will look at to determine which behaviour or QoS level
apply.</p><p>As you can deduce, Differentiated Services involves a domain on which
all DS rules will have to be applied. In fact you can think I
will classify all the packets entering my domain. Once they enter my
domain they will be subjected to the rules that my classification dictates
and every traversed node will apply that QoS level.</p><p>In fact, you can apply your own policies into your local domains, but some
<span class="emphasis"><i class="EMPHASIS">Service Level Agreements</i></span> should be considered when connecting to
other DS domains.</p><p>At this point, you maybe have a lot of questions. DiffServ is more than I've
explained. In fact, you can understand that I can not resume more than 3
RFCs in just 50 lines :-).</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1919">14.3.4. Working with Dsmark</a></h3><p>As the DiffServ bibliography specifies, we differentiate boundary nodes and
interior nodes. These are two important points in the traffic path. Both
types perform a classification when the packets arrive. Its result may be
used in different places along the DS process before the packet is released
to the network. It's just because of this that the diffserv code supplies an
structure called sk_buff, including a new field called skb-&gt;tc_index
where we'll store the result of initial classification that may be used in
several points in DS treatment.</p><p>The skb-&gt;tc_index value will be initially set by the DSMARK qdisc,
retrieving it from the DS field in IP header of every received packet.
Besides, cls_tcindex classifier will read all or part of skb-&gt;tcindex
value and use it to select classes.</p><p>But, first of all, take a look at DSMARK qdisc command and its parameters:

</p><pre class="SCREEN">... dsmark indices INDICES [ default_index DEFAULT_INDEX ] [ set_tc_index ]</pre>

What do these parameters mean?

<p></p><ul><li><p><span class="emphasis"><i class="EMPHASIS">indices</i></span>: size of table of (mask,value) pairs. Maximum value is 2n, where n&gt;=0.</p></li><li><p><span class="emphasis"><i class="EMPHASIS">Default_index</i></span>: the default table entry index if classifier finds no match.</p></li><li><p><span class="emphasis"><i class="EMPHASIS">Set_tc_index</i></span>: instructs dsmark discipline to retrieve the DS field and store it onto skb-&gt;tc_index.</p></li></ul>

Let's see the DSMARK process.<p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1935">14.3.5. How SCH_DSMARK works.</a></h3><p>This qdisc will apply the next steps:

</p><p></p><ul><li><p>If we have declared set_tc_index option in qdisc command, DS field is retrieved and stored onto
skb-&gt;tc_index variable.</p></li><li><p>Classifier is invoked. The classifier will be executed and it will return a class ID that will be stored in
skb-&gt;tc_index variable. If no filter matches are found, we consider the default_index option to determine the
classId to store. If neither set_tc_index nor default_index has been declared results may be
unpredictable.</p></li><li><p>After been sent to internal qdiscs where you can reuse the result of the filter, the classid returned by
the internal qdisc is stored into skb-&gt;tc_index. We will use this value in the future to index a mask-
value table. The final result to assign to the packet will be that resulting from next operation:

</p><pre class="SCREEN">New_Ds_field = ( Old_DS_field &amp; mask ) | value</pre>
<p></p></li><li><p>Thus, new value will result from "anding" ds_field and mask values and next, this result "ORed" with
value parameter. See next diagram to understand all this process:</p></li></ul>


<pre class="SCREEN">                         skb-&gt;ihp-&gt;tos
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &gt;
     |                                                       |     ^
     | -- If you declare set_tc_index, we set DS             |     |  &lt;-----May change
     |    value into skb-&gt;tc_index variable                  |     |O       DS field
     |                                                      A|     |R
   +-|-+      +------+    +---+-+    Internal   +-+     +---N|-----|----+
   | | |      | tc   |---&gt;|   | |--&gt;  . . .  --&gt;| |     |   D|     |    |
   | | |-----&gt;|index |---&gt;|   | |     Qdisc     | |----&gt;|    v     |    |
   | | |      |filter|---&gt;| | | +---------------+ |   ----&gt;(mask,value) |
--&gt;| O |      +------+    +-|-+--------------^----+  /  |  (.  ,  .)    |
   | | |          ^         |                |       |  |  (.  ,  .)    |
   | | +----------|---------|----------------|-------|--+  (.  ,  .)    |
   | | sch_dsmark |         |                |       |                  |
   +-|------------|---------|----------------|-------|------------------+
     |            |         | &lt;- tc_index -&gt; |       |
     |            |(read)   |    may change  |       |  &lt;--------------Index to the
     |            |         |                |       |                    (mask,value)
     v            |         v                v       |                    pairs table
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -&gt;
                         skb-&gt;tc_index</pre><p></p><p>How to do marking? Just change the mask and value of the class you want to remark. See next line of code:

</p><pre class="SCREEN">tc class change dev eth0 classid 1:1 dsmark mask 0x3 value 0xb8</pre>

This changes the (mask,value) pair in hash table, to remark packets belonging to class 1:1.You have to "change" this values
because of default values that (mask,value) gets initially (see table below).<p></p><p>Now, we'll explain how TC_INDEX filter works and how fits into this. Besides, TCINDEX filter can be
used in other configurations rather than those including DS services.</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1952">14.3.6. TC_INDEX Filter</a></h3><p>This is the basic command to declare a TC_INDEX filter:

</p><pre class="SCREEN">... tcindex [ hash SIZE ] [ mask MASK ] [ shift SHIFT ]
            [ pass_on | fall_through ]
            [ classid CLASSID ] [ police POLICE_SPEC ]</pre><p></p><p>Next, we show the example used to explain TC_INDEX operation mode. Pay attention to bolded words:

</p><pre class="SCREEN">tc qdisc add dev eth0 handle 1:0 root dsmark indices 64 <span class="emphasis"><i class="EMPHASIS">set_tc_index</i></span>

tc filter add dev eth0 parent 1:0 protocol ip prio 1 tcindex <span class="emphasis"><i class="EMPHASIS">mask 0xfc  shift 2</i></span>

tc qdisc add dev eth0 parent 1:0 handle 2:0 cbq bandwidth 10Mbit cell 8 avpkt 1000 mpu 64

# EF traffic class

tc class add dev eth0 parent 2:0 classid 2:1 cbq bandwidth 10Mbit rate 1500Kbit avpkt 1000 prio 1 bounded isolated allot 1514 weight 1 maxburst 10

# Packet fifo qdisc for EF traffic

tc qdisc add dev eth0 parent 2:1 pfifo limit 5

tc filter add dev eth0 parent 2:0 protocol ip prio 1 <span class="emphasis"><i class="EMPHASIS">handle 0x2e</i></span> tcindex <span class="emphasis"><i class="EMPHASIS">classid 2:1 pass_on</i></span></pre>


(This code is not complete. It's just an extract from EFCBQ example included in iproute2 distribution).<p></p><p>First of all, suppose we receive a packet marked as EF .  If you read RFC2598, you'll see that DSCP
recommended value for EF traffic is 101110. This means that DS field will be 10111000 (remember that
less significant bits in TOS byte are not used in DS) or 0xb8 in hexadecimal codification.</p><p></p><pre class="SCREEN">              TC INDEX
              FILTER
   +---+      +-------+    +---+-+    +------+                +-+    +-------+
   |   |      |       |    |   | |    |FILTER|  +-+    +-+    | |    |       |
   |   |-----&gt;| MASK  | -&gt; |   | | -&gt; |HANDLE|-&gt;| |    | | -&gt; | | -&gt; |       |
   |   |  .   | =0xfc |    |   | |    |0x2E  |  | +----+ |    | |    |       |
   |   |  .   |       |    |   | |    +------+  +--------+    | |    |       |
   |   |  .   |       |    |   | |                            | |    |       |
--&gt;|   |  .   | SHIFT |    |   | |                            | |    |       |--&gt;
   |   |  .   | =2    |    |   | +----------------------------+ |    |       |
   |   |      |       |    |   |       CBQ 2:0                  |    |       |
   |   |      +-------+    +---+--------------------------------+    |       |
   |   |                                                             |       |
   |   +-------------------------------------------------------------+       |
   |                          DSMARK 1:0                                     |
   +-------------------------------------------------------------------------+</pre><p></p><p>The packet arrives, then, set with 0xb8 value at DS field. As we explained before, dsmark qdisc identified
by 1:0 id in the example, retrieves DS field and store it in skb-&gt;tc_index variable.
Next step in the example will correspond to the filter associated to this qdisc (second line in the example).
This will perform next operations:

</p><pre class="SCREEN">Value1 = skb-&gt;tc_index &amp; MASK
Key = Value1 &gt;&gt; SHIFT</pre><p></p><p>In the example, MASK=0xFC and SHIFT=2.

</p><pre class="SCREEN">Value1 = 10111000 &amp; 11111100 = 10111000
Key = 10111000 &gt;&gt; 2 = 00101110 -&gt; 0x2E in hexadecimal</pre><p></p><p>The returned value will correspond to a qdisc internal filter handle (in the example, identifier 2:0). If a
filter with this id exists, policing and metering conditions will be verified (in case that filter includes this)
and the classid will be returned (in our example, classid 2:1) and stored in skb-&gt;tc_index variable.</p><p>But if any filter with that identifier is not found, the result will depend on fall_through flag declaration. If so,
value key is returned as classid. If not, an error is returned and process continues with the rest filters. Be
careful if you use fall_through flag; this can be done if a simple relation exists between values

of skb-&gt;tc_index variable and class id's.</p><p>The latest parameters to comment on are hash and pass_on. The first one
relates to hash table size. Pass_on will be used to indicate that if no classid
equal to the result of this filter is found, try next filter.
The default action is fall_through (look at next table).</p><p>Finally, let's see which possible values can be set to all this TCINDEX parameters:

</p><pre class="SCREEN">TC Name                 Value           Default
-----------------------------------------------------------------
Hash                    1...0x10000     Implementation dependent
Mask                    0...0xffff      0xffff
Shift                   0...15          0
Fall through / Pass_on  Flag            Fall_through
Classid                 Major:minor     None
Police                  .....           None</pre><p></p><p>This kind 
of filter is very powerful. It's necessary to explore all possibilities.
 Besides, this filter is not only used in DiffServ configurations.
You can use it as any other kind of filter.</p><p>I recommend you to look at all DiffServ examples included in iproute2 distribution. I promise I will try to
complement this text as soon as I can. Besides, all I have explained is the result of a lot of tests.
I would thank you tell me if I'm wrong in any point.</p></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-QDISC.INGRESS">14.4. Ingress qdisc</a></h2><p>All qdiscs discussed so far are egress qdiscs. Each interface however can
also have an ingress qdisc which is not used to send packets
out to the network adaptor. Instead, it allows you to apply tc filters to
packets coming in over the interface, regardless of whether they have a local
destination or are to be forwarded.</p><p>As the tc filters contain a full Token Bucket Filter implementation, and are
also able to match on the kernel flow estimator, there is a lot of
functionality available. This effectively allows you to police incoming
traffic, before it even enters the IP stack.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN1980">14.4.1. Parameters &amp; usage</a></h3><p>The ingress qdisc itself does not require any parameters. It differs from
other qdiscs in that it does not occupy the root of a device. Attach it like
this:

</p><pre class="SCREEN"># tc qdisc add dev eth0 ingress</pre>

This allows you to have other, sending, qdiscs on your device besides the
ingress qdisc. <p></p><p>For a contrived example how the ingress qdisc could be used, see the
Cookbook.</p></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-QDISC.RED">14.5. Random Early Detection (RED)</a></h2><p>This section is meant as an introduction to the queuing at backbone networks, which often
involves &gt;100 megabit bandwidths, which requires a different approach than
your ADSL modem at home.</p><p>The normal behaviour of router queues on the Internet is called tail-drop.
Tail-drop works by queueing up to a certain amount, then dropping all traffic
that 'spills over'. This is very unfair, and also leads to retransmit 
synchronization. When retransmit synchronization occurs, the sudden burst
of drops from a router that has reached its fill will cause a delayed burst
of retransmits, which will over fill the congested router again. </p><p>In order to cope with transient congestion on links, backbone routers will
often implement large queues. Unfortunately, while these queues are good for
throughput, they can substantially increase latency and cause TCP
connections to behave very burstily during congestion.</p><p>These issues with tail-drop are becoming increasingly troublesome on the
Internet because the use of network unfriendly applications is increasing.
The Linux kernel offers us RED, short for Random Early Detect, also called
Random Early Drop, as that is how it works.</p><p>RED isn't a cure-all for this, applications which inappropriately fail to 
implement exponential backoff still get an unfair share of the bandwidth,
however, with RED they do not cause as much harm to the throughput and
latency of other connections.</p><p>RED statistically drops packets from flows before it reaches its hard
limit. This causes a congested backbone link to slow more gracefully, and
prevents retransmit synchronization. This also helps TCP find its 'fair'
speed faster by allowing some packets to get dropped sooner keeping queue
sizes low and latency under control. The probability of a packet being
dropped from a particular connection is proportional to its bandwidth usage
rather than the number of packets it transmits. </p><p>RED is a good queue for backbones, where you can't afford the 
complexity of per-session state tracking needed by fairness queueing.</p><p>In order to use RED, you must decide on three parameters: Min, Max, and
burst. Min sets the minimum queue size in bytes before dropping will begin,
Max is a soft maximum that the algorithm will attempt to stay under, and
burst sets the maximum number of packets that can 'burst through'.</p><p>You should set the min by calculating that highest acceptable base queueing 
latency you wish, and multiply it by your bandwidth. For instance, on my 
64kbit/s ISDN link, I might want a base queueing latency of 200ms so I set
min to 1600 bytes. Setting min too small will degrade throughput and too
large will degrade latency. Setting a small min is not a replacement for
reducing the MTU on a slow link to improve interactive response.</p><p>You should make max at least twice min to prevent synchronization. On slow
links with small Min's it might be wise to make max perhaps four or
more times large then min.</p><p>Burst controls how the RED algorithm responds to bursts. Burst must be set
larger then min/avpkt. Experimentally, I've found (min+min+max)/(3*avpkt) to
work ok.</p><p>Additionally, you need to set limit and avpkt. Limit is a safety value, after
there are limit bytes in the queue, RED 'turns into' tail-drop. I typical set
limit to eight times max. Avpkt should be your average packet size. 1000
works OK on high speed Internet links with a 1500byte MTU. </p><p>Read <a href="http://www.aciri.org/floyd/papers/red/red.html" target="_top">the paper on RED queueing</a> by Sally Floyd and Van Jacobson for technical
information.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-QDISC.GRED">14.6. Generic Random Early Detection</a></h2><p>Not a lot is known about GRED. It looks like GRED with several internal
queues, whereby the internal queue is chosen based on the Diffserv tcindex
field. According to a slide found
<a href="http://www.davin.ottawa.on.ca/ols/img22.htm" target="_top">here</a>,
it contains the capabilities of Cisco's 'Distributed Weighted RED', as well 
as Dave Clark's RIO.</p><p>Each virtual queue can have its own Drop Parameters specified.</p><p>FIXME: get Jamal or Werner to tell us more</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-QDISC.VC-ATM">14.7. VC/ATM emulation</a></h2><p>This is quite a major effort by Werner Almesberger to allow you to build
Virtual Circuits over TCP/IP sockets. A Virtual Circuit is a concept from
ATM network theory. </p><p>For more information, see the <a href="http://linux-atm.sourceforge.net/" target="_top">ATM on Linux homepage</a>. </p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.ADV-QDISC.WRR">14.8. Weighted Round Robin (WRR)</a></h2><p>This qdisc is not included in the standard kernels but can be downloaded from 
<a href="http://wipl-wrr.dkik.dk/wrr/" target="_top">here</a>. 
Currently the qdisc is only tested with Linux 2.2 kernels but it will 
probably work with 2.4/2.5 kernels too.</p><p>The WRR qdisc distributes bandwidth between its classes using the weighted 
round robin scheme. That is, like the CBQ qdisc it contains classes 
into which arbitrary qdiscs can be plugged. All classes which have sufficient 
demand will get bandwidth proportional to the weights associated with the classes.
The weights can be set manually using the <tt class="LITERAL">tc</tt> program. But they
can also be made automatically decreasing for classes transferring much data.</p><p>The qdisc has a built-in classifier which assigns packets coming from or 
sent to different machines to different classes. Either the MAC or IP and 
either source or destination addresses can be used. The MAC address can only 
be used when the Linux box is acting as an ethernet bridge, however. The 
classes are automatically assigned to machines based on the packets seen.</p><p>The qdisc can be very useful at sites such as dorms where a lot of unrelated 
individuals share an Internet connection. A set of scripts setting up a 
relevant behavior for such a site is a central part of the WRR distribution.</p></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.COOKBOOK"></a>Chapter 15. Cookbook</h1><p>This section contains 'cookbook' entries which may help you solve problems.
A cookbook is no replacement for understanding however, so try and comprehend
what is going on. </p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.COOKBOOK.SLA">15.1. Running multiple sites with different SLAs</a></h2><p>You can do this in several ways. Apache has some support for this with a
module, but we'll show how Linux can do this for you, and do so for other
services as well. These commands are stolen from a presentation by Jamal
Hadi that's referenced below.</p><p>Let's say we have two customers, with http, ftp and streaming audio, and we
want to sell them a limited amount of bandwidth. We do so on the server itself.</p><p>Customer A should have at most 2 megabits, customer B has paid for 5
megabits. We separate our customers by creating virtual IP addresses on our
server.</p><p></p><pre class="SCREEN"># ip address add 188.177.166.1 dev eth0
# ip address add 188.177.166.2 dev eth0</pre><p></p><p>It is up to you to attach the different servers to the right IP address. All
popular daemons have support for this.</p><p>We first attach a CBQ qdisc to eth0:

</p><pre class="SCREEN"># tc qdisc add dev eth0 root handle 1: cbq bandwidth 10Mbit cell 8 avpkt 1000 \
  mpu 64</pre><p></p><p>We then create classes for our customers:</p><p></p><pre class="SCREEN"># tc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 10Mbit rate \
  2MBit avpkt 1000 prio 5 bounded isolated allot 1514 weight 1 maxburst 21
# tc class add dev eth0 parent 1:0 classid 1:2 cbq bandwidth 10Mbit rate \
  5Mbit avpkt 1000 prio 5 bounded isolated allot 1514 weight 1 maxburst 21</pre><p></p><p>Then we add filters for our two classes:

</p><pre class="SCREEN">##FIXME: Why this line, what does it do?, what is a divisor?:
##FIXME: A divisor has something to do with a hash table, and the number of
##       buckets - ahu
# tc filter add dev eth0 parent 1:0 protocol ip prio 5 handle 1: u32 divisor 1
# tc filter add dev eth0 parent 1:0 prio 5 u32 match ip src 188.177.166.1
  flowid 1:1
# tc filter add dev eth0 parent 1:0 prio 5 u32 match ip src 188.177.166.2
  flowid 1:2</pre><p></p><p>And we're done.</p><p>FIXME: why no token bucket filter? is there a default pfifo_fast fallback
somewhere?</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.COOKBOOK.SYNFLOOD-PROTECT">15.2. Protecting your host from SYN floods</a></h2><p>From Alexey's iproute documentation, adapted to netfilter and with more
plausible paths. If you use this, take care to adjust the numbers to
reasonable values for your system.</p><p>If you want to protect an entire network, skip this script, which is best
suited for a single host.</p><p>It appears that you need the very latest version of the iproute2 tools to
get this to work with 2.4.0.</p><p></p><pre class="SCREEN">#! /bin/sh -x
#
# sample script on using the ingress capabilities
# this script shows how one can rate limit incoming SYNs
# Useful for TCP-SYN attack protection. You can use
# IPchains to have more powerful additions to the SYN (eg 
# in addition the subnet)
#
#path to various utilities;
#change to reflect yours.
#
TC=/sbin/tc
IP=/sbin/ip
IPTABLES=/sbin/iptables
INDEV=eth2
#
# tag all incoming SYN packets through $INDEV as mark value 1
############################################################ 
$iptables -A PREROUTING -i $INDEV -t mangle -p tcp --syn \
  -j MARK --set-mark 1
############################################################ 
#
# install the ingress qdisc on the ingress interface
############################################################ 
$TC qdisc add dev $INDEV handle ffff: ingress
############################################################ 

#
# 
# SYN packets are 40 bytes (320 bits) so three SYNs equals
# 960 bits (approximately 1kbit); so we rate limit below
# the incoming SYNs to 3/sec (not very useful really; but
#serves to show the point - JHS
############################################################ 
$TC filter add dev $INDEV parent ffff: protocol ip prio 50 handle 1 fw \
police rate 1kbit burst 40 mtu 9k drop flowid :1
############################################################ 


#
echo "---- qdisc parameters Ingress  ----------"
$TC qdisc ls dev $INDEV
echo "---- Class parameters Ingress  ----------"
$TC class ls dev $INDEV
echo "---- filter parameters Ingress ----------"
$TC filter ls dev $INDEV parent ffff:

#deleting the ingress qdisc
#$TC qdisc del $INDEV ingress</pre><p></p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.COOKBOOK.ICMP-RATELIMIT">15.3. Rate limit ICMP to prevent dDoS</a></h2><p>Recently, distributed denial of service attacks have become a major nuisance
on the Internet. By properly filtering and rate limiting your network, you can
both prevent becoming a casualty or the cause of these attacks.</p><p>You should filter your networks so that you do not allow non-local IP source
addressed packets to leave your network. This stops people from anonymously
sending junk to the Internet. </p><p>Rate limiting goes much as shown earlier. To refresh your memory, our
ASCIIgram again:</p><p></p><pre class="SCREEN">[The Internet] ---&lt;E3, T3, whatever&gt;--- [Linux router] --- [Office+ISP]
                                      eth1          eth0</pre><p></p><p>We first set up the prerequisite parts:</p><p></p><pre class="SCREEN"># tc qdisc add dev eth0 root handle 10: cbq bandwidth 10Mbit avpkt 1000
# tc class add dev eth0 parent 10:0 classid 10:1 cbq bandwidth 10Mbit rate \
  10Mbit allot 1514 prio 5 maxburst 20 avpkt 1000</pre><p></p><p>If you have 100Mbit, or more, interfaces, adjust these numbers. Now you need
to determine how much ICMP traffic you want to allow. You can perform
measurements with tcpdump, by having it write to a file for a while, and
seeing how much ICMP passes your network. Do not forget to raise the
snapshot length!</p><p>If measurement is impractical, you might want to choose 5% of your available
bandwidth. Let's set up our class:

</p><pre class="SCREEN"># tc class add dev eth0 parent 10:1 classid 10:100 cbq bandwidth 10Mbit rate \
  100Kbit allot 1514 weight 800Kbit prio 5 maxburst 20 avpkt 250 \
  bounded</pre><p></p><p>This limits at 100Kbit. Now we need a filter to assign ICMP traffic to this
class:

</p><pre class="SCREEN"># tc filter add dev eth0 parent 10:0 protocol ip prio 100 u32 match ip
  protocol 1 0xFF flowid 10:100</pre><p></p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.COOKBOOK.INTERACTIVE-PRIO">15.4. Prioritizing interactive traffic</a></h2><p>If lots of data is coming down your link, or going up for that matter, and
you are trying to do some maintenance via telnet or ssh, this may not go too
well. Other packets are blocking your keystrokes. Wouldn't it be great if
there were a way for your interactive packets to sneak past the bulk
traffic? Linux can do this for you!</p><p>As before, we need to handle traffic going both ways. Evidently, this works
best if there are Linux boxes on both ends of your link, although other
UNIX's are able to do this. Consult your local Solaris/BSD guru for this.</p><p>The standard pfifo_fast scheduler has 3 different 'bands'. Traffic in band 0
is transmitted first, after which traffic in band 1 and 2 gets considered.
It is vital that our interactive traffic be in band 0!</p><p>We blatantly adapt from the (soon to be obsolete) ipchains HOWTO:</p><p>There are four seldom-used bits in the IP header, called the Type of Service
(TOS) bits. They effect the way packets are treated; the four bits are
"Minimum Delay", "Maximum Throughput", "Maximum Reliability" and "Minimum
Cost". Only one of these bits is allowed to be set. Rob van Nieuwkerk, the
author of the ipchains TOS-mangling code, puts it as follows:</p><a name="AEN2069"></a><blockquote class="BLOCKQUOTE"><p>Especially the "Minimum Delay" is important for me. I switch it on for
"interactive" packets in my upstream (Linux) router. I'm
behind a 33k6 modem link. Linux prioritizes packets in 3 queues. This
way I get acceptable interactive performance while doing bulk
downloads at the same time. </p></blockquote><p>The most common use is to set telnet &amp; ftp control connections to "Minimum
Delay" and FTP data to "Maximum Throughput". This would be
done as follows, on your upstream router:</p><p></p><pre class="SCREEN"># iptables -A PREROUTING -t mangle -p tcp --sport telnet \
  -j TOS --set-tos Minimize-Delay
# iptables -A PREROUTING -t mangle -p tcp --sport ftp \
  -j TOS --set-tos Minimize-Delay
# iptables -A PREROUTING -t mangle -p tcp --sport ftp-data \
  -j TOS --set-tos Maximize-Throughput</pre><p></p><p>Now, this only works for data going from your telnet foreign host to your
local computer. The other way around appears to be done for you, ie, telnet,
ssh &amp; friends all set the TOS field on outgoing packets automatically.</p><p>Should you have an application that does not do this, you can always do it 
with netfilter. On your local box:</p><p></p><pre class="SCREEN"># iptables -A OUTPUT -t mangle -p tcp --dport telnet \
  -j TOS --set-tos Minimize-Delay
# iptables -A OUTPUT -t mangle -p tcp --dport ftp \
  -j TOS --set-tos Minimize-Delay
# iptables -A OUTPUT -t mangle -p tcp --dport ftp-data \
  -j TOS --set-tos Maximize-Throughput</pre><p></p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.COOKBOOK.SQUID">15.5. Transparent web-caching using <span class="APPLICATION">netfilter</span>,
	<span class="APPLICATION">iproute2</span>, <span class="APPLICATION">ipchains</span> and 
	<span class="APPLICATION">squid</span></a></h2><p>	This section was sent in by reader Ram Narula from Internet for Education
	(Thailand).
      </p><p>	The regular technique in accomplishing this in Linux
	is probably with use of ipchains AFTER making sure
	that the "outgoing" port 80(web) traffic gets routed through
	the server running squid.
      </p><p>	There are 3 common methods to make sure "outgoing"
	port 80 traffic gets routed to the server running squid
	and 4th one is being introduced here.
      </p><p>	</p><p></p><div class="VARIABLELIST"><dl><dt>Making the gateway router do it.</dt><dd><p>		If you can tell your gateway router to 
		match packets that has outgoing destination port
		of 80 to be sent to the IP address of squid server.
	      </p><p>		BUT
	      </p><p>		This would put additional load on the router and
		some commercial routers might not even support this.
	      </p></dd><dt>Using a Layer 4 switch.</dt><dd><p>		Layer 4 switches can handle this without any problem.
	      </p><p>		BUT
	      </p><p>		The cost for this equipment is usually very high. Typical
		layer 4 switch would normally cost more than
		a typical router+good linux server.
	      </p></dd><dt>Using cache server as network's gateway.</dt><dd><p>		You can force ALL traffic through cache server.
	      </p><p>		BUT
	      </p><p>		This is quite risky because Squid does utilize lots of CPU power which might
		result in slower over-all network performance or the server itself might crash and no one on the
		network will be able to access the Internet if that occurs.
	      </p></dd><dt>Linux+NetFilter router.</dt><dd><p>		By using NetFilter another technique can be implemented
		which is using NetFilter for "mark"ing the packets
		with destination port 80 and using iproute2 to
		route the "mark"ed packets to the Squid server.
	      </p></dd></dl></div>
	<pre class="SCREEN">|----------------|
| Implementation |
|----------------|

 Addresses used
 10.0.0.1 naret (NetFilter server)
 10.0.0.2 silom (Squid server)
 10.0.0.3 donmuang (Router connected to the Internet)
 10.0.0.4 kaosarn (other server on network)
 10.0.0.5 RAS
 10.0.0.0/24 main network
 10.0.0.0/19 total network

|---------------|
|Network diagram|
|---------------|

Internet
|
donmuang
|
------------hub/switch----------
|        |             |       |
naret   silom        kaosarn  RAS etc.
	</pre>

	First, make all traffic pass through naret by making sure it is the default gateway except for silom.
	Silom's default gateway has to be donmuang (10.0.0.3) or this would create web traffic loop.
      <p></p><p>	(all servers on my network had 10.0.0.1 as the default 
gateway 	which was the former IP address of donmuang router so what I 
did
	was changed the IP address of donmuang to 10.0.0.3 and gave naret ip 
address of 10.0.0.1)
      </p><p>	</p><pre class="SCREEN">Silom
-----
-setup squid and ipchains 
	</pre>
      <p></p><p>	Setup Squid server on silom, make sure it does support 
	transparent caching/proxying, the default port is usually
	3128, so all traffic for port 80 has to be redirected to port 3128 
locally. This can be done by using ipchains with the following:
      </p><p>	</p><pre class="SCREEN">silom# ipchains -N allow1
silom# ipchains -A allow1 -p TCP -s 10.0.0.0/19 -d 0/0 80 -j REDIRECT 3128
silom# ipchains -I input -j allow1
	</pre>
      <p></p><p>Or, in netfilter lingo:
	</p><pre class="SCREEN">silom# iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 3128
	</pre>
      <p></p><p>	(note: you might have other entries as well)
      </p><p>	For more information on setting Squid server please refer to Squid FAQ page on <a href="http://squid.nlanr.net/" target="_top">http://squid.nlanr.net</a>).
      </p><p>	Make sure ip forwarding is enabled on this server and the default gateway for this server is donmuang router (NOT naret).
      </p><p>	</p><pre class="SCREEN">Naret
-----
-setup iptables and iproute2
-disable icmp REDIRECT messages (if needed)
	</pre>
      <p></p><p>	</p><p></p><ol type="1"><li><p>	      "Mark" packets of destination port 80 with value 2
	      </p><pre class="SCREEN">naret# iptables -A PREROUTING -i eth0 -t mangle -p tcp --dport 80 \
 -j MARK --set-mark 2
	      </pre>
	    <p></p></li><li><p>	      Setup iproute2 so it will route packets with "mark" 2 to silom
	      </p><pre class="SCREEN">naret# echo 202 www.out &gt;&gt; /etc/iproute2/rt_tables
naret# ip rule add fwmark 2 table www.out
naret# ip route add default via 10.0.0.2 dev eth0 table www.out
naret# ip route flush cache
	      </pre>
	    <p></p><p>	      If donmuang and naret is on the same subnet then naret should not send out icmp REDIRECT messages.
	      In this case it is, so icmp REDIRECTs has to be disabled by:
	      </p><pre class="SCREEN">naret# echo 0 &gt; /proc/sys/net/ipv4/conf/all/send_redirects
naret# echo 0 &gt; /proc/sys/net/ipv4/conf/default/send_redirects
naret# echo 0 &gt; /proc/sys/net/ipv4/conf/eth0/send_redirects
	      </pre>
	    <p></p></li></ol>
      <p></p><p>	The setup is complete, check the configuration
      </p><p>	</p><pre class="SCREEN">On naret:

naret# iptables -t mangle -L
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination         
MARK       tcp  --  anywhere             anywhere           tcp dpt:www MARK set 0x2 

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         

naret# ip rule ls
0:      from all lookup local 
32765:  from all fwmark        2 lookup www.out 
32766:  from all lookup main 
32767:  from all lookup default 

naret# ip route list table www.out
default via 203.114.224.8 dev eth0 

naret# ip route   
10.0.0.1 dev eth0  scope link 
10.0.0.0/24 dev eth0  proto kernel  scope link  src 10.0.0.1
127.0.0.0/8 dev lo  scope link 
default via 10.0.0.3 dev eth0 

(make sure silom belongs to one of the above lines, in this case
it's the line with 10.0.0.0/24)

|------|
|-DONE-|
|------|
	</pre>
      <p></p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2139">15.5.1. Traffic flow diagram after implementation</a></h3><pre class="SCREEN">|-----------------------------------------|
|Traffic flow diagram after implementation|
|-----------------------------------------|

INTERNET
/\
||
\/
-----------------donmuang router---------------------
/\                                      /\         ||
||                                      ||         ||
||                                      \/         ||
naret                                  silom       ||
*destination port 80 traffic=========&gt;(cache)      ||
/\                                      ||         ||
||                                      \/         \/
\\===================================kaosarn, RAS, etc.</pre><p>Note that the network is asymmetric as there is one extra hop on 
general outgoing path.</p><p>Here is run down for packet traversing the network from kaosarn
to and from the Internet.</p><p></p><div class="VARIABLELIST"><dl><dt>For web/http traffic</dt><dd><p></p><pre class="SCREEN">kaosarn http request-&gt;naret-&gt;silom-&gt;donmuang-&gt;internet
http replies from Internet-&gt;donmuang-&gt;silom-&gt;kaosarn
  </pre><p></p></dd><dt>For non-web/http requests(eg. telnet)</dt><dd><p></p><pre class="SCREEN">kaosarn outgoing data-&gt;naret-&gt;donmuang-&gt;internet
incoming data from Internet-&gt;donmuang-&gt;kaosarn
  </pre><p></p></dd></dl></div></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.COOKBOOK.MTU-DISCOVERY">15.6. Circumventing Path MTU Discovery issues with per route MTU settings</a></h2><p>For sending bulk data, the Internet generally works better when using larger
packets. Each packet implies a routing decision, when sending a 1 megabyte
file, this can either mean around 700 packets when using packets that are as
large as possible, or 4000 if using the smallest default.</p><p>However, not all parts of the Internet support full 1460 bytes of payload
per packet. It is therefore necessary to try and find the largest packet
that will 'fit', in order to optimize a connection.</p><p>This process is called 'Path MTU Discovery', where MTU stands for 'Maximum
Transfer Unit.' </p><p>When a router encounters a packet that's too big too send in one piece, AND
it has been flagged with the "Don't Fragment" bit, it returns an ICMP
message stating that it was forced to drop a packet because of this. The
sending host acts on this hint by sending smaller packets, and by iterating
it can find the optimum packet size for a connection over a certain path.</p><p>This used to work well until the Internet was discovered by hooligans who do
their best to disrupt communications. This in turn lead administrators to
either block or shape ICMP traffic in a misguided attempt to improve
security or robustness of their Internet service.</p><p>What has happened now is that Path MTU Discovery is working less and less
well and fails for certain routes, which leads to strange TCP/IP sessions
which die after a while.</p><p>Although I have no proof for this, two sites who I used to have this problem
with both run Alteon Acedirectors before the affected systems - perhaps
somebody more knowledgeable can provide clues as to why this happens.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2164">15.6.1. Solution</a></h3><p>When you encounter sites that suffer from this problem, you can disable Path
MTU discovery by setting it manually. Koos van den Hout, slightly edited,
writes:</p><a name="AEN2167"></a><blockquote class="BLOCKQUOTE"><p>The following problem: I set the mtu/mru of my leased line running ppp to
296 because it's only 33k6 and I cannot influence the queueing on the
other side. At 296, the response to a key press is within a reasonable
time frame.</p><p>And, on my side I have a masqrouter running (of course) Linux.</p><p>Recently I split 'server' and 'router' so most applications are run on a
different machine than the routing happens on.</p><p>I then had trouble logging into irc. Big panic! Some digging did find
out that I got connected to irc, even showed up as 'connected' on irc
but I did not receive the motd from irc. I checked what could be wrong
and noted that I already had some previous trouble reaching certain
websites related to the MTU, since I had no trouble reaching them when
the MTU was 1500, the problem just showed when the MTU was set to 296.
Since irc servers block about every kind of traffic not needed for their
immediate operation, they also block icmp. </p><p>I managed to convince the operators of a webserver that this was the cause
of a problem, but the irc server operators were not going to fix this.</p><p>So, I had to make sure outgoing masqueraded traffic started with the lower
mtu of the outside link. But I want local ethernet traffic to have the
normal mtu (for things like nfs traffic).</p><p>Solution:</p><pre class="SCREEN">ip route add default via 10.0.0.1 mtu 296</pre><p>(10.0.0.1 being the default gateway, the inside address of the
masquerading router)</p></blockquote><p>In general, it is possible to override PMTU Discovery by setting specific
routes. For example, if only a certain subnet is giving problems, this
should help:</p><pre class="SCREEN">ip route add 195.96.96.0/24 via 10.0.0.1 mtu 1000</pre></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.COOKBOOK.MTU-MSS">15.7. Circumventing Path MTU Discovery issues with MSS Clamping
  (for ADSL, cable, PPPoE &amp; PPtP users)</a></h2><p>As explained above, Path MTU Discovery doesn't work as well as it should
anymore. If you know for a fact that a hop somewhere in your network has a
limited (&lt;1500) MTU, you cannot rely on PMTU Discovery finding this out.</p><p>Besides MTU, there is yet another way to set the maximum packet size, the so
called Maximum Segment Size. This is a field in the TCP Options part of a
SYN packet.</p><p>Recent Linux kernels, and a few PPPoE drivers (notably, the excellent
Roaring Penguin one), feature the possibility to 'clamp the MSS'. </p><p>The good thing about this is that by setting the MSS value, you are telling
the remote side unequivocally 'do not ever try to send me packets bigger
than this value'. No ICMP traffic is needed to get this to work.</p><p>The bad thing is that it's an obvious hack - it breaks 'end to end' by
modifying packets. Having said that, we use this trick in many places and it
works like a charm.</p><p>In order for this to work you need at least iptables-1.2.1a and Linux 2.4.3
or higher. The basic command line is:

</p><pre class="SCREEN"># iptables -A FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS  --clamp-mss-to-pmtu</pre><p></p><p>This calculates the proper MSS for your link. If you are feeling brave, or
think that you know best, you can also do something like this:</p><p></p><pre class="SCREEN"># iptables -A FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --set-mss 128</pre><p></p><p>This sets the MSS of passing SYN packets to 128. Use this if you have VoIP
with tiny packets, and huge http packets which are causing chopping in your
voice calls.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.COOKBOOK.ULTIMATE-TC">15.8. The Ultimate Traffic Conditioner: Low Latency, Fast Up &amp; Downloads</a></h2><p>Note: This script has recently been upgraded and previously only worked for
Linux clients in your network! So you might want to update if you have
Windows machines or Macs in your network and noticed that they were not able
to download faster while others were uploading.</p><p>I attempted to create the holy grail:
</p><p></p><div class="VARIABLELIST"><dl><dt>Maintain low latency for interactive traffic at all times</dt><dd><p>This means that downloading or uploading files should not disturb SSH or
even telnet. These are the most important things, even 200ms latency is
sluggish to work over.</p></dd><dt>Allow 'surfing' at reasonable speeds while up or downloading</dt><dd><p>Even though http is 'bulk' traffic, other traffic should not drown it out 
too much.</p></dd><dt>Make sure uploads don't harm downloads, and the other way around</dt><dd><p>This is a much observed phenomenon where outgress traffic simply destroys
download speed.</p></dd></dl></div>
It turns out that all this is possible, at the cost of a tiny bit of
bandwidth. The reason that uploads, downloads and ssh hurt each other is the
presence of large queues in many domestic access devices like cable or DSL
modems.<p></p><p>The next section explains in depth what causes the delays, and how we can
fix them. You can safely skip it and head straight for the script if you
don't care how the magic is performed.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2210">15.8.1. Why it doesn't work well by default</a></h3><p>ISPs know that they are benchmarked solely on how fast people can download.
Besides available bandwidth, download speed is influenced heavily by packet
loss, which seriously hampers TCP/IP performance. Large queues can help
prevent packet loss, and speed up downloads. So ISPs configure large queues.</p><p>These large queues however damage interactivity. A keystroke must first
travel the upstream queue, which may be seconds (!) long and go to your
remote host. It is then displayed, which leads to a packet coming back, which
must then traverse the downstream queue, located at your ISP, before it
appears on your screen.</p><p>This HOWTO teaches you how to mangle and process the queue in many ways, but
sadly, not all queues are accessible to us. The queue over at the ISP is
completely off-limits, whereas the upstream queue probably lives inside your
cable modem or DSL device. You may or may not be able to configure it. Most
probably not.</p><p>So, what next? As we can't control either of those queues, they must be
eliminated, and moved to your Linux router. Luckily this is possible.</p><p></p><p></p><div class="VARIABLELIST"><dl><dt>Limit upload speed</dt><dd><p>By limiting our upload speed to slightly less than the truly available rate,
no queues are built up in our modem. The queue is now moved to Linux.</p></dd><dt>Limit download speed</dt><dd><p>This is slightly trickier as we can't really influence how fast the internet
ships us data. We can however drop packets that are coming in too fast,
which causes TCP/IP to slow down to just the rate we want. Because we don't 
want to drop traffic unnecessarily, we configure a 'burst' size we allow at
higher speed.</p></dd></dl></div><p></p><p>Now, once we have done this, we have eliminated the downstream queue totally
(except for short bursts), and gain the ability to manage the upstream queue
with all the power Linux offers.</p><p>What remains to be done is to make sure interactive traffic jumps to the
front of the upstream queue. To make sure that uploads don't hurt downloads,
we also move ACK packets to the front of the queue. This is what normally
causes the huge slowdown observed when generating bulk traffic both ways.
The ACKnowledgements for downstream traffic must compete with upstream
traffic, and get delayed in the process.</p><p>If we do all this we get the following measurements using an excellent ADSL
connection from xs4all in the Netherlands:</p><p></p><pre class="SCREEN">Baseline latency:
round-trip min/avg/max = 14.4/17.1/21.7 ms

Without traffic conditioner, while downloading:
round-trip min/avg/max = 560.9/573.6/586.4 ms

Without traffic conditioner, while uploading:
round-trip min/avg/max = 2041.4/2332.1/2427.6 ms

With conditioner, during 220kbit/s upload:
round-trip min/avg/max = 15.7/51.8/79.9 ms

With conditioner, during 850kbit/s download:
round-trip min/avg/max = 20.4/46.9/74.0 ms

When uploading, downloads proceed at ~80% of the available speed. Uploads
at around 90%. Latency then jumps to 850 ms, still figuring out why.</pre><p></p><p>What you can expect from this script depends a lot on your actual uplink
speed. When uploading at full speed, there will always be a single packet
ahead of your keystroke. That is the lower limit to the latency you can
achieve - divide your MTU by your upstream speed to calculate. Typical
values will be somewhat higher than that. Lower your MTU for better effects!</p><p>Next, two versions of this script, one with Devik's excellent HTB, the other
with CBQ which is in each Linux kernel, unlike HTB. Both are tested and work
well.</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2233">15.8.2. The actual script (CBQ)</a></h3><p>Works on all kernels. Within the CBQ
qdisc we place two Stochastic Fairness Queues that make sure that multiple
bulk streams don't drown each other out.</p><p>Downstream traffic is policed using a tc filter containing a Token Bucket
Filter.</p><p>You might improve on this script by adding 'bounded' to the line that starts
with 'tc class add .. classid 1:20'. If you lowered your MTU, also lower the
allot &amp; avpkt numbers!</p><p></p><pre class="SCREEN">#!/bin/bash 

# The Ultimate Setup For Your Internet Connection At Home
# 
#
# Set the following values to somewhat less than your actual download
# and uplink speed. In kilobits
DOWNLINK=800
UPLINK=220
DEV=ppp0

# clean existing down- and uplink qdiscs, hide errors
tc qdisc del dev $DEV root    2&gt; /dev/null &gt; /dev/null
tc qdisc del dev $DEV ingress 2&gt; /dev/null &gt; /dev/null

###### uplink

# install root CBQ

tc qdisc add dev $DEV root handle 1: cbq avpkt 1000 bandwidth 10mbit 

# shape everything at $UPLINK speed - this prevents huge queues in your
# DSL modem which destroy latency:
# main class

tc class add dev $DEV parent 1: classid 1:1 cbq rate ${UPLINK}kbit \
allot 1500 prio 5 bounded isolated 

# high prio class 1:10:

tc class add dev $DEV parent 1:1 classid 1:10 cbq rate ${UPLINK}kbit \
   allot 1600 prio 1 avpkt 1000

# bulk and default class 1:20 - gets slightly less traffic, 
#  and a lower priority:

tc class add dev $DEV parent 1:1 classid 1:20 cbq rate $[9*$UPLINK/10]kbit \
   allot 1600 prio 2 avpkt 1000

# both get Stochastic Fairness:
tc qdisc add dev $DEV parent 1:10 handle 10: sfq perturb 10
tc qdisc add dev $DEV parent 1:20 handle 20: sfq perturb 10

# start filters
# TOS Minimum Delay (ssh, NOT scp) in 1:10:
tc filter add dev $DEV parent 1:0 protocol ip prio 10 u32 \
      match ip tos 0x10 0xff  flowid 1:10

# ICMP (ip protocol 1) in the interactive class 1:10 so we 
# can do measurements &amp; impress our friends:
tc filter add dev $DEV parent 1:0 protocol ip prio 11 u32 \
	match ip protocol 1 0xff flowid 1:10

# To speed up downloads while an upload is going on, put ACK packets in
# the interactive class:

tc filter add dev $DEV parent 1: protocol ip prio 12 u32 \
   match ip protocol 6 0xff \
   match u8 0x05 0x0f at 0 \
   match u16 0x0000 0xffc0 at 2 \
   match u8 0x10 0xff at 33 \
   flowid 1:10

# rest is 'non-interactive' ie 'bulk' and ends up in 1:20

tc filter add dev $DEV parent 1: protocol ip prio 13 u32 \
   match ip dst 0.0.0.0/0 flowid 1:20

########## downlink #############
# slow downloads down to somewhat less than the real speed  to prevent 
# queuing at our ISP. Tune to see how high you can set it.
# ISPs tend to have *huge* queues to make sure big downloads are fast
#
# attach ingress policer:

tc qdisc add dev $DEV handle ffff: ingress

# filter *everything* to it (0.0.0.0/0), drop everything that's
# coming in too fast:

tc filter add dev $DEV parent ffff: protocol ip prio 50 u32 match ip src \
   0.0.0.0/0 police rate ${DOWNLINK}kbit burst 10k drop flowid :1</pre>

If you want this script to be run by ppp on connect, copy it to
/etc/ppp/ip-up.d.<p></p><p>If the last two lines give an error, update your tc tool to a newer version!</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2241">15.8.3. The actual script (HTB)</a></h3><p>The following script achieves all goals using the wonderful HTB queue, see
the relevant chapter. Well worth patching your kernel for! 

</p><pre class="SCREEN">#!/bin/bash

# The Ultimate Setup For Your Internet Connection At Home
# 
#
# Set the following values to somewhat less than your actual download
# and uplink speed. In kilobits
DOWNLINK=800
UPLINK=220
DEV=ppp0

# clean existing down- and uplink qdiscs, hide errors
tc qdisc del dev $DEV root    2&gt; /dev/null &gt; /dev/null
tc qdisc del dev $DEV ingress 2&gt; /dev/null &gt; /dev/null

###### uplink

# install root HTB, point default traffic to 1:20:

tc qdisc add dev $DEV root handle 1: htb default 20

# shape everything at $UPLINK speed - this prevents huge queues in your
# DSL modem which destroy latency:

tc class add dev $DEV parent 1: classid 1:1 htb rate ${UPLINK}kbit burst 6k

# high prio class 1:10:

tc class add dev $DEV parent 1:1 classid 1:10 htb rate ${UPLINK}kbit \
   burst 6k prio 1

# bulk &amp; default class 1:20 - gets slightly less traffic, 
# and a lower priority:

tc class add dev $DEV parent 1:1 classid 1:20 htb rate $[9*$UPLINK/10]kbit \
   burst 6k prio 2

# both get Stochastic Fairness:
tc qdisc add dev $DEV parent 1:10 handle 10: sfq perturb 10
tc qdisc add dev $DEV parent 1:20 handle 20: sfq perturb 10

# TOS Minimum Delay (ssh, NOT scp) in 1:10:
tc filter add dev $DEV parent 1:0 protocol ip prio 10 u32 \
      match ip tos 0x10 0xff  flowid 1:10

# ICMP (ip protocol 1) in the interactive class 1:10 so we 
# can do measurements &amp; impress our friends:
tc filter add dev $DEV parent 1:0 protocol ip prio 10 u32 \
	match ip protocol 1 0xff flowid 1:10

# To speed up downloads while an upload is going on, put ACK packets in
# the interactive class:

tc filter add dev $DEV parent 1: protocol ip prio 10 u32 \
   match ip protocol 6 0xff \
   match u8 0x05 0x0f at 0 \
   match u16 0x0000 0xffc0 at 2 \
   match u8 0x10 0xff at 33 \
   flowid 1:10

# rest is 'non-interactive' ie 'bulk' and ends up in 1:20


########## downlink #############
# slow downloads down to somewhat less than the real speed  to prevent 
# queuing at our ISP. Tune to see how high you can set it.
# ISPs tend to have *huge* queues to make sure big downloads are fast
#
# attach ingress policer:

tc qdisc add dev $DEV handle ffff: ingress

# filter *everything* to it (0.0.0.0/0), drop everything that's
# coming in too fast:

tc filter add dev $DEV parent ffff: protocol ip prio 50 u32 match ip src \
   0.0.0.0/0 police rate ${DOWNLINK}kbit burst 10k drop flowid :1</pre><p></p><p>If you want this script to be run by ppp on connect, copy it to
/etc/ppp/ip-up.d.</p><p>If the last two lines give an error, update your tc tool to a newer version!</p></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.RATELIMIT.SINGLE">15.9. Rate limiting a single host or netmask</a></h2><p>	Although this is described in stupendous details elsewhere and in our manpages, this question gets asked a lot and 
	happily there is a simple answer that does not need full comprehension of traffic control.
      </p><p>	This three line script does the trick:
      </p><p>	</p><pre class="SCREEN">	  tc qdisc add dev $DEV root handle 1: cbq avpkt 1000 bandwidth 10mbit 

	  tc class add dev $DEV parent 1: classid 1:1 cbq rate 512kbit \
	  allot 1500 prio 5 bounded isolated 

	  tc filter add dev $DEV parent 1: protocol ip prio 16 u32 \
	  match ip dst 195.96.96.97 flowid 1:1
	</pre>
      <p></p><p>	The first line installs a class based queue on your interface, and tells the kernel that for calculations,
	it can be assumed to be a 10mbit interface. If you get this wrong, no real harm is done. But getting it right will 
	make everything more precise.
      </p><p>	The second line creates a 512kbit class with some reasonable defaults. For details, see the cbq manpages and
	<a href="#LARTC.QDISC">Chapter 9</a>.
      </p><p>	The last line tells which traffic should go to the shaped class. Traffic not matched by this rule is NOT shaped. To make more 
	complicated matches (subnets, source ports, destination ports), see <a href="#LARTC.FILTERING.SIMPLE">Section 9.6.2</a>.
      </p><p>	If you changed anything and want to reload the script, execute 'tc qdisc del dev $DEV root' to clean up your existing
	configuration.
      </p><p>	The script can further be improved by adding a last optional line 'tc qdisc add dev $DEV parent 1:1 sfq perturb 10'. See 
	<a href="#LARTC.SFQ">Section 9.2.3</a> for details on what this does.
      </p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.COOKBOOK.FULLNAT.INTRO">15.10. Example of a full nat solution with QoS</a></h2><p>			I'm Pedro Larroy
<code class="EMAIL">&lt;<a href="mailto:piotr%member.fsf.org">piotr%member.fsf.org</a>&gt;</code>.
 Here I'm describing a common set up where we have lots of users in a 
private network connected to the Internet trough a Linux router with a 
public ip address that is doing network address translation (NAT). I use
 this QoS setup to give access to the Internet to 198 users in a 
university dorm, in which I live and I'm netadmin of. The users here do 
heavy use of peer to peer programs, so proper traffic control is a must.
 I hope this serves as a practical example for all interested lartc 
readers.
		</p><p>			At first I make a practical approach with step by step 
configuration, and in the end I explain how to make the process 
automatic at bootime. The network to which this example applies is a 
private LAN connected to the Internet through a Linux router which has 
one public ip address. Extending it to several public ip address should 
be very easy, a couple of iptables rules should be added.
			In order to get things working we need:
			</p><p></p><div class="VARIABLELIST"><dl><dt>Linux 2.4.18 or higher kernel version installed</dt><dd><p>					If you use 2.4.18 you will have to apply HTB patch available here.
					</p></dd><dt>iproute</dt><dd><p>					Also ensure the "tc" binary is HTB ready, a precompiled binary is distributed with HTB.
					</p></dd><dt>iptables</dt><dd><p>					</p></dd></dl></div>

		<p></p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2279">15.10.1. Let's begin optimizing that scarce bandwidth</a></h3><p>
			First we set up some qdiscs in which we will classify the traffic. We
 create a htb qdisc with 6 classes with ascending priority. Then we have
 classes that will always get allocated rate, but can use the unused 
bandwidth that other classes don't need. Recall that classes with higher
 priority ( i.e with a lower prio number ) will get excess of bandwith 
allocated first. Our connection is 2Mb down 300kbits/s up Adsl. I use 
240kbit/s as ceil rate just because it's the higher I can set it before 
latency starts to grow, due to buffer filling in whatever place between 
us and remote hosts. This parameter should be timed experimentally, 
raising and lowering it while observing latency between some near hosts.
		</p><p>			Adjust CEIL to 75% of your upstream bandwith limit by now, 
and where I use eth0, you should use the interface which has a public 
Internet address. To begin our example execute the following in a root 
shell:
			</p><pre class="SCREEN">CEIL=240
tc qdisc add dev eth0 root handle 1: htb default 15
tc class add dev eth0 parent 1: classid 1:1 htb rate ${CEIL}kbit ceil ${CEIL}kbit
tc class add dev eth0 parent 1:1 classid 1:10 htb rate 80kbit ceil 80kbit prio 0
tc class add dev eth0 parent 1:1 classid 1:11 htb rate 80kbit ceil ${CEIL}kbit prio 1
tc class add dev eth0 parent 1:1 classid 1:12 htb rate 20kbit ceil ${CEIL}kbit prio 2
tc class add dev eth0 parent 1:1 classid 1:13 htb rate 20kbit ceil ${CEIL}kbit prio 2
tc class add dev eth0 parent 1:1 classid 1:14 htb rate 10kbit ceil ${CEIL}kbit prio 3
tc class add dev eth0 parent 1:1 classid 1:15 htb rate 30kbit ceil ${CEIL}kbit prio 3
tc qdisc add dev eth0 parent 1:12 handle 120: sfq perturb 10
tc qdisc add dev eth0 parent 1:13 handle 130: sfq perturb 10
tc qdisc add dev eth0 parent 1:14 handle 140: sfq perturb 10
tc qdisc add dev eth0 parent 1:15 handle 150: sfq perturb 10
			</pre>
			We have just created a htb tree with one level depth. Something like this:

			<pre class="SCREEN">+---------+
| root 1: |
+---------+
     |
+---------------------------------------+
| class 1:1                             |
+---------------------------------------+
  |      |      |      |      |      |      
+----+ +----+ +----+ +----+ +----+ +----+
|1:10| |1:11| |1:12| |1:13| |1:14| |1:15| 
+----+ +----+ +----+ +----+ +----+ +----+ 
			</pre>
			<p></p><div class="VARIABLELIST"><dl><dt>classid 1:10 htb rate 80kbit ceil 80kbit prio 0</dt><dd><p>
					This is the highest priority class. The packets in this class will 
have the lowest delay and would get the excess of bandwith first so it's
 a good idea to limit the ceil rate to this class. We will send through 
this class the following packets that benefit from low delay, such as 
interactive traffic: <span class="emphasis"><i class="EMPHASIS">ssh, telnet, dns, quake3, irc, and packets with the SYN flag</i></span>.
					</p></dd><dt>classid 1:11 htb rate 80kbit ceil ${CEIL}kbit prio 1</dt><dd><p>
					Here we have the first class in which we can start to put bulk 
traffic. In my example I have traffic from the local web server and 
requests for web pages: source port 80, and destination port 80 
respectively.
					</p></dd><dt>classid 1:12 htb rate 20kbit ceil ${CEIL}kbit prio 2</dt><dd><p>					In this class I will put traffic with Maximize-Throughput TOS bit set and the rest of the traffic that goes from <span class="emphasis"><i class="EMPHASIS">local processes</i></span> on the router to the Internet. So the following classes will only have traffic that is <span class="QUOTE">"routed through"</span> the box.
					</p></dd><dt>classid 1:13 htb rate 20kbit ceil ${CEIL}kbit prio 2</dt><dd><p>					This class is for the traffic of other NATed machines that need higher priority in their bulk traffic.
					</p></dd><dt>classid 1:14 htb rate 10kbit ceil ${CEIL}kbit prio 3</dt><dd><p>					Here goes mail traffic (SMTP,pop3...) and packets with Minimize-Cost TOS bit set.
					</p></dd><dt>classid 1:15 htb rate 30kbit ceil ${CEIL}kbit prio 3</dt><dd><p>
					And finally here we have bulk traffic from the NATed machines 
behind the router. All kazaa, edonkey, and others will go here, in order
 to not interfere with other services.
					</p></dd></dl></div>




		<p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2313">15.10.2. Classifying packets</a></h3><p>
			We have created the qdisc setup but no packet classification has been
 made, so now all outgoing packets are going out in class 1:15 ( because
 we used: tc qdisc add dev eth0 root handle 1: htb <span class="emphasis"><i class="EMPHASIS">default 15</i></span> ). Now we need to tell which packets go where. This is the most important part.
		</p><p>			Now we set the filters so we can classify the packets with 
iptables. I really prefer to do it with iptables, because they are very 
flexible and you have packet count for each rule. Also with the RETURN 
target packets don't need to traverse all rules. We execute the 
following commands:
			</p><pre class="SCREEN">tc filter add dev eth0 parent 1:0 protocol ip prio 1 handle 1 fw classid 1:10
tc filter add dev eth0 parent 1:0 protocol ip prio 2 handle 2 fw classid 1:11
tc filter add dev eth0 parent 1:0 protocol ip prio 3 handle 3 fw classid 1:12
tc filter add dev eth0 parent 1:0 protocol ip prio 4 handle 4 fw classid 1:13
tc filter add dev eth0 parent 1:0 protocol ip prio 5 handle 5 fw classid 1:14
tc filter add dev eth0 parent 1:0 protocol ip prio 6 handle 6 fw classid 1:15
			</pre>
			We have just told the kernel that packets that have a specific FWMARK
 value ( handle x fw ) go in the specified class ( classid x:x). Next 
you will see how to mark packets with iptables. 
		<p></p><p>			First you have to understand how packet traverse the filters with iptables:
			</p><pre class="SCREEN">        +------------+                +---------+               +-------------+
Packet -| PREROUTING |--- routing-----| FORWARD |-------+-------| POSTROUTING |- Packets
input   +------------+    decision    +---------+       |       +-------------+    out
                             |                          |
                        +-------+                    +--------+   
                        | INPUT |---- Local process -| OUTPUT |
                        +-------+                    +--------+

			</pre>
			I assume you have all your tables created and with default policy 
ACCEPT ( -P ACCEPT ) if you haven't poked with iptables yet, It should 
be ok by default. Ours private network is a class B with address 
172.17.0.0/16 and public ip is 212.170.21.172
		<p></p><p>			Next we instruct the kernel to <span class="emphasis"><i class="EMPHASIS">actually do NAT</i></span>, so clients in the private network can start talking to the outside. 

			</p><pre class="SCREEN">echo 1 &gt; /proc/sys/net/ipv4/ip_forward
iptables -t nat -A POSTROUTING -s 172.17.0.0/255.255.0.0 -o eth0 -j SNAT --to-source 212.170.21.172
			</pre>
			
			Now check that packets are flowing through 1:15:
			
			<pre class="SCREEN">tc -s class show dev eth0
			</pre>
			
		<p></p><p>			You can start marking packets adding rules to the PREROUTING chain in the mangle table.
			
			</p><pre class="SCREEN">iptables -t mangle -A PREROUTING -p icmp -j MARK --set-mark 0x1
iptables -t mangle -A PREROUTING -p icmp -j RETURN
			</pre>
			
			Now you should be able to see packet count increasing when pinging 
from machines within the private network to some site on the Internet. 
Check packet count increasing in 1:10
			<pre class="SCREEN">tc -s class show dev eth0
			</pre>
			We have done a -j RETURN so packets don't traverse all rules. Icmp 
packets won't match other rules below RETURN. Keep that in mind.
			Now we can start adding more rules, lets do proper TOS handling:
			
			<pre class="SCREEN">iptables -t mangle -A PREROUTING -m tos --tos Minimize-Delay -j MARK --set-mark 0x1
iptables -t mangle -A PREROUTING -m tos --tos Minimize-Delay -j RETURN
iptables -t mangle -A PREROUTING -m tos --tos Minimize-Cost -j MARK --set-mark 0x5
iptables -t mangle -A PREROUTING -m tos --tos Minimize-Cost -j RETURN
iptables -t mangle -A PREROUTING -m tos --tos Maximize-Throughput -j MARK --set-mark 0x6
iptables -t mangle -A PREROUTING -m tos --tos Maximize-Throughput -j RETURN
			</pre>

			Now prioritize ssh packets:
			<pre class="SCREEN">iptables -t mangle -A PREROUTING -p tcp -m tcp --sport 22 -j MARK --set-mark 0x1
iptables -t mangle -A PREROUTING -p tcp -m tcp --sport 22 -j RETURN
			</pre>
			A good idea is to prioritize packets to begin tcp connections, those with SYN flag set:
			<pre class="SCREEN">iptables -t mangle -I PREROUTING -p tcp -m tcp --tcp-flags SYN,RST,ACK SYN -j MARK --set-mark 0x1
iptables -t mangle -I PREROUTING -p tcp -m tcp --tcp-flags SYN,RST,ACK SYN -j RETURN
			</pre>
			And so on.
			
			When we are done adding rules to PREROUTING in mangle, we terminate the PREROUTING table with:
			<pre class="SCREEN">iptables -t mangle -A PREROUTING -j MARK --set-mark 0x6
			</pre>
			So previously unmarked traffic goes in 1:15. In fact this last step 
is unnecessary since default class was 1:15, but I will mark them in 
order to be consistent with the whole setup, and furthermore it's useful
 to see the counter in that rule.
		<p></p><p>			It will be a good idea to do the same in the OUTPUT rule,
 so repeat those commands with -A OUTPUT instead of PREROUTING. ( 
s/PREROUTING/OUTPUT/ ). Then traffic generated locally (on the Linux 
router) will also be classified. I finish OUTPUT chain with -j MARK 
--set-mark 0x3 so local traffic has higher priority. 
		</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2333">15.10.3. Improving our setup</a></h3><p>
			Now we have all our setup working. Take time looking at the graphs, 
and watching where your bandwith is spent and how do you want it. Doing 
that for lots of hours, I finally got the Internet connection working 
really well. Otherwise continuous timeouts and nearly zero allotment of 
bandwith to newly created tcp connections will occur.
		</p><p>			If you find that some classes are full most of the time it 
would be a good idea to attach another queueing discipline to them so 
bandwith sharing is more fair:
			</p><pre class="SCREEN">tc qdisc add dev eth0 parent 1:13 handle 130: sfq perturb 10
tc qdisc add dev eth0 parent 1:14 handle 140: sfq perturb 10
tc qdisc add dev eth0 parent 1:15 handle 150: sfq perturb 10
			</pre>
		<p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2338">15.10.4. Making all of the above start at boot</a></h3><p>
			It sure can be done in many ways. In mine, I have a shell script in 
/etc/init.d/packetfilter that accepts [start | stop | stop-tables | 
start-tables | reload-tables] it configures qdiscs and loads needed 
kernel modules, so it behaves much like a daemon. The same script loads 
iptables rules from /etc/network/iptables-rules which can be saved with 
iptables-save and restored with iptables-restore. 
			
		</p></div></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.BRIDGING"></a>Chapter 16. Building bridges, and pseudo-bridges with Proxy ARP</h1><p>Bridges are devices which can be installed in a network without any
reconfiguration. A network switch is basically a many-port bridge. A bridge
is often a 2-port switch. Linux does however support multiple interfaces in
a bridge, making it a true switch.</p><p>Bridges are often deployed when confronted with a broken network that needs
to be fixed without any alterations. Because the bridge is a layer-2 device,
one layer below IP, routers and servers are not aware of its existence.
This means that you can transparently block or modify certain packets, or do
shaping.</p><p>Another good thing is that a bridge can often be replaced by a cross cable
or a hub, should it break down.</p><p>The bad news is that a bridge can cause great confusion unless it is very
well documented. It does not appear in traceroutes, but somehow packets
disappear or get changed from point A to point B ('this network is
HAUNTED!'). You should also wonder if an organization that 'does not want to
change anything' is doing the right thing.</p><p>The Linux 2.4/2.5 bridge is documented on
<a href="http://bridge.sourceforge.net/" target="_top">this page</a>.</p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.BRIDGING.IPTABLES">16.1. State of bridging and iptables</a></h2><p>As of Linux 2.4.20, bridging and iptables do not 'see' each other without
help. If you bridge packets from eth0 to eth1, they do not 'pass' by
iptables. This means that you cannot do filtering, or NAT or mangling or
whatever. In Linux 2.5.45 and higher, this is fixed.</p><p>You may also see 'ebtables' mentioned which is yet another project - it
allows you to do wild things as MACNAT and 'brouting'. It is truly scary.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.BRIDGING.SHAPING">16.2. Bridging and shaping</a></h2><p>This does work as advertised. Be sure to figure out which side each
interface is on, otherwise you might be shaping outbound traffic in your
internal interface, which won't work. Use tcpdump if needed.</p></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.BRIDGING.PROXY-ARP">16.3. Pseudo-bridges with Proxy-ARP</a></h2><p>If you just want to implement a Pseudo-bridge, skip down a few sections 
to 'Implementing it', but it is wise to read a bit about how it works in
practice.</p><p>A Pseudo-bridge works a bit differently. By default, a bridge passes packets
unaltered from one interface to the other. It only looks at the hardware
address of packets to determine what goes where. This in turn means that you
can bridge traffic that Linux does not understand, as long as it has an
hardware address it does.</p><p>A 'Pseudo-bridge' works differently and looks more like a hidden router than
a bridge, but like a bridge, it has little impact on network design.</p><p>An advantage of the fact that it is not a bridge lies in the fact that
packets really pass through the kernel, and can be filtered, changed,
redirected or rerouted. </p><p>A real bridge can also be made to perform these feats, but it needs special
code, like the Ethernet Frame Diverter, or the above mentioned patch.</p><p>Another advantage of a pseudo-bridge is that it does not pass packets it
does not understand - thus cleaning your network of a lot of cruft. In cases
where you need this cruft (like SAP packets, or Netbeui), use a real bridge.</p><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2364">16.3.1. ARP &amp; Proxy-ARP</a></h3><p>When a host wants to talk to another host on the same physical network
segment, it sends out an Address Resolution Protocol packet, which, somewhat
simplified, reads like this 'who has 10.0.0.1, tell 10.0.0.7'. In response
to this, 10.0.0.1 replies with a short 'here' packet.</p><p>10.0.0.7 then sends packets to the hardware address mentioned in the 'here' 
packet. It caches this hardware address for a relatively long time, and
after the cache expires, it re-asks the question.</p><p>When building a Pseudo-bridge, we instruct the bridge to reply to these ARP
packets, which causes the hosts in the network to send its packets to the
bridge. The bridge then processes these packets, and sends them to the
relevant interface.</p><p>So, in short, whenever a host on one side of the bridge asks for the
hardware address of a host on the other, the bridge replies with a packet
that says 'hand it to me'.</p><p>This way, all data traffic gets transmitted to the right place, and always
passes through the bridge.</p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2371">16.3.2. Implementing it</a></h3><p>In the bad old days, it used to be possible to instruct the Linux Kernel to
perform 'proxy-ARP' for just any subnet. So, to configure a pseudo-bridge,
you would have to specify both the proper routes to both sides of the bridge
AND create matching proxy-ARP rules. This is bad in that it requires a lot
of typing, but also because it easily allows you to make mistakes which make
your bridge respond to ARP queries for networks it does not know how to
route.</p><p>With Linux 2.4/2.5 (and possibly 2.2), this possibility has been withdrawn and
has been replaced by a flag in the /proc directory, called 'proxy_arp'. The
procedure for building a pseudo-bridge is then:</p><p></p><p></p><ol type="1"><li><p>Assign an IP address to both interfaces, the 'left' and the 'right'
one</p></li><li><p>Create routes so your machine knows which hosts reside on the left,
and which on the right</p></li><li><p>Turn on proxy-ARP on both interfaces, echo 1 &gt;
/proc/sys/net/ipv4/conf/ethL/proxy_arp, echo 1 &gt;
/proc/sys/net/ipv4/conf/ethR/proxy_arp, where L and R stand for the numbers
of your interfaces on the left and on the right side</p></li></ol><p></p><p>Also, do not forget to turn on the ip_forwarding flag! When converting from
a true bridge, you may find that this flag was turned off as it is not
needed when bridging.</p><p>Another thing you might note when converting is that you need to clear the
arp cache of computers in the network - the arp cache might contain old
pre-bridge hardware addresses which are no longer correct.</p><p>On a Cisco, this is done using the command 'clear arp-cache', under
Linux, use 'arp -d ip.address'. You can also wait for the cache to expire
manually, which can take rather long.</p><p>You can speed this up using the wonderful 'arping' tool, which on many
distributions is part of the 'iputils' package. Using 'arping' you can send
out unsolicited ARP messages so as to update remote arp caches. </p><p>This is a very powerful technique that is also used by 'black hats' to
subvert your routing!</p><div class="NOTE"><p></p><table class="NOTE" width="100%" border="0"><tbody><tr><td width="25" align="CENTER" valign="TOP"></td><td align="LEFT" valign="TOP"><p>On Linux 2.4, you may need to execute 
'echo 1 &gt; /proc/sys/net/ipv4/ip_nonlocal_bind' before being able to send
out unsolicited ARP messages!</p></td></tr></tbody></table></div><p>You may also discover that your network was misconfigured if you are/were of
the habit of specifying routes without netmasks. To explain, some versions
of route may have guessed your netmask right in the past, or guessed wrong
without you noticing. When doing surgical routing like described above, it
is *vital* that you check your netmasks! </p></div></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.DYNAMIC-ROUTING"></a>Chapter 17. Dynamic routing - OSPF and BGP</h1><p>Once your network starts to get really big, or you start to consider 'the
internet' as your network, you need tools which dynamically route your data.
Sites are often connected to each other with multiple links, and more are
popping up all the time. </p><p>The Internet has mostly standardized on OSPF (RFC 2328) and BGP4 (RFC 1771).
Linux supports both, by way of <span class="APPLICATION">gated</span> and 
<span class="APPLICATION">zebra</span>.</p><p>While currently not within the scope of this document, we would like to
point you to the definitive works:</p><p>Overview:</p><p>Cisco Systems
<a href="http://www.cisco.com/univercd/cc/td/doc/cisintwk/idg4/nd2003.htm" target="_top">Designing large-scale IP Internetworks</a></p><p>For OSPF:</p><p>Moy, John T.
"OSPF.  The anatomy of an Internet routing protocol"
Addison Wesley. Reading, MA. 1998.</p><p>Halabi has also written a good guide to OSPF routing design, but this
appears to have been dropped from the Cisco web site.</p><p>For BGP:</p><p>Halabi, Bassam
"Internet routing architectures"
Cisco Press (New Riders Publishing). Indianapolis, IN. 1997.</p><p>also</p><p>Cisco Systems</p><p><a href="http://www.cisco.com/univercd/cc/td/doc/cisintwk/ics/icsbgp4.htm" target="_top">Using the Border Gateway Protocol for interdomain routing</a></p><p>Although the examples are Cisco-specific, they are remarkably similar
to the configuration language in Zebra :-)</p><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.DYNAMIC-ROUTING.OSPF">17.1. Setting up OSPF with Zebra</a></h2><p>		Please, let <a href="mailto:piotr%member.fsf.org" target="_top">me</a> know if any of the following information is not accurate or if you have any suggestions.
		<a href="http://www.zebra.org/" target="_top">Zebra</a> is a great 
dynamic routing software written by Kunihiro Ishiguro, Toshiaki Takada 
and Yasuhiro Ohara. With Zebra, setting up OSPF is fast an simple, but 
in practice there's a lot of parameters to tune if you have very 
specific needs. OSPF stands for Open Shortest Path First, and some of 
its principal features are:
		</p><p></p><div class="VARIABLELIST"><dl><dt>Hierachical</dt><dd><p>				Networks are grouped by <span class="emphasis"><i class="EMPHASIS">areas</i></span>, which are interconnected by a <span class="emphasis"><i class="EMPHASIS">backbone area</i></span> which will be designated as <span class="emphasis"><i class="EMPHASIS">area 0</i></span>. All traffic goes through area 0, and all the routers in area 0 have routing information about all the other areas.
				</p></dd><dt>Short convergence</dt><dd><p>				Routes are propagated very fast, compared with RIP, for example.
				</p></dd><dt>Bandwith efficient</dt><dd><p>				Uses multicasting 
instead of broadcasting, so it doesn't flood other hosts with routing 
information that may not be of interest for them, thus reducing network 
overhead. Also, <span class="emphasis"><i class="EMPHASIS">Internal Routers</i></span>
 (those which only have interfaces in one area) don't have routing 
information about other areas. Routers with interfaces in more than one 
area are called <span class="emphasis"><i class="EMPHASIS">Area Border Routers</i></span>, and hold topological information about the areas they are connected to.
				</p></dd><dt>Cpu intensive</dt><dd><p>				OSPF is based on Dijkstra's <a href="http://www.soi.wide.ad.jp/class/99007/slides/13/07.html" target="_top">Shortest Path First algorithm</a>, which is expensive compared to other routing algorithms. But really is not that bad, since the Shortest Path is only
calculated for each area, also for small to medium sized networks this won't be an issue, and you won't even notice.
				</p></dd><dt>Link state</dt><dd><p>				OSPF counts with the special characteristics of networks and interfaces, such as bandwith, link failures, and monetary cost.
				</p></dd><dt>Open protocol and GPLed software</dt><dd><p>				OSPF is an open protocol, and Zebra is GPL software, which has obvious advantages over propietary software and protocols.
				</p></dd></dl></div>
  <p></p><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.DYNAMIC-ROUTING.OSPF.PREREQ">17.1.1. Prerequisites</a></h3><p>			</p><p></p><div class="VARIABLELIST"><dl><dt>Linux Kernel:</dt><dd><p>					Compiled with CONFIG_NETLINK_DEV and CONFIG_IP_MULTICAST (I am not sure if anything more is also needed).
					</p></dd><dt>Iproute</dt><dd><p>					</p></dd><dt>Zebra</dt><dd><p>					Get it with your favorite package manager or from <a href="http://www.zebra.org/" target="_top">http://www.zebra.org</a>.
					</p></dd></dl></div>
		<p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.DYNAMIC-ROUTING.OSPF.ZEBRACFG">17.1.2. Configuring Zebra</a></h3><p>			Let's take this network as an example:
			</p><pre class="SCREEN">----------------------------------------------------
| 192.168.0.0/24                                   |
|                                                  |
|      Area 0    100BaseTX Switched                |
|     Backbone     Ethernet                        |
----------------------------------------------------
  |           |                |              |
  |           |                |              |
  |eth1       |eth1            |eth0          |
  |100BaseTX  |100BaseTX       |100BaseTX     |100BaseTX
  |.1         |.2              |.253          |
 ---------   ------------   -----------      ----------------
 |R Omega|   |R Atlantis|   |R Legolas|      |R Frodo       |
 ---------   ------------   -----------      ----------------
  |eth0         |eth0             |             |          |
  |             |                 |             |          |
  |2MbDSL/ATM   |100BaseTX        |10BaseT      |10BaseT   |10BaseT
------------   ------------------------------------       -------------------------------
| Internet |   | 172.17.0.0/16        Area 1      |       |  192.168.1.0/24 wlan  Area 2|
------------   |         Student network (dorm)   |       |       barcelonawireless     |
               ------------------------------------       -------------------------------
			</pre>
			Don't be afraid by this diagram, zebra does most of the work 
automatically, so it won't take any work to put all the routes up with 
zebra. It would be painful to maintain all those routes by hand in a day
 to day basis. The most important thing you must make clear, is the 
network topology. And take special care with Area 0, since it's the most
 important.
			First configure zebra, editing zebra.conf and adapt it to your needs:
			<pre class="SCREEN">hostname omega
password xxx 
enable password xxx
!
! Interface's description.
!
!interface lo
! description test of desc.
!
interface eth1
multicast
!
! Static default route
!
ip route 0.0.0.0/0 212.170.21.129
!
log file /var/log/zebra/zebra.log
			</pre>
			In Debian, I will also have to edit /etc/zebra/daemons so they start at boot:
			<pre class="SCREEN">zebra=yes
ospfd=yes
			</pre>
			Now we have to edit ospfd.conf if you are still running IPV4 or ospf6d.conf if you run IPV6. My ospfd.conf looks like:
			<pre class="SCREEN">hostname omega
password xxx
enable password xxx
!
router ospf
  network 192.168.0.0/24 area 0
  network 172.17.0.0/16 area 1
!
! log stdout
log file /var/log/zebra/ospfd.log
			</pre>
			Here we instruct ospf about our network topology.
		<p></p></div><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.DYNAMIC-ROUTING.OSPF.RUNNING">17.1.3. Running Zebra</a></h3><p>
			Now, we have to start Zebra; either by hand by typing "zebra -d" or 
with some script like "/etc/init.d/zebra start". Then carefully watching
 the ospdfd logs we should see something like:
			</p><pre class="SCREEN">2002/12/13 22:46:24 OSPF: interface 192.168.0.1 join AllSPFRouters Multicast group.
2002/12/13 22:46:34 OSPF: SMUX_CLOSE with reason: 5   
2002/12/13 22:46:44 OSPF: SMUX_CLOSE with reason: 5
2002/12/13 22:46:54 OSPF: SMUX_CLOSE with reason: 5   
2002/12/13 22:47:04 OSPF: SMUX_CLOSE with reason: 5   
2002/12/13 22:47:04 OSPF: DR-Election[1st]: Backup 192.168.0.1
2002/12/13 22:47:04 OSPF: DR-Election[1st]: DR     192.168.0.1
2002/12/13 22:47:04 OSPF: DR-Election[2nd]: Backup 0.0.0.0
2002/12/13 22:47:04 OSPF: DR-Election[2nd]: DR     192.168.0.1
2002/12/13 22:47:04 OSPF: interface 192.168.0.1 join AllDRouters Multicast group.
2002/12/13 22:47:06 OSPF: DR-Election[1st]: Backup 192.168.0.2
2002/12/13 22:47:06 OSPF: DR-Election[1st]: DR     192.168.0.1
2002/12/13 22:47:06 OSPF: Packet[DD]: Negotiation done (Slave).
2002/12/13 22:47:06 OSPF: nsm_change_status(): scheduling new router-LSA origination
2002/12/13 22:47:11 OSPF: ospf_intra_add_router: Start
			</pre>
			Ignore the SMUX_CLOSE message by now, since it's about SNMP. We can see that 192.168.0.1 is the <span class="emphasis"><i class="EMPHASIS">Designated Router</i></span> and 192.168.0.2 is the <span class="emphasis"><i class="EMPHASIS">Backup Designated Router</i></span>
		<p></p><p>			We can also interact with the zebra or the ospfd interface by executing:
			</p><pre class="SCREEN"><samp class="PROMPT">$ </samp>telnet localhost zebra
<samp class="PROMPT">$ </samp>telnet localhost ospfd
			</pre>

			Let's see how to view if the routes are propagating, log into zebra and type:
			
			<pre class="SCREEN">root@atlantis:~# telnet localhost zebra
Trying 127.0.0.1...
Connected to atlantis.
Escape character is '^]'.

Hello, this is zebra (version 0.92a).
Copyright 1996-2001 Kunihiro Ishiguro.

User Access Verification

Password: 
atlantis&gt; show ip route
Codes: K - kernel route, C - connected, S - static, R - RIP, O - OSPF,
       B - BGP, &gt; - selected route, * - FIB route

K&gt;* 0.0.0.0/0 via 192.168.0.1, eth1
C&gt;* 127.0.0.0/8 is directly connected, lo
O   172.17.0.0/16 [110/10] is directly connected, eth0, 06:21:53
C&gt;* 172.17.0.0/16 is directly connected, eth0
O   192.168.0.0/24 [110/10] is directly connected, eth1, 06:21:53
C&gt;* 192.168.0.0/24 is directly connected, eth1
atlantis&gt; show ip ospf border-routers
============ OSPF router routing table =============
R    192.168.0.253         [10] area: (0.0.0.0), ABR
			   via 192.168.0.253, eth1
				 [10] area: (0.0.0.1), ABR
			   via 172.17.0.2, eth0
			</pre>
			Or with iproute directly:
			<pre class="SCREEN">root@omega:~# ip route
212.170.21.128/26 dev eth0  proto kernel  scope link  src 212.170.21.172 
192.168.0.0/24 dev eth1  proto kernel  scope link  src 192.168.0.1 
172.17.0.0/16 via 192.168.0.2 dev eth1  proto zebra  metric 20 
default via 212.170.21.129 dev eth0  proto zebra 
root@omega:~# 
			</pre>
			We can see the zebra routes, that weren't there before. It's really 
nice to see routes appearing just a few seconds after you start zebra 
and ospfd. You can check connectivity to other hosts with ping. Zebra 
routes are automatic, you can just add another router to the network, 
configure zebra, and voila!
		<p></p><p>			Hint: You can use:
			</p><pre class="SCREEN">tcpdump -i eth1 ip[9] == 89
			</pre>
			To capture OSPF packets for analysis. OSPF ip protocol number is 89, 
and the protocol field is the 9th octet on the ip header.
		<p></p><p>			OSPF has a lot of tunable parameters, specially for large
 networks. In further ampliations of the howto we will show some 
methodologies for fine tunning OSPF.
		</p></div></div><div class="SECT1"><hr><h2 class="SECT1"><a name="LARTC.DYNAMIC-ROUTING.BGP">17.2. Setting up BGP4 with Zebra</a></h2><p>The Border Gateway Protocol Version 4 (BGP4) is a dynamic routing
protocol described in RFC 1771. It allows the distribution of
reachability information, i.e. routing tables, to other BGP4
enabled nodes. It can either be used as EGP or IGP, in EGP mode
each node must have its own Autonomous System (AS) number.
BGP4 supports Classless Inter Domain Routing (CIDR) and route
aggregation (merge multiple routes into one).</p><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.DYNAMIC-ROUTING.BGP.NETMAP">17.2.1. Network Map (Example)</a></h3><p>The following network map is used for further examples. AS 1 and 50
have more neighbors but we only need to configure 1 and 50 as our
neighbor. The nodes itself communicate over tunnels in this example
but that is not a must.</p><p>Note: The AS numbers used in this example are reserved, please
get your own AS from RIPE if you set up official peerings.</p><pre class="SCREEN">          --------------------
          | 192.168.23.12/24 |
          |    AS: 23        |
          --------------------
            /             \
           /               \
          /                 \
------------------       ------------------
| 192.168.1.1/24 |-------| 10.10.1.1/16   |
|    AS: 1       |       |    AS: 50      |
------------------       ------------------</pre></div><div class="SECT2"><hr><h3 class="SECT2"><a name="LARTC.DYNAMIC-ROUTING.BGP.CONFIG">17.2.2. Configuration (Example)</a></h3><p>The following configuration is written for node 192.168.23.12/24,
it is easy to adapt it for the other nodes.</p><p>It starts with some general stuff like hostname, passwords and
debug switches:</p><pre class="SCREEN">! hostname
hostname anakin

! login password
password xxx

! enable password (super user mode)
enable password xxx

! path to logfile
log file /var/log/zebra/bgpd.log

! debugging: be verbose (can be removed afterwards)
debug bgp events
debug bgp filters
debug bgp fsm
debug bgp keepalives
debug bgp updates</pre><p>Access list, used to limit the redistribution to 
private networks (RFC 1918).</p><pre class="SCREEN">! RFC 1918 networks
access-list local_nets permit 192.168.0.0/16
access-list local_nets permit 172.16.0.0/12
access-list local_nets permit 10.0.0.0/8
access-list local_nets deny any</pre><p>Next step is to do the per AS configuration:</p><pre class="SCREEN">! Own AS number
router bgp 23

    ! IP address of the router
    bgp router-id 192.168.23.12

    ! announce our own network to other neighbors
    network 192.168.23.0/24

    ! advertise all connected routes (= directly attached interfaces)
    redistribute connected

    ! advertise kernel routes (= manually inserted routes)
    redistribute kernel</pre><p>Every 'router bgp' block contains a list of neighbors to which
the router is connected to:</p><pre class="SCREEN">    neighbor 192.168.1.1 remote-as 1
    neighbor 192.168.1.1 distribute-list local_nets in
    neighbor 10.10.1.1   remote-as 50
    neighbor 10.10.1.1   distribute-list local_nets in</pre></div><div class="SECT2"><hr><h3 class="SECT2"><a name="AEN2512">17.2.3. Checking Configuration</a></h3><p>Note: vtysh is a multiplexer and connects all the Zebra interfaces
together.</p><pre class="SCREEN">anakin# sh ip bgp summary 
BGP router identifier 192.168.23.12, local AS number 23
2 BGP AS-PATH entries
0 BGP community entries

Neighbor        V    AS MsgRcvd MsgSent   TblVer  InQ OutQ Up/Down  State/PfxRcd
10.10.0.1       4    50      35      40        0    0    0 00:28:40        1
192.168.1.1     4     1   27574   27644        0    0    0 03:26:04       14

Total number of neighbors 2
anakin#
anakin# sh ip bgp neighbors 10.10.0.1
BGP neighbor is 10.10.0.1, remote AS 50, local AS 23, external link
  BGP version 4, remote router ID 10.10.0.1
  BGP state = Established, up for 00:29:01
  ....
anakin#</pre><p>Let's see which routes we got from our neighbors:</p><pre class="SCREEN">anakin# sh ip ro bgp 
Codes: K - kernel route, C - connected, S - static, R - RIP, O - OSPF,
       B - BGP, &gt; - selected route, * - FIB route

B&gt;* 172.16.0.0/14 [20/0] via 192.168.1.1, tun0, 2d10h19m
B&gt;* 172.30.0.0/16 [20/0] via 192.168.1.1, tun0, 10:09:24
B&gt;* 192.168.5.10/32 [20/0] via 192.168.1.1, tun0, 2d10h27m
B&gt;* 192.168.5.26/32 [20/0] via 192.168.1.1, tun0, 10:09:24
B&gt;* 192.168.5.36/32 [20/0] via 192.168.1.1, tun0, 2d10h19m
B&gt;* 192.168.17.0/24 [20/0] via 192.168.1.1, tun0, 3d05h07m
B&gt;* 192.168.17.1/32 [20/0] via 192.168.1.1, tun0, 3d05h07m
B&gt;* 192.168.32.0/24 [20/0] via 192.168.1.1, tun0, 2d10h27m
anakin#</pre></div></div></div><div class="CHAPTER"><hr><h1><a name="LARTC.OTHER"></a>Chapter 18. Other possibilities</h1><p>This chapter is a list of projects having to do with advanced Linux routing
&amp; traffic shaping. Some of these links may deserve chapters of their
own, some are documented very well of themselves, and don't need more HOWTO.</p><p></p><p></p><div class="VARIABLELIST"><dl><dt>802.1Q VLAN Implementation for Linux <a href="http://scry.wanfear.com/~greear/vlan.html" target="_top">(site)</a></dt><dd><p>VLANs are a very cool way to segregate your
networks in a more virtual than physical way. Good information on VLANs can
be found <a href="ftp://ftp.netlab.ohio-state.edu/pub/jain/courses/cis788-97/virtual_lans/index.htm" target="_top">here</a>. With this implementation, you can have your Linux box talk
VLANs with machines like Cisco Catalyst, 3Com: {Corebuilder, Netbuilder II,
SuperStack II switch 630}, Extreme Ntwks Summit 48, Foundry: {ServerIronXL,
FastIron}.</p><p>A great HOWTO about VLANs can be found <a href="http://scry.wanfear.com/~greear/vlan/cisco_howto.html" target="_top">here</a>.</p><p>Update: has been included in the kernel as of 2.4.14 (perhaps 13).</p></dd><dt>Alternate 802.1Q VLAN Implementation for Linux <a href="http://vlan.sourceforge.net/" target="_top">(site)</a></dt><dd><p>Alternative VLAN implementation for linux. This project was started out of
disagreement with the 'established' VLAN project's architecture and coding
style, resulting in a cleaner overall design.</p></dd><dt>Linux Virtual Server <a href="http://www.linuxvirtualserver.org/" target="_top">(site)</a></dt><dd><p>These people are brilliant. The Linux Virtual Server is a highly scalable and
highly available server built on a cluster of real servers, with the load
balancer running on the Linux operating system. The architecture of the
cluster is transparent to end users. End users only see a single virtual
server.</p><p>In short whatever you need to load balance, at whatever level of traffic, LVS
will have a way of doing it. Some of their techniques are positively evil!
For example, they let several machines have the same IP address on a
segment, but turn off ARP on them. Only the LVS machine does ARP - it then
decides which of the backend hosts should handle an incoming packet, and
sends it directly to the right MAC address of the backend server. Outgoing
traffic will flow directly to the router, and not via the LVS machine, which
does therefore not need to see your 5Gbit/s of content flowing to the world,
and cannot be a bottleneck.</p><p>The LVS is implemented as a kernel patch in Linux 2.0 and 2.2, but as a
Netfilter module in 2.4/2.5, so it does not need kernel patches! Their 2.4
support is still in early development, so beat on it and give feedback or
send patches.</p></dd><dt>CBQ.init <a href="ftp://ftp.equinox.gu.net/pub/linux/cbq/" target="_top">(site)</a></dt><dd><p>Configuring CBQ can be a bit daunting, especially if all you want to do is
shape some computers behind a router. CBQ.init can help you configure Linux
with a simplified syntax.</p><p>For example, if you want all computers in your 192.168.1.0/24 subnet
(on 10mbit eth1) to be limited to 28kbit/s download speed, put
this in the CBQ.init configuration file:</p><p></p><pre class="SCREEN">DEVICE=eth1,10Mbit,1Mbit
RATE=28Kbit
WEIGHT=2Kbit
PRIO=5
RULE=192.168.1.0/24</pre><p></p><p>By all means use this program if the 'how and why' don't interest you.
We're using CBQ.init in production and it works very well. It can even do
some more advanced things, like time dependent shaping. The documentation is
embedded in the script, which explains why you can't find a README.</p></dd><dt>Chronox easy shaping scripts <a href="http://www.chronox.de/" target="_top">(site)</a></dt><dd><p>Stephan Mueller (smueller@chronox.de) wrote two useful scripts, 'limit.conn'
and 'shaper'. The first one allows you to easily throttle a single download
session, like this:</p><p></p><pre class="SCREEN"># limit.conn -s SERVERIP -p SERVERPORT -l LIMIT</pre><p></p><p>It works on Linux 2.2 and 2.4/2.5.</p><p>The second script is more complicated, and can be used to make lots of
different queues based on iptables rules, which are used to mark packets
which are then shaped.</p></dd><dt>Virtual Router
Redundancy Protocol implementation (
<a href="http://off.net/~jme/vrrpd/" target="_top">site1</a>,
<a href="http://www.imagestream.com/VRRP.html" target="_top">site2</a>
)</dt><dd><p>FIXME: This link died, anybody know where it went?</p><p>This is purely for redundancy. Two machines with their own IP address and
MAC Address together create a third IP Address and MAC Address, which is
virtual. Originally intended purely for routers, which need constant MAC
addresses, it also works for other servers.</p><p>The beauty of this approach is the incredibly easy configuration. No kernel
compiling or patching required, all userspace.</p><p>Just run this on all machines participating in a service:

</p><pre class="SCREEN"># vrrpd -i eth0 -v 50 10.0.0.22</pre><p></p><p>And you are in business! 10.0.0.22 is now carried by one of your servers,
probably the first one to run the vrrp daemon. Now disconnect that computer
from the network and very rapidly one of the other computers will assume the
10.0.0.22 address, as well as the MAC address.</p><p>I tried this over here and had it up and running in 1 minute. For some
strange reason it decided to drop my default gateway, but the -n flag
prevented that.</p><p>This is a 'live' fail over:</p><p></p><pre class="SCREEN">64 bytes from 10.0.0.22: icmp_seq=3 ttl=255 time=0.2 ms
64 bytes from 10.0.0.22: icmp_seq=4 ttl=255 time=0.2 ms
64 bytes from 10.0.0.22: icmp_seq=5 ttl=255 time=16.8 ms
64 bytes from 10.0.0.22: icmp_seq=6 ttl=255 time=1.8 ms
64 bytes from 10.0.0.22: icmp_seq=7 ttl=255 time=1.7 ms</pre><p></p><p>Not *one* ping packet was lost! Just after packet 4, I disconnected my P200
from the network, and my 486 took over, which you can see from the higher
latency.</p></dd><dt>tc-config
<a href="http://slava.local.nsys.by/projects/tc_config/" target="_top">(site)</a></dt><dd><p>tc_config is set of scripts for linux 2.4+ traffic control
configuration on RedHat systems and (hopefully) derivatives
(linux 2.2.X with ipchains is obsotete).
Uses cbq qdisc as root one, and sfq qdisc at leafs.</p><p>Includes snmp_pass utility for getting stats on traffic control via snmp.
FIXME: Write</p></dd></dl></div><p></p></div><div class="CHAPTER"><hr><h1><a name="LARTC.FURTHER"></a>Chapter 19. Further reading</h1><p></p><p></p><div class="VARIABLELIST"><dl><dt><a href="http://snafu.freedom.org/linux2.2/iproute-notes.html" target="_top">http://snafu.freedom.org/linux2.2/iproute-notes.html</a></dt><dd><p>Contains lots of technical information, comments from the kernel</p></dd><dt><a href="http://www.davin.ottawa.on.ca/ols/" target="_top">http://www.davin.ottawa.on.ca/ols/</a></dt><dd><p>Slides by Jamal Hadi Salim, one of the authors of Linux traffic control</p></dd><dt><a href="http://defiant.coinet.com/iproute2/ip-cref/" target="_top">http://defiant.coinet.com/iproute2/ip-cref/</a></dt><dd><p>HTML version of Alexey's LaTeX documentation - explains part of iproute2 in
great detail</p></dd><dt><a href="http://www.aciri.org/floyd/cbq.html" target="_top">http://www.aciri.org/floyd/cbq.html</a></dt><dd><p>Sally Floyd has a good page on CBQ, including her original papers. None of
it is Linux specific, but it does a fair job discussing the theory and uses
of CBQ.
Very technical stuff, but good reading for those so inclined. </p></dd><dt>Differentiated Services on Linux</dt><dd><p>This <a href="ftp://icaftp.epfl.ch/pub/linux/diffserv/misc/dsid-01.txt.gz" target="_top">document</a> by Werner Almesberger, Jamal Hadi Salim and Alexey
Kuznetsov describes DiffServ facilities in the Linux kernel, amongst which
are TBF, GRED, the DSMARK qdisc and the tcindex classifier.</p></dd><dt><a href="http://ceti.pl/~kravietz/cbq/NET4_tc.html" target="_top">http://ceti.pl/~kravietz/cbq/NET4_tc.html</a></dt><dd><p>Yet another HOWTO, this time in Polish! You can copy/paste command lines
however, they work just the same in every language. The author is
cooperating with us and may soon author sections of this HOWTO.</p></dd><dt><a href="http://www.cisco.com/univercd/cc/td/doc/product/software/ios111/cc111/car.htm" target="_top">IOS Committed Access Rate</a></dt><dd><p><a name="CAR"></a>
From the helpful folks of Cisco who have the laudable habit of putting
their documentation online. Cisco syntax is different but the concepts are
the same, except that we can do more and do it without routers the price of
cars :-)</p></dd><dt>Docum experimental site<a href="http://www.docum.org/" target="_top">(site)</a></dt><dd><p>Stef Coene is busy convincing his boss to sell Linux support, and so he is
experimenting a lot, especially with managing bandwidth. His site has a lot
of practical information, examples, tests and also points out some CBQ/tc bugs. </p></dd><dt>TCP/IP Illustrated, volume 1, W. Richard Stevens, ISBN 0-201-63346-9</dt><dd><p>Required reading if you truly want to understand TCP/IP. Entertaining as
well.</p></dd><dt>Policy Routing Using Linux, Matthew G. Marsh, ISBN 0-672-32052-5</dt><dd><p>A introduction to policy routing with lots of examples.</p></dd><dt>Internet QoS: Architectures and Mechanisms for Quality of Service,
Zheng Wang, ISBN 1-55860-608-4</dt><dd><p>Hardcover textbook covering topics
related to Quality of Service. Good for understanding basic concepts.</p></dd></dl></div> <p></p></div><div class="CHAPTER"><hr><h1><a name="LARTC.ACK"></a>Chapter 20. Acknowledgements </h1><p> 
It is our goal to list everybody who has contributed to this HOWTO, or
helped us demystify how things work. While there are currently no plans
for a Netfilter type scoreboard, we do like to recognize the people who are
helping.</p><p></p><p></p><ul compact="COMPACT"><li><p>   Junk Alins
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:juanjo@mat.upc.es">juanjo@mat.upc.es</a>&gt;</code></p>
   <p></p></li><li><p>   Joe Van Andel
   </p></li><li><p>   Michael T. Babcock
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:mbabcock@fibrespeed.net">mbabcock@fibrespeed.net</a>&gt;</code></p>
   <p></p></li><li><p>   Christopher Barton
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:cpbarton%uiuc.edu">cpbarton%uiuc.edu</a>&gt;</code></p>
   <p></p></li><li><p>   Peter Bieringer
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:pb:bieringer.de">pb:bieringer.de</a>&gt;</code></p>
   <p></p></li><li><p>   Adam Burke
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:aburke%crg.ee.uct.ac.za">aburke%crg.ee.uct.ac.za</a>&gt;</code></p>
   <p></p></li><li><p>   Ard van Breemen
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:ard%kwaak.net">ard%kwaak.net</a>&gt;</code></p>
  <p></p></li><li><p>   Ron Brinker
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:service%emcis.com">service%emcis.com</a>&gt;</code></p>
   <p></p></li><li><p>   Lukasz Bromirski
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:l.bromirski@mr0vka.eu.org">l.bromirski@mr0vka.eu.org</a>&gt;</code></p>
   <p></p></li><li><p>   Lennert Buytenhek
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:buytenh@gnu.org">buytenh@gnu.org</a>&gt;</code></p>
   <p></p></li><li><p>   Esteve Camps
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:esteve@hades.udg.es">esteve@hades.udg.es</a>&gt;</code></p>
   <p></p></li><li><p>   Ricardo Javier Cardenes
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:ricardo%conysis.com">ricardo%conysis.com</a>&gt;</code></p>
   <p></p></li><li><p>   Nelson Castillo
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:arhuaco%yahoo.com">arhuaco%yahoo.com</a>&gt;</code></p>
   <p></p></li><li><p>   Stef Coene
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:stef.coene@docum.org">stef.coene@docum.org</a>&gt;</code></p>
   <p></p></li><li><p>   Don Cohen
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:don-lartc%isis.cs3-inc.com">don-lartc%isis.cs3-inc.com</a>&gt;</code></p>
   <p></p></li><li><p>   Jonathan Corbet
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:lwn%lwn.net">lwn%lwn.net</a>&gt;</code></p>
   <p></p></li><li><p>   Gerry N5JXS Creager
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:gerry%cs.tamu.edu">gerry%cs.tamu.edu</a>&gt;</code></p>
   <p></p></li><li><p>   Marco Davids
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:marco@sara.nl">marco@sara.nl</a>&gt;</code></p>
   <p></p></li><li><p>   Jonathan Day
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:jd9812@my-deja.com">jd9812@my-deja.com</a>&gt;</code></p>
   <p></p></li><li><p>   Martin aka devik Devera
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:devik@cdi.cz">devik@cdi.cz</a>&gt;</code></p>
  <p></p></li><li><p>   Hannes Ebner
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:he%fli4l.de">he%fli4l.de</a>&gt;</code></p>
  <p></p></li><li><p>   Derek Fawcus
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:dfawcus%cisco.com">dfawcus%cisco.com</a>&gt;</code></p>
  <p></p></li><li><p>   David Fries
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:dfries%mail.win.org">dfries%mail.win.org</a>&gt;</code></p>
  <p></p></li><li><p>   Stephan "Kobold" Gehring
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:Stephan.Gehring@bechtle.de">Stephan.Gehring@bechtle.de</a>&gt;</code></p>
  <p></p></li><li><p>   Jacek Glinkowski
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:jglinkow%hns.com">jglinkow%hns.com</a>&gt;</code></p>
  <p></p></li><li><p>   Andrea Glorioso
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:sama%perchetopi.org">sama%perchetopi.org</a>&gt;</code></p>
  <p></p></li><li><p>   Thomas Graf
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:tgraf%suug.ch">tgraf%suug.ch</a>&gt;</code></p>
  <p></p></li><li><p>   Sandy Harris
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:sandy%storm.ca">sandy%storm.ca</a>&gt;</code></p>
  <p></p></li><li><p>   Nadeem Hasan
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:nhasan@usa.net">nhasan@usa.net</a>&gt;</code></p>
   <p></p></li><li><p>   Erik Hensema
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:erik%hensema.xs4all.nl">erik%hensema.xs4all.nl</a>&gt;</code></p>
   <p></p></li><li><p>   Vik Heyndrickx
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:vik.heyndrickx@edchq.com">vik.heyndrickx@edchq.com</a>&gt;</code></p>
   <p></p></li><li><p>   Spauldo Da Hippie
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:spauldo%usa.net">spauldo%usa.net</a>&gt;</code></p>
   <p></p></li><li><p>   Koos van den Hout
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:koos@kzdoos.xs4all.nl">koos@kzdoos.xs4all.nl</a>&gt;</code></p>
   <p></p></li><li><p>Stefan Huelbrock &lt;shuelbrock%datasystems.de&gt;</p></li><li><p>   Ayotunde Itayemi
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:aitayemi:metrong.com">aitayemi:metrong.com</a>&gt;</code></p>
   <p></p></li><li><p>Alexander W. Janssen &lt;yalla%ynfonatic.de&gt;</p></li><li><p>Andreas Jellinghaus &lt;aj%dungeon.inka.de&gt;</p></li><li><p>Gareth John &lt;gdjohn%zepler.org&gt;</p></li><li><p>   Dave Johnson
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:dj@www.uk.linux.org">dj@www.uk.linux.org</a>&gt;</code></p>
   <p></p></li><li><p>Martin Josefsson &lt;gandalf%wlug.westbo.se&gt;</p></li><li><p>Andi Kleen &lt;ak%suse.de&gt;</p></li><li><p>Andreas J. Koenig &lt;andreas.koenig%anima.de&gt;</p></li><li><p>Pawel Krawczyk &lt;kravietz%alfa.ceti.pl&gt;</p></li><li><p>Amit Kucheria &lt;amitk@ittc.ku.edu&gt;</p></li><li><p>Pedro Larroy
</p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:piotr%member.fsf.org">piotr%member.fsf.org</a>&gt;</code></p>
<p></p><ul><li><p>Chapter 15, section 10: Example of a full nat solution with QoS</p></li><li><p>Chapter 17, section 1: Setting up OSPF with Zebra</p></li></ul><p></p></li><li><p>Edmund Lau &lt;edlau%ucf.ics.uci.edu&gt;</p></li><li><p>Philippe Latu &lt;philippe.latu%linux-france.org&gt;</p></li><li><p>Arthur van Leeuwen &lt;arthurvl%sci.kun.nl&gt;</p></li><li><p>Jose Luis Domingo Lopez
</p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:jdomingo@24x7linux.com">jdomingo@24x7linux.com</a>&gt;</code></p><p></p></li><li><p>   Robert Lowe
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:robert.h.lowe@lawrence.edu">robert.h.lowe@lawrence.edu</a>&gt;</code></p>
  <p></p></li><li><p>Jason Lunz &lt;j@cc.gatech.edu&gt;</p></li><li><p>Stuart Lynne &lt;sl@fireplug.net&gt;</p></li><li><p>Alexey Mahotkin &lt;alexm@formulabez.ru&gt;</p></li><li><p>Predrag Malicevic &lt;pmalic@ieee.org&gt;</p></li><li><p>Patrick McHardy &lt;kaber@trash.net&gt;</p></li><li><p>Andreas Mohr &lt;andi%lisas.de&gt;</p></li><li><p>James Morris &lt;jmorris@intercode.com.au&gt;</p></li><li><p>Andrew Morton &lt;akpm%zip.com.au&gt;</p></li><li><p>Wim van der Most </p></li><li><p>Stephan Mueller &lt;smueller@chronox.de&gt;</p></li><li><p>Togan Muftuoglu &lt;toganm%yahoo.com&gt;</p></li><li><p>Chris Murray &lt;cmurray@stargate.ca&gt;</p></li><li><p>Takeo NAKANO &lt;nakano@apm.seikei.ac.jp&gt;</p></li><li><p>Patrick Nagelschmidt &lt;dto%gmx.net&gt;</p></li><li><p>Ram Narula &lt;ram@princess1.net&gt;</p></li><li><p>Jorge Novo &lt;jnovo@educanet.net&gt;</p></li><li><p>Patrik &lt;ph@kurd.nu&gt;</p></li><li><p>Pl Osgyny &lt;oplab%westel900.net&gt;</p></li><li><p>Lutz Preler &lt;Lutz.Pressler%SerNet.DE&gt;</p></li><li><p>Jason Pyeron &lt;jason%pyeron.com&gt;</p></li><li><p>Rod Roark &lt;rod%sunsetsystems.com&gt;</p></li><li><p>Pavel Roskin &lt;proski@gnu.org&gt;</p></li><li><p>Rusty Russell &lt;rusty%rustcorp.com.au&gt;</p></li><li><p>Mihai RUSU &lt;dizzy%roedu.net&gt;</p></li><li><p>Rob Pitman &lt;rob%pitman.co.za&gt;</p></li><li><p>Jamal Hadi Salim &lt;hadi%cyberus.ca&gt;</p></li><li><p>Ren Serral &lt;rserral%ac.upc.es&gt; </p></li><li><p>David Sauer &lt;davids%penguin.cz&gt;</p></li><li><p>Sheharyar Suleman Shaikh &lt;sss23@drexel.edu&gt;</p></li><li><p>Stewart Shields &lt;MourningBlade%bigfoot.com&gt;</p></li><li><p>Nick Silberstein &lt;nhsilber%yahoo.com&gt;</p></li><li><p>Konrads Smelkov &lt;konrads@interbaltika.com&gt;</p></li><li><p>William Stearns
</p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:wstearns@pobox.com">wstearns@pobox.com</a>&gt;</code></p><p></p></li><li><p>Andreas Steinmetz &lt;ast%domdv.de&gt;</p></li><li><p>Matthew Strait &lt;straitm%mathcs.carleton.edu&gt;</p></li><li><p>Jason Tackaberry &lt;tack@linux.com&gt;</p></li><li><p>Charles Tassell &lt;ctassell%isn.net&gt;</p></li><li><p>Jason Thomas &lt;jason5intology.com.au&gt;</p></li><li><p>Glen Turner &lt;glen.turner%aarnet.edu.au&gt;</p></li><li><p>Tea Sponsor: Eric Veldhuyzen &lt;eric%terra.nu&gt; </p></li><li><p>Thomas Walpuski &lt;thomas%bender.thinknerd.de&gt;</p></li><li><p>Song Wang &lt;wsong@ece.uci.edu&gt;</p></li><li><p>Frank v Waveren &lt;fvw@var.cx&gt;</p></li><li><p>   Chris Wilson
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:chris@netservers.co.uk">chris@netservers.co.uk</a>&gt;</code></p>
   <p></p></li><li><p>   Lazar Yanackiev
   </p><p class="ADDRESS"><code class="EMAIL">&lt;<a href="mailto:Lyanackiev%gmx.net">Lyanackiev%gmx.net</a>&gt;</code></p>
   <p></p></li></ul><p></p></div></div></body></html>
